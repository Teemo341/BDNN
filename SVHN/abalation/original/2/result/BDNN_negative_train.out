True
load data:  svhn
Building SVHN data loader with 1 workers
Using downloaded and verified file: /home/ssy/BDNN/data/svhn/train_32x32.mat
Using downloaded and verified file: /home/ssy/BDNN/data/svhn/test_32x32.mat
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 1.414210 | Loss_in_diffu: 12.478272 | Loss_out_diffu: 12.067618 | Acc: 52.969296 (38782/73216)
(1643166868.3841295, 1643166991.171384, 122.78725457191467)
Test epoch: 0| Acc: 79.14100985221675 (20564/25984) 

Epoch: 1
Train epoch:1 	Loss_in: 0.578409 | Loss_in_diffu: 11.901791 | Loss_out_diffu: 12.759959 | Acc: 83.031031 (60792/73216)
(1643166994.1482153, 1643167116.4094722, 122.26125693321228)
Test epoch: 1| Acc: 86.50708128078817 (22478/25984) 

Epoch: 2
Train epoch:2 	Loss_in: 0.415775 | Loss_in_diffu: 11.885663 | Loss_out_diffu: 12.969714 | Acc: 87.763604 (64257/73216)
(1643167119.5268917, 1643167241.9676523, 122.4407606124878)
Test epoch: 2| Acc: 88.56988916256158 (23014/25984) 

Epoch: 3
Train epoch:3 	Loss_in: 0.342990 | Loss_in_diffu: 11.931959 | Loss_out_diffu: 13.103507 | Acc: 89.853311 (65787/73216)
(1643167244.9363732, 1643167366.9229827, 121.98660945892334)
Test epoch: 3| Acc: 91.49091748768473 (23773/25984) 

Epoch: 4
Train epoch:4 	Loss_in: 0.308628 | Loss_in_diffu: 12.019354 | Loss_out_diffu: 13.240340 | Acc: 90.969187 (66604/73216)
(1643167369.9042554, 1643167491.9411995, 122.03694415092468)
Test epoch: 4| Acc: 92.74553571428571 (24099/25984) 

Epoch: 5
Train epoch:5 	Loss_in: 0.282150 | Loss_in_diffu: 12.122485 | Loss_out_diffu: 13.347865 | Acc: 91.783217 (67200/73216)
(1643167494.911225, 1643167616.8966315, 121.9854063987732)
Test epoch: 5| Acc: 92.99184113300493 (24163/25984) 

Epoch: 6
Train epoch:6 	Loss_in: 0.262503 | Loss_in_diffu: 12.239748 | Loss_out_diffu: 13.470989 | Acc: 92.330911 (67601/73216)
(1643167619.9844487, 1643167742.0502508, 122.06580209732056)
Test epoch: 6| Acc: 93.07650862068965 (24185/25984) 

Epoch: 7
Train epoch:7 	Loss_in: 0.245634 | Loss_in_diffu: 12.365862 | Loss_out_diffu: 13.629729 | Acc: 92.834899 (67970/73216)
(1643167745.1539123, 1643167867.2495093, 122.0955970287323)
Test epoch: 7| Acc: 92.82635467980296 (24120/25984) 

Epoch: 8
Train epoch:8 	Loss_in: 0.233672 | Loss_in_diffu: 12.509136 | Loss_out_diffu: 13.792842 | Acc: 93.262402 (68283/73216)
(1643167870.2282014, 1643167992.25523, 122.02702856063843)
Test epoch: 8| Acc: 93.24584359605912 (24229/25984) 

Epoch: 9
Train epoch:9 	Loss_in: 0.218908 | Loss_in_diffu: 12.654218 | Loss_out_diffu: 13.927411 | Acc: 93.655758 (68571/73216)
(1643167995.3458457, 1643168117.4026108, 122.05676507949829)
Test epoch: 9| Acc: 93.68072660098522 (24342/25984) 

Epoch: 10
Train epoch:10 	Loss_in: 0.209138 | Loss_in_diffu: 12.784063 | Loss_out_diffu: 14.081030 | Acc: 93.979458 (68808/73216)
(1643168120.3835115, 1643168242.850721, 122.46720933914185)
Test epoch: 10| Acc: 93.01878078817734 (24170/25984) 

Epoch: 11
Train epoch:11 	Loss_in: 0.142753 | Loss_in_diffu: 12.801951 | Loss_out_diffu: 14.161122 | Acc: 96.200284 (70434/73216)
(1643168245.8475473, 1643168368.1728776, 122.32533025741577)
Test epoch: 11| Acc: 95.13161945812809 (24719/25984) 

Epoch: 12
Train epoch:12 	Loss_in: 0.130210 | Loss_in_diffu: 12.793931 | Loss_out_diffu: 14.168924 | Acc: 96.575885 (70709/73216)
(1643168371.2669554, 1643168493.3428345, 122.07587909698486)
Test epoch: 12| Acc: 94.95843596059113 (24674/25984) 

Epoch: 13
Train epoch:13 	Loss_in: 0.124514 | Loss_in_diffu: 12.792567 | Loss_out_diffu: 14.174064 | Acc: 96.769832 (70851/73216)
(1643168496.4354508, 1643168618.462564, 122.02711319923401)
Test epoch: 13| Acc: 95.10467980295566 (24712/25984) 

Epoch: 14
Train epoch:14 	Loss_in: 0.119219 | Loss_in_diffu: 12.792017 | Loss_out_diffu: 14.183390 | Acc: 96.974705 (71001/73216)
(1643168621.447742, 1643168743.483056, 122.03531408309937)
Test epoch: 14| Acc: 95.03925492610837 (24695/25984) 

Epoch: 15
Train epoch:15 	Loss_in: 0.114676 | Loss_in_diffu: 12.792170 | Loss_out_diffu: 14.190644 | Acc: 97.074410 (71074/73216)
(1643168746.4564195, 1643168868.8858685, 122.4294490814209)
Test epoch: 15| Acc: 94.8776169950739 (24653/25984) 

Epoch: 16
Train epoch:16 	Loss_in: 0.109779 | Loss_in_diffu: 12.792111 | Loss_out_diffu: 14.200151 | Acc: 97.277917 (71223/73216)
(1643168872.0098152, 1643168995.0370069, 123.02719163894653)
Test epoch: 16| Acc: 95.09698275862068 (24710/25984) 

Epoch: 17
Train epoch:17 	Loss_in: 0.105474 | Loss_in_diffu: 12.791772 | Loss_out_diffu: 14.205776 | Acc: 97.428158 (71333/73216)
(1643168998.0529509, 1643169120.9946527, 122.94170188903809)
Test epoch: 17| Acc: 94.80064655172414 (24633/25984) 

Epoch: 18
Train epoch:18 	Loss_in: 0.101146 | Loss_in_diffu: 12.791811 | Loss_out_diffu: 14.211226 | Acc: 97.593422 (71454/73216)
(1643169124.1551008, 1643169246.1665707, 122.01146984100342)
Test epoch: 18| Acc: 94.95073891625616 (24672/25984) 

Epoch: 19
Train epoch:19 	Loss_in: 0.097051 | Loss_in_diffu: 12.791804 | Loss_out_diffu: 14.218556 | Acc: 97.701322 (71533/73216)
(1643169249.2534213, 1643169371.2665656, 122.01314425468445)
Test epoch: 19| Acc: 94.80449507389163 (24634/25984) 

Epoch: 20
Train epoch:20 	Loss_in: 0.093177 | Loss_in_diffu: 12.791817 | Loss_out_diffu: 14.223146 | Acc: 97.852928 (71644/73216)
(1643169374.3590763, 1643169496.3467078, 121.98763155937195)
Test epoch: 20| Acc: 94.9353448275862 (24668/25984) 

Epoch: 21
Train epoch:21 	Loss_in: 0.081938 | Loss_in_diffu: 12.784135 | Loss_out_diffu: 14.221033 | Acc: 98.283162 (71959/73216)
(1643169499.4412289, 1643169621.40564, 121.96441102027893)
Test epoch: 21| Acc: 94.96228448275862 (24675/25984) 

Epoch: 22
Train epoch:22 	Loss_in: 0.080290 | Loss_in_diffu: 12.783151 | Loss_out_diffu: 14.222799 | Acc: 98.332332 (71995/73216)
(1643169624.4916527, 1643169746.5717628, 122.0801100730896)
Test epoch: 22| Acc: 94.91995073891626 (24664/25984) 

Epoch: 23
Train epoch:23 	Loss_in: 0.079582 | Loss_in_diffu: 12.782688 | Loss_out_diffu: 14.223333 | Acc: 98.363746 (72018/73216)
(1643169749.5548646, 1643169871.4762816, 121.92141699790955)
Test epoch: 23| Acc: 94.88916256157636 (24656/25984) 

Epoch: 24
Train epoch:24 	Loss_in: 0.078973 | Loss_in_diffu: 12.782216 | Loss_out_diffu: 14.224434 | Acc: 98.377404 (72028/73216)
(1643169874.5649908, 1643169996.891023, 122.32603216171265)
Test epoch: 24| Acc: 94.89301108374384 (24657/25984) 

Epoch: 25
Train epoch:25 	Loss_in: 0.078352 | Loss_in_diffu: 12.781846 | Loss_out_diffu: 14.224580 | Acc: 98.397891 (72043/73216)
(1643170000.0276043, 1643170123.0033317, 122.97572731971741)
Test epoch: 25| Acc: 94.85452586206897 (24647/25984) 

Epoch: 26
Train epoch:26 	Loss_in: 0.077715 | Loss_in_diffu: 12.781913 | Loss_out_diffu: 14.226449 | Acc: 98.410184 (72052/73216)
(1643170126.02766, 1643170248.7543662, 122.7267062664032)
Test epoch: 26| Acc: 94.84682881773399 (24645/25984) 

Epoch: 27
Train epoch:27 	Loss_in: 0.077244 | Loss_in_diffu: 12.781666 | Loss_out_diffu: 14.227077 | Acc: 98.437500 (72072/73216)
(1643170251.716608, 1643170373.7252204, 122.00861239433289)
Test epoch: 27| Acc: 94.85837438423646 (24648/25984) 

Epoch: 28
Train epoch:28 	Loss_in: 0.076622 | Loss_in_diffu: 12.781017 | Loss_out_diffu: 14.227420 | Acc: 98.442963 (72076/73216)
(1643170376.8204997, 1643170499.7405267, 122.92002701759338)
Test epoch: 28| Acc: 94.91225369458128 (24662/25984) 

Epoch: 29
Train epoch:29 	Loss_in: 0.076150 | Loss_in_diffu: 12.780681 | Loss_out_diffu: 14.228376 | Acc: 98.463451 (72091/73216)
(1643170502.7631934, 1643170625.9092073, 123.14601397514343)
Test epoch: 29| Acc: 94.91225369458128 (24662/25984) 

Epoch: 30
Train epoch:30 	Loss_in: 0.075571 | Loss_in_diffu: 12.781053 | Loss_out_diffu: 14.228915 | Acc: 98.486670 (72108/73216)
(1643170629.0465877, 1643170752.1047728, 123.05818510055542)
Test epoch: 30| Acc: 94.85452586206897 (24647/25984) 

Epoch: 31
Train epoch:31 	Loss_in: 0.074264 | Loss_in_diffu: 12.779548 | Loss_out_diffu: 14.229383 | Acc: 98.523547 (72135/73216)
(1643170755.2441442, 1643170877.2227578, 121.97861361503601)
Test epoch: 31| Acc: 94.86222290640394 (24649/25984) 

Epoch: 32
Train epoch:32 	Loss_in: 0.074081 | Loss_in_diffu: 12.779579 | Loss_out_diffu: 14.229530 | Acc: 98.541302 (72148/73216)
(1643170880.315057, 1643171002.4440594, 122.12900233268738)
Test epoch: 32| Acc: 94.86991995073892 (24651/25984) 

Epoch: 33
Train epoch:33 	Loss_in: 0.074131 | Loss_in_diffu: 12.779562 | Loss_out_diffu: 14.229897 | Acc: 98.533108 (72142/73216)
(1643171005.5263612, 1643171128.0656617, 122.53930044174194)
Test epoch: 33| Acc: 94.88916256157636 (24656/25984) 

Epoch: 34
Train epoch:34 	Loss_in: 0.073925 | Loss_in_diffu: 12.779603 | Loss_out_diffu: 14.229851 | Acc: 98.552229 (72156/73216)
(1643171131.1646824, 1643171254.0334613, 122.8687789440155)
Test epoch: 34| Acc: 94.86222290640394 (24649/25984) 

Epoch: 35
Train epoch:35 	Loss_in: 0.073969 | Loss_in_diffu: 12.779814 | Loss_out_diffu: 14.230101 | Acc: 98.550863 (72155/73216)
(1643171257.0353155, 1643171379.0914416, 122.0561261177063)
Test epoch: 35| Acc: 94.8737684729064 (24652/25984) 

Epoch: 36
Train epoch:36 	Loss_in: 0.073977 | Loss_in_diffu: 12.779495 | Loss_out_diffu: 14.230184 | Acc: 98.549497 (72154/73216)
(1643171382.056234, 1643171504.9509106, 122.89467668533325)
Test epoch: 36| Acc: 94.85067733990148 (24646/25984) 

Epoch: 37
Train epoch:37 	Loss_in: 0.073859 | Loss_in_diffu: 12.779434 | Loss_out_diffu: 14.230098 | Acc: 98.542668 (72149/73216)
(1643171507.9612367, 1643171630.4698138, 122.50857710838318)
Test epoch: 37| Acc: 94.86607142857143 (24650/25984) 

Epoch: 38
Train epoch:38 	Loss_in: 0.073715 | Loss_in_diffu: 12.779317 | Loss_out_diffu: 14.230283 | Acc: 98.546766 (72152/73216)
(1643171633.552421, 1643171755.6268847, 122.07446360588074)
Test epoch: 38| Acc: 94.86222290640394 (24649/25984) 

Epoch: 39
Train epoch:39 	Loss_in: 0.073576 | Loss_in_diffu: 12.779334 | Loss_out_diffu: 14.230170 | Acc: 98.546766 (72152/73216)
(1643171758.6149354, 1643171880.5734956, 121.95856022834778)
Test epoch: 39| Acc: 94.83913177339902 (24643/25984) 
