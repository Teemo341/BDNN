True
load data:  svhn
Building SVHN data loader with 1 workers
Using downloaded and verified file: /home/ssy/BDNN/data/svhn/train_32x32.mat
Using downloaded and verified file: /home/ssy/BDNN/data/svhn/test_32x32.mat
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 1.323812 | Loss_in_diffu: 12.388624 | Loss_out_diffu: 12.099109 | Acc: 55.613527 (40718/73216)
(1643176511.35456, 1643176636.059117, 124.70455718040466)
Test epoch: 0| Acc: 79.67980295566502 (20704/25984) 

Epoch: 1
Train epoch:1 	Loss_in: 0.542327 | Loss_in_diffu: 11.901013 | Loss_out_diffu: 12.774311 | Acc: 83.950229 (61465/73216)
(1643176639.0989697, 1643176762.6337717, 123.53480195999146)
Test epoch: 1| Acc: 86.76108374384236 (22544/25984) 

Epoch: 2
Train epoch:2 	Loss_in: 0.386362 | Loss_in_diffu: 11.900167 | Loss_out_diffu: 13.048759 | Acc: 88.568073 (64846/73216)
(1643176765.6465716, 1643176889.2427728, 123.59620118141174)
Test epoch: 2| Acc: 90.00538793103448 (23387/25984) 

Epoch: 3
Train epoch:3 	Loss_in: 0.320806 | Loss_in_diffu: 11.949288 | Loss_out_diffu: 13.222808 | Acc: 90.551246 (66298/73216)
(1643176892.2801356, 1643177016.323989, 124.04385328292847)
Test epoch: 3| Acc: 92.11052955665025 (23934/25984) 

Epoch: 4
Train epoch:4 	Loss_in: 0.289560 | Loss_in_diffu: 12.033490 | Loss_out_diffu: 13.356094 | Acc: 91.590636 (67059/73216)
(1643177019.3418417, 1643177143.1828384, 123.84099674224854)
Test epoch: 4| Acc: 93.38823891625616 (24266/25984) 

Epoch: 5
Train epoch:5 	Loss_in: 0.262032 | Loss_in_diffu: 12.117967 | Loss_out_diffu: 13.457837 | Acc: 92.382812 (67639/73216)
(1643177146.2242744, 1643177270.2540672, 124.02979278564453)
Test epoch: 5| Acc: 93.23044950738917 (24225/25984) 

Epoch: 6
Train epoch:6 	Loss_in: 0.243715 | Loss_in_diffu: 12.224454 | Loss_out_diffu: 13.573061 | Acc: 92.830802 (67967/73216)
(1643177273.27642, 1643177397.383535, 124.10711479187012)
Test epoch: 6| Acc: 91.8411330049261 (23864/25984) 

Epoch: 7
Train epoch:7 	Loss_in: 0.221262 | Loss_in_diffu: 12.323456 | Loss_out_diffu: 13.683998 | Acc: 93.624344 (68548/73216)
(1643177400.394233, 1643177524.176416, 123.78218293190002)
Test epoch: 7| Acc: 93.23814655172414 (24227/25984) 

Epoch: 8
Train epoch:8 	Loss_in: 0.209419 | Loss_in_diffu: 12.433716 | Loss_out_diffu: 13.821165 | Acc: 93.949410 (68786/73216)
(1643177527.1928535, 1643177650.8674817, 123.67462825775146)
Test epoch: 8| Acc: 93.4690578817734 (24287/25984) 

Epoch: 9
Train epoch:9 	Loss_in: 0.197719 | Loss_in_diffu: 12.550339 | Loss_out_diffu: 13.945051 | Acc: 94.292231 (69037/73216)
(1643177653.891399, 1643177778.0433826, 124.15198373794556)
Test epoch: 9| Acc: 93.6576354679803 (24336/25984) 

Epoch: 10
Train epoch:10 	Loss_in: 0.185231 | Loss_in_diffu: 12.664383 | Loss_out_diffu: 14.074790 | Acc: 94.752513 (69374/73216)
(1643177781.0938604, 1643177904.8837395, 123.78987908363342)
Test epoch: 10| Acc: 94.19258004926108 (24475/25984) 

Epoch: 11
Train epoch:11 	Loss_in: 0.122522 | Loss_in_diffu: 12.683430 | Loss_out_diffu: 14.135193 | Acc: 96.758905 (70843/73216)
(1643177907.892333, 1643178031.783652, 123.89131903648376)
Test epoch: 11| Acc: 95.13546798029557 (24720/25984) 

Epoch: 12
Train epoch:12 	Loss_in: 0.110492 | Loss_in_diffu: 12.674523 | Loss_out_diffu: 14.140561 | Acc: 97.194602 (71162/73216)
(1643178034.803731, 1643178158.6740015, 123.87027049064636)
Test epoch: 12| Acc: 95.32019704433498 (24768/25984) 

Epoch: 13
Train epoch:13 	Loss_in: 0.104129 | Loss_in_diffu: 12.671478 | Loss_out_diffu: 14.146346 | Acc: 97.395378 (71309/73216)
(1643178161.7300274, 1643178285.1854696, 123.45544219017029)
Test epoch: 13| Acc: 95.1893472906404 (24734/25984) 

Epoch: 14
Train epoch:14 	Loss_in: 0.098401 | Loss_in_diffu: 12.669691 | Loss_out_diffu: 14.152688 | Acc: 97.635763 (71485/73216)
(1643178288.2040899, 1643178412.7072518, 124.50316190719604)
Test epoch: 14| Acc: 95.12392241379311 (24717/25984) 

Epoch: 15
Train epoch:15 	Loss_in: 0.093537 | Loss_in_diffu: 12.668329 | Loss_out_diffu: 14.161071 | Acc: 97.742297 (71563/73216)
(1643178415.738257, 1643178539.2650177, 123.5267608165741)
Test epoch: 15| Acc: 95.15086206896552 (24724/25984) 

Epoch: 16
Train epoch:16 	Loss_in: 0.088432 | Loss_in_diffu: 12.667146 | Loss_out_diffu: 14.169017 | Acc: 97.899366 (71678/73216)
(1643178542.2918196, 1643178666.0757267, 123.78390717506409)
Test epoch: 16| Acc: 95.16625615763547 (24728/25984) 

Epoch: 17
Train epoch:17 	Loss_in: 0.083393 | Loss_in_diffu: 12.665217 | Loss_out_diffu: 14.173797 | Acc: 98.105605 (71829/73216)
(1643178669.131081, 1643178792.602649, 123.4715678691864)
Test epoch: 17| Acc: 94.8737684729064 (24652/25984) 

Epoch: 18
Train epoch:18 	Loss_in: 0.079522 | Loss_in_diffu: 12.664884 | Loss_out_diffu: 14.181882 | Acc: 98.235358 (71924/73216)
(1643178795.619515, 1643178919.1468263, 123.52731132507324)
Test epoch: 18| Acc: 95.1277709359606 (24718/25984) 

Epoch: 19
Train epoch:19 	Loss_in: 0.075260 | Loss_in_diffu: 12.664332 | Loss_out_diffu: 14.190698 | Acc: 98.348722 (72007/73216)
(1643178922.160366, 1643179045.6812892, 123.5209231376648)
Test epoch: 19| Acc: 95.00461822660098 (24686/25984) 

Epoch: 20
Train epoch:20 	Loss_in: 0.071410 | Loss_in_diffu: 12.663718 | Loss_out_diffu: 14.195591 | Acc: 98.474377 (72099/73216)
(1643179048.6891265, 1643179172.8723123, 124.18318581581116)
Test epoch: 20| Acc: 95.08928571428571 (24708/25984) 

Epoch: 21
Train epoch:21 	Loss_in: 0.061453 | Loss_in_diffu: 12.657359 | Loss_out_diffu: 14.193100 | Acc: 98.832222 (72361/73216)
(1643179175.9302611, 1643179300.427914, 124.49765276908875)
Test epoch: 21| Acc: 95.18549876847291 (24733/25984) 

Epoch: 22
Train epoch:22 	Loss_in: 0.060027 | Loss_in_diffu: 12.656394 | Loss_out_diffu: 14.194213 | Acc: 98.881392 (72397/73216)
(1643179303.4771695, 1643179427.08605, 123.60888051986694)
Test epoch: 22| Acc: 95.10852832512315 (24713/25984) 

Epoch: 23
Train epoch:23 	Loss_in: 0.059375 | Loss_in_diffu: 12.655814 | Loss_out_diffu: 14.194878 | Acc: 98.896416 (72408/73216)
(1643179430.1063218, 1643179553.877786, 123.77146410942078)
Test epoch: 23| Acc: 95.05080049261083 (24698/25984) 

Epoch: 24
Train epoch:24 	Loss_in: 0.058681 | Loss_in_diffu: 12.655304 | Loss_out_diffu: 14.195908 | Acc: 98.925098 (72429/73216)
(1643179556.9478436, 1643179681.3535695, 124.40572595596313)
Test epoch: 24| Acc: 95.08543719211822 (24707/25984) 

Epoch: 25
Train epoch:25 	Loss_in: 0.058145 | Loss_in_diffu: 12.654955 | Loss_out_diffu: 14.195958 | Acc: 98.948317 (72446/73216)
(1643179684.393007, 1643179808.4929252, 124.09991812705994)
Test epoch: 25| Acc: 95.00846674876847 (24687/25984) 

Epoch: 26
Train epoch:26 	Loss_in: 0.057554 | Loss_in_diffu: 12.655016 | Loss_out_diffu: 14.198204 | Acc: 98.944220 (72443/73216)
(1643179811.5608315, 1643179935.1548772, 123.59404563903809)
Test epoch: 26| Acc: 95.10467980295566 (24712/25984) 

Epoch: 27
Train epoch:27 	Loss_in: 0.057041 | Loss_in_diffu: 12.654691 | Loss_out_diffu: 14.198936 | Acc: 98.975634 (72466/73216)
(1643179938.175481, 1643180061.846196, 123.67071485519409)
Test epoch: 27| Acc: 95.09698275862068 (24710/25984) 

Epoch: 28
Train epoch:28 	Loss_in: 0.056393 | Loss_in_diffu: 12.653902 | Loss_out_diffu: 14.199243 | Acc: 99.001584 (72485/73216)
(1643180064.8691883, 1643180188.943368, 124.07417964935303)
Test epoch: 28| Acc: 95.05849753694581 (24700/25984) 

Epoch: 29
Train epoch:29 	Loss_in: 0.055987 | Loss_in_diffu: 12.653639 | Loss_out_diffu: 14.200261 | Acc: 99.005682 (72488/73216)
(1643180191.9635077, 1643180315.391601, 123.42809343338013)
Test epoch: 29| Acc: 95.00846674876847 (24687/25984) 

Epoch: 30
Train epoch:30 	Loss_in: 0.055530 | Loss_in_diffu: 12.653969 | Loss_out_diffu: 14.201278 | Acc: 99.009779 (72491/73216)
(1643180318.4076734, 1643180441.8070672, 123.39939379692078)
Test epoch: 30| Acc: 95.00461822660098 (24686/25984) 

Epoch: 31
Train epoch:31 	Loss_in: 0.054360 | Loss_in_diffu: 12.652663 | Loss_out_diffu: 14.201600 | Acc: 99.061681 (72529/73216)
(1643180444.8249564, 1643180568.6330495, 123.80809307098389)
Test epoch: 31| Acc: 95.05080049261083 (24698/25984) 

Epoch: 32
Train epoch:32 	Loss_in: 0.054220 | Loss_in_diffu: 12.652686 | Loss_out_diffu: 14.201731 | Acc: 99.057583 (72526/73216)
(1643180571.6416278, 1643180695.5750942, 123.93346643447876)
Test epoch: 32| Acc: 95.03540640394088 (24694/25984) 

Epoch: 33
Train epoch:33 	Loss_in: 0.054216 | Loss_in_diffu: 12.652689 | Loss_out_diffu: 14.201968 | Acc: 99.073973 (72538/73216)
(1643180698.5937486, 1643180822.0641131, 123.47036457061768)
Test epoch: 33| Acc: 95.02001231527093 (24690/25984) 

Epoch: 34
Train epoch:34 	Loss_in: 0.054106 | Loss_in_diffu: 12.652731 | Loss_out_diffu: 14.201897 | Acc: 99.060315 (72528/73216)
(1643180825.0832055, 1643180948.5486493, 123.4654438495636)
Test epoch: 34| Acc: 95.0315578817734 (24693/25984) 

Epoch: 35
Train epoch:35 	Loss_in: 0.054068 | Loss_in_diffu: 12.652893 | Loss_out_diffu: 14.202131 | Acc: 99.071241 (72536/73216)
(1643180951.58519, 1643181074.9751408, 123.3899507522583)
Test epoch: 35| Acc: 95.03540640394088 (24694/25984) 

Epoch: 36
Train epoch:36 	Loss_in: 0.054033 | Loss_in_diffu: 12.652611 | Loss_out_diffu: 14.202193 | Acc: 99.071241 (72536/73216)
(1643181078.0041196, 1643181201.8212824, 123.81716275215149)
Test epoch: 36| Acc: 95.01231527093596 (24688/25984) 

Epoch: 37
Train epoch:37 	Loss_in: 0.053939 | Loss_in_diffu: 12.652572 | Loss_out_diffu: 14.202181 | Acc: 99.069875 (72535/73216)
(1643181204.8885143, 1643181329.0427718, 124.15425753593445)
Test epoch: 37| Acc: 95.0315578817734 (24693/25984) 

Epoch: 38
Train epoch:38 	Loss_in: 0.053823 | Loss_in_diffu: 12.652412 | Loss_out_diffu: 14.202358 | Acc: 99.072607 (72537/73216)
(1643181332.0906396, 1643181456.250359, 124.15971946716309)
Test epoch: 38| Acc: 95.02001231527093 (24690/25984) 

Epoch: 39
Train epoch:39 	Loss_in: 0.053777 | Loss_in_diffu: 12.652476 | Loss_out_diffu: 14.202401 | Acc: 99.090363 (72550/73216)
(1643181459.2875884, 1643181583.340884, 124.0532956123352)
Test epoch: 39| Acc: 95.00461822660098 (24686/25984) 
