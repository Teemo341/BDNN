True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.535396 | Loss_out: 0.337817 | Acc: 82.274973 (49286/59904)
(1673152137.912194, 1673152151.7578435, 13.845649480819702)
Test epoch: 0| Acc: 98.22 (9822/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.067756 | Loss_out: 0.326295 | Acc: 98.130342 (58784/59904)
(1673152152.2044172, 1673152165.6122353, 13.407818078994751)
Test epoch: 1| Acc: 98.46 (9846/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.059987 | Loss_out: 0.326388 | Acc: 98.355702 (58919/59904)
(1673152166.0637033, 1673152179.4859807, 13.422277450561523)
Test epoch: 2| Acc: 98.86 (9886/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.050354 | Loss_out: 0.325993 | Acc: 98.589410 (59059/59904)
(1673152179.9238575, 1673152193.3810952, 13.457237720489502)
Test epoch: 3| Acc: 99.02 (9902/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.051312 | Loss_out: 0.325963 | Acc: 98.604434 (59068/59904)
(1673152193.8282583, 1673152207.2920184, 13.463760137557983)
Test epoch: 4| Acc: 99.0 (9900/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.052254 | Loss_out: 0.326094 | Acc: 98.604434 (59068/59904)
(1673152207.7433197, 1673152221.2079585, 13.464638710021973)
Test epoch: 5| Acc: 98.6 (9860/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.051723 | Loss_out: 0.325957 | Acc: 98.619458 (59077/59904)
(1673152221.6627944, 1673152235.1538339, 13.491039514541626)
Test epoch: 6| Acc: 99.21 (9921/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.049573 | Loss_out: 0.325935 | Acc: 98.652845 (59097/59904)
(1673152235.6068234, 1673152249.0711472, 13.46432375907898)
Test epoch: 7| Acc: 99.09 (9909/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.046062 | Loss_out: 0.325714 | Acc: 98.736311 (59147/59904)
(1673152249.5096202, 1673152262.97465, 13.4650297164917)
Test epoch: 8| Acc: 99.08 (9908/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.045274 | Loss_out: 0.325817 | Acc: 98.803085 (59187/59904)
(1673152263.4190974, 1673152276.8815498, 13.462452411651611)
Test epoch: 9| Acc: 99.03 (9903/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.045629 | Loss_out: 0.325758 | Acc: 98.806424 (59189/59904)
(1673152277.321759, 1673152290.7980654, 13.476306438446045)
Test epoch: 10| Acc: 98.92 (9892/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.017762 | Loss_out: 0.325137 | Acc: 99.577658 (59651/59904)
(1673152291.2353754, 1673152304.6962059, 13.460830450057983)
Test epoch: 11| Acc: 99.45 (9945/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.011490 | Loss_out: 0.325103 | Acc: 99.744591 (59751/59904)
(1673152305.14275, 1673152318.606309, 13.463558912277222)
Test epoch: 12| Acc: 99.39 (9939/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.008744 | Loss_out: 0.325098 | Acc: 99.834736 (59805/59904)
(1673152319.0528507, 1673152332.5126154, 13.4597647190094)
Test epoch: 13| Acc: 99.4 (9940/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.007147 | Loss_out: 0.325097 | Acc: 99.883146 (59834/59904)
(1673152332.9609435, 1673152346.4230075, 13.462064027786255)
Test epoch: 14| Acc: 99.55 (9955/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005791 | Loss_out: 0.325092 | Acc: 99.926549 (59860/59904)
(1673152346.8742993, 1673152360.336171, 13.46187162399292)
Test epoch: 15| Acc: 99.48 (9948/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004948 | Loss_out: 0.325092 | Acc: 99.938235 (59867/59904)
(1673152360.7763648, 1673152374.2372158, 13.460850954055786)
Test epoch: 16| Acc: 99.47 (9947/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004370 | Loss_out: 0.325090 | Acc: 99.956597 (59878/59904)
(1673152374.692422, 1673152388.1530027, 13.460580825805664)
Test epoch: 17| Acc: 99.5 (9950/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004108 | Loss_out: 0.325089 | Acc: 99.966613 (59884/59904)
(1673152388.592749, 1673152402.069603, 13.476853847503662)
Test epoch: 18| Acc: 99.5 (9950/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004086 | Loss_out: 0.325089 | Acc: 99.964944 (59883/59904)
(1673152402.5206246, 1673152415.9947538, 13.47412919998169)
Test epoch: 19| Acc: 99.43 (9943/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.005331 | Loss_out: 0.325090 | Acc: 99.926549 (59860/59904)
(1673152416.4404013, 1673152429.8956642, 13.455262899398804)
Test epoch: 20| Acc: 99.43 (9943/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.004619 | Loss_out: 0.325088 | Acc: 99.944912 (59871/59904)
(1673152430.3489075, 1673152443.8568573, 13.507949829101562)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.003706 | Loss_out: 0.325088 | Acc: 99.973291 (59888/59904)
(1673152444.3078218, 1673152457.7817085, 13.473886728286743)
Test epoch: 22| Acc: 99.5 (9950/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.003561 | Loss_out: 0.325087 | Acc: 99.978299 (59891/59904)
(1673152458.233689, 1673152471.7058446, 13.472155570983887)
Test epoch: 23| Acc: 99.49 (9949/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.003488 | Loss_out: 0.325087 | Acc: 99.979968 (59892/59904)
(1673152472.157089, 1673152485.5994694, 13.442380428314209)
Test epoch: 24| Acc: 99.49 (9949/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.003438 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152486.0388877, 1673152499.5072463, 13.468358516693115)
Test epoch: 25| Acc: 99.5 (9950/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.003393 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152499.9465406, 1673152513.4160342, 13.469493627548218)
Test epoch: 26| Acc: 99.5 (9950/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.003355 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152513.8677683, 1673152527.3395808, 13.47181248664856)
Test epoch: 27| Acc: 99.5 (9950/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.003311 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152527.7932622, 1673152541.2647436, 13.471481323242188)
Test epoch: 28| Acc: 99.5 (9950/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.003273 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152541.7132947, 1673152555.1789289, 13.465634107589722)
Test epoch: 29| Acc: 99.5 (9950/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.003217 | Loss_out: 0.325087 | Acc: 99.981637 (59893/59904)
(1673152555.6220107, 1673152569.091233, 13.4692223072052)
Test epoch: 30| Acc: 99.49 (9949/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.003156 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152569.5316305, 1673152582.9967961, 13.465165615081787)
Test epoch: 31| Acc: 99.49 (9949/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.003151 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152583.446068, 1673152596.85685, 13.410781860351562)
Test epoch: 32| Acc: 99.49 (9949/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.003146 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152597.2962797, 1673152610.693658, 13.39737844467163)
Test epoch: 33| Acc: 99.49 (9949/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.003142 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152611.1332417, 1673152624.545984, 13.412742376327515)
Test epoch: 34| Acc: 99.49 (9949/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.003137 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152624.9983745, 1673152638.4030778, 13.404703378677368)
Test epoch: 35| Acc: 99.49 (9949/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.003131 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152638.8437934, 1673152652.248238, 13.404444694519043)
Test epoch: 36| Acc: 99.49 (9949/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.003128 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152652.7002833, 1673152666.111058, 13.41077470779419)
Test epoch: 37| Acc: 99.49 (9949/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.003123 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152666.5651426, 1673152679.9642415, 13.399098873138428)
Test epoch: 38| Acc: 99.49 (9949/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.003120 | Loss_out: 0.325087 | Acc: 99.983307 (59894/59904)
(1673152680.4164276, 1673152693.8226235, 13.406195878982544)
Test epoch: 39| Acc: 99.49 (9949/10000) 
