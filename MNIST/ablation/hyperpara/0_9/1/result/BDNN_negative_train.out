True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.658326 | Loss_in_diffu: 11.583086 | Loss_out_diffu: 12.046954 | Acc: 84.954260 (50891/59904)
(1679153545.7772505, 1679153644.0651085, 98.28785800933838)
Test epoch: 0| Acc: 95.96 (9596/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.113991 | Loss_in_diffu: 11.002168 | Loss_out_diffu: 12.394389 | Acc: 97.003539 (58109/59904)
(1679153644.6430068, 1679153742.526895, 97.8838882446289)
Test epoch: 1| Acc: 97.81 (9781/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.076071 | Loss_in_diffu: 10.871157 | Loss_out_diffu: 12.402848 | Acc: 97.923344 (58660/59904)
(1679153743.0888233, 1679153841.299569, 98.21074557304382)
Test epoch: 2| Acc: 98.08 (9808/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.056731 | Loss_in_diffu: 10.738131 | Loss_out_diffu: 12.326777 | Acc: 98.357372 (58920/59904)
(1679153841.8659596, 1679153939.514885, 97.64892530441284)
Test epoch: 3| Acc: 98.45 (9845/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049022 | Loss_in_diffu: 10.607483 | Loss_out_diffu: 12.226994 | Acc: 98.584402 (59056/59904)
(1679153940.091233, 1679154038.0066676, 97.91543459892273)
Test epoch: 4| Acc: 98.63 (9863/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.043614 | Loss_in_diffu: 10.475124 | Loss_out_diffu: 12.096157 | Acc: 98.746327 (59153/59904)
(1679154038.5863347, 1679154136.9584835, 98.37214875221252)
Test epoch: 5| Acc: 98.11 (9811/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037580 | Loss_in_diffu: 10.332225 | Loss_out_diffu: 11.970771 | Acc: 98.919939 (59257/59904)
(1679154137.5363855, 1679154236.1084707, 98.57208514213562)
Test epoch: 6| Acc: 99.21 (9921/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.035726 | Loss_in_diffu: 10.198192 | Loss_out_diffu: 11.854739 | Acc: 98.951656 (59276/59904)
(1679154236.6871758, 1679154335.6056461, 98.91847038269043)
Test epoch: 7| Acc: 98.58 (9858/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.029357 | Loss_in_diffu: 10.063870 | Loss_out_diffu: 11.740273 | Acc: 99.126936 (59381/59904)
(1679154336.1719582, 1679154434.3246558, 98.15269756317139)
Test epoch: 8| Acc: 98.68 (9868/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.028880 | Loss_in_diffu: 9.941454 | Loss_out_diffu: 11.634935 | Acc: 99.160323 (59401/59904)
(1679154434.8890424, 1679154533.110869, 98.22182655334473)
Test epoch: 9| Acc: 98.91 (9891/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026810 | Loss_in_diffu: 9.824893 | Loss_out_diffu: 11.518804 | Acc: 99.245459 (59452/59904)
(1679154533.6745806, 1679154631.4940994, 97.81951880455017)
Test epoch: 10| Acc: 99.07 (9907/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009797 | Loss_in_diffu: 9.742846 | Loss_out_diffu: 11.497600 | Acc: 99.721221 (59737/59904)
(1679154632.0707672, 1679154730.5331237, 98.46235656738281)
Test epoch: 11| Acc: 99.49 (9949/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006859 | Loss_in_diffu: 9.716081 | Loss_out_diffu: 11.476833 | Acc: 99.816373 (59794/59904)
(1679154731.1029418, 1679154829.3836067, 98.28066492080688)
Test epoch: 12| Acc: 99.48 (9948/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005735 | Loss_in_diffu: 9.687337 | Loss_out_diffu: 11.458244 | Acc: 99.863114 (59822/59904)
(1679154829.948712, 1679154928.8993242, 98.95061206817627)
Test epoch: 13| Acc: 99.45 (9945/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004926 | Loss_in_diffu: 9.656624 | Loss_out_diffu: 11.435309 | Acc: 99.881477 (59833/59904)
(1679154929.4806192, 1679155028.2515993, 98.7709801197052)
Test epoch: 14| Acc: 99.5 (9950/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004680 | Loss_in_diffu: 9.625910 | Loss_out_diffu: 11.413977 | Acc: 99.879808 (59832/59904)
(1679155028.832893, 1679155126.8086812, 97.97578835487366)
Test epoch: 15| Acc: 99.49 (9949/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003608 | Loss_in_diffu: 9.594312 | Loss_out_diffu: 11.394820 | Acc: 99.929888 (59862/59904)
(1679155127.3724296, 1679155226.8850985, 99.51266884803772)
Test epoch: 16| Acc: 99.5 (9950/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003601 | Loss_in_diffu: 9.563078 | Loss_out_diffu: 11.373123 | Acc: 99.909856 (59850/59904)
(1679155227.4709172, 1679155325.4973457, 98.02642846107483)
Test epoch: 17| Acc: 99.4 (9940/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003213 | Loss_in_diffu: 9.533028 | Loss_out_diffu: 11.353226 | Acc: 99.934896 (59865/59904)
(1679155326.0755973, 1679155424.418552, 98.34295463562012)
Test epoch: 18| Acc: 99.45 (9945/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002785 | Loss_in_diffu: 9.504957 | Loss_out_diffu: 11.331375 | Acc: 99.938235 (59867/59904)
(1679155424.9971173, 1679155523.3521426, 98.35502529144287)
Test epoch: 19| Acc: 99.16 (9916/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002395 | Loss_in_diffu: 9.475975 | Loss_out_diffu: 11.314531 | Acc: 99.951589 (59875/59904)
(1679155523.9306195, 1679155621.8121536, 97.88153409957886)
Test epoch: 20| Acc: 99.48 (9948/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001516 | Loss_in_diffu: 9.459845 | Loss_out_diffu: 11.305283 | Acc: 99.979968 (59892/59904)
(1679155622.3942575, 1679155720.7580018, 98.36374425888062)
Test epoch: 21| Acc: 99.55 (9955/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001354 | Loss_in_diffu: 9.456136 | Loss_out_diffu: 11.303030 | Acc: 99.983307 (59894/59904)
(1679155721.3348634, 1679155820.274323, 98.93945956230164)
Test epoch: 22| Acc: 99.56 (9956/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001340 | Loss_in_diffu: 9.452701 | Loss_out_diffu: 11.300422 | Acc: 99.979968 (59892/59904)
(1679155820.8496053, 1679155919.6779854, 98.82838010787964)
Test epoch: 23| Acc: 99.55 (9955/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001253 | Loss_in_diffu: 9.448015 | Loss_out_diffu: 11.297780 | Acc: 99.986645 (59896/59904)
(1679155920.2478456, 1679156018.5586147, 98.31076908111572)
Test epoch: 24| Acc: 99.58 (9958/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001217 | Loss_in_diffu: 9.443832 | Loss_out_diffu: 11.294773 | Acc: 99.988315 (59897/59904)
(1679156019.1344647, 1679156116.9059126, 97.7714478969574)
Test epoch: 25| Acc: 99.55 (9955/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001188 | Loss_in_diffu: 9.438873 | Loss_out_diffu: 11.291806 | Acc: 99.988315 (59897/59904)
(1679156117.4827387, 1679156215.1920435, 97.70930480957031)
Test epoch: 26| Acc: 99.56 (9956/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001135 | Loss_in_diffu: 9.434595 | Loss_out_diffu: 11.288704 | Acc: 99.986645 (59896/59904)
(1679156215.7590868, 1679156313.5004544, 97.74136757850647)
Test epoch: 27| Acc: 99.54 (9954/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001072 | Loss_in_diffu: 9.429699 | Loss_out_diffu: 11.286118 | Acc: 99.991653 (59899/59904)
(1679156314.0773408, 1679156411.8008661, 97.72352528572083)
Test epoch: 28| Acc: 99.57 (9957/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001036 | Loss_in_diffu: 9.425159 | Loss_out_diffu: 11.283049 | Acc: 99.988315 (59897/59904)
(1679156412.3659766, 1679156510.1868892, 97.8209125995636)
Test epoch: 29| Acc: 99.57 (9957/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.000983 | Loss_in_diffu: 9.420518 | Loss_out_diffu: 11.280854 | Acc: 99.989984 (59898/59904)
(1679156510.7654994, 1679156609.3910663, 98.6255669593811)
Test epoch: 30| Acc: 99.55 (9955/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.000921 | Loss_in_diffu: 9.417833 | Loss_out_diffu: 11.279380 | Acc: 99.993323 (59900/59904)
(1679156609.9723141, 1679156708.4617934, 98.48947930335999)
Test epoch: 31| Acc: 99.56 (9956/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.000909 | Loss_in_diffu: 9.417670 | Loss_out_diffu: 11.279589 | Acc: 99.993323 (59900/59904)
(1679156709.0326579, 1679156807.436641, 98.4039831161499)
Test epoch: 32| Acc: 99.55 (9955/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.000911 | Loss_in_diffu: 9.417048 | Loss_out_diffu: 11.279223 | Acc: 99.993323 (59900/59904)
(1679156808.015892, 1679156906.0798223, 98.06393027305603)
Test epoch: 33| Acc: 99.54 (9954/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.000903 | Loss_in_diffu: 9.416469 | Loss_out_diffu: 11.278906 | Acc: 99.993323 (59900/59904)
(1679156906.651868, 1679157004.6461825, 97.99431443214417)
Test epoch: 34| Acc: 99.56 (9956/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.000899 | Loss_in_diffu: 9.416143 | Loss_out_diffu: 11.279020 | Acc: 99.993323 (59900/59904)
(1679157005.2101927, 1679157103.5787437, 98.36855101585388)
Test epoch: 35| Acc: 99.56 (9956/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.000898 | Loss_in_diffu: 9.415459 | Loss_out_diffu: 11.278767 | Acc: 99.993323 (59900/59904)
(1679157104.14434, 1679157201.9210691, 97.77672910690308)
Test epoch: 36| Acc: 99.55 (9955/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.000893 | Loss_in_diffu: 9.414593 | Loss_out_diffu: 11.278398 | Acc: 99.993323 (59900/59904)
(1679157202.4852436, 1679157300.147759, 97.66251540184021)
Test epoch: 37| Acc: 99.59 (9959/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.000885 | Loss_in_diffu: 9.414238 | Loss_out_diffu: 11.278538 | Acc: 99.993323 (59900/59904)
(1679157300.7312274, 1679157398.5095515, 97.77832412719727)
Test epoch: 38| Acc: 99.54 (9954/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.000884 | Loss_in_diffu: 9.413902 | Loss_out_diffu: 11.278326 | Acc: 99.993323 (59900/59904)
(1679157399.0888784, 1679157497.2432456, 98.15436720848083)
Test epoch: 39| Acc: 99.54 (9954/10000) 
