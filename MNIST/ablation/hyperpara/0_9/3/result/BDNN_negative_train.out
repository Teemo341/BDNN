True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.727285 | Loss_in_diffu: 11.663650 | Loss_out_diffu: 11.994582 | Acc: 82.904314 (49663/59904)
(1679154535.4052885, 1679154633.4138784, 98.00858998298645)
Test epoch: 0| Acc: 96.19 (9619/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.124381 | Loss_in_diffu: 11.042632 | Loss_out_diffu: 12.352515 | Acc: 96.756477 (57961/59904)
(1679154633.9888291, 1679154730.5786185, 96.58978939056396)
Test epoch: 1| Acc: 96.9 (9690/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.080893 | Loss_in_diffu: 10.913365 | Loss_out_diffu: 12.353308 | Acc: 97.744725 (58553/59904)
(1679154731.167285, 1679154828.3873417, 97.22005677223206)
Test epoch: 2| Acc: 97.48 (9748/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.060583 | Loss_in_diffu: 10.787322 | Loss_out_diffu: 12.271883 | Acc: 98.273905 (58870/59904)
(1679154828.9621937, 1679154925.6040008, 96.64180707931519)
Test epoch: 3| Acc: 98.16 (9816/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049597 | Loss_in_diffu: 10.655171 | Loss_out_diffu: 12.189104 | Acc: 98.606103 (59069/59904)
(1679154926.189666, 1679155023.0940855, 96.90441942214966)
Test epoch: 4| Acc: 99.22 (9922/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.045664 | Loss_in_diffu: 10.516734 | Loss_out_diffu: 12.044200 | Acc: 98.636151 (59087/59904)
(1679155023.6836634, 1679155121.3996775, 97.71601414680481)
Test epoch: 5| Acc: 98.77 (9877/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037692 | Loss_in_diffu: 10.373585 | Loss_out_diffu: 11.914454 | Acc: 98.906584 (59249/59904)
(1679155121.987453, 1679155219.5413003, 97.55384731292725)
Test epoch: 6| Acc: 98.69 (9869/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.036019 | Loss_in_diffu: 10.241554 | Loss_out_diffu: 11.790982 | Acc: 98.906584 (59249/59904)
(1679155220.1287084, 1679155316.887358, 96.75864958763123)
Test epoch: 7| Acc: 99.05 (9905/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.031633 | Loss_in_diffu: 10.115549 | Loss_out_diffu: 11.863190 | Acc: 99.085203 (59356/59904)
(1679155317.4787982, 1679155414.1922965, 96.71349835395813)
Test epoch: 8| Acc: 99.08 (9908/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.030558 | Loss_in_diffu: 9.987608 | Loss_out_diffu: 11.767224 | Acc: 99.093550 (59361/59904)
(1679155414.7795768, 1679155511.3642838, 96.58470702171326)
Test epoch: 9| Acc: 99.01 (9901/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026310 | Loss_in_diffu: 9.849707 | Loss_out_diffu: 11.666980 | Acc: 99.198718 (59424/59904)
(1679155511.950736, 1679155609.184123, 97.2333869934082)
Test epoch: 10| Acc: 99.15 (9915/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009465 | Loss_in_diffu: 9.764253 | Loss_out_diffu: 11.623125 | Acc: 99.764623 (59763/59904)
(1679155609.7707942, 1679155706.9450974, 97.17430329322815)
Test epoch: 11| Acc: 99.53 (9953/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006972 | Loss_in_diffu: 9.736257 | Loss_out_diffu: 11.605376 | Acc: 99.808026 (59789/59904)
(1679155707.5337307, 1679155805.1826031, 97.64887237548828)
Test epoch: 12| Acc: 99.46 (9946/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005970 | Loss_in_diffu: 9.705798 | Loss_out_diffu: 11.585075 | Acc: 99.864784 (59823/59904)
(1679155805.758325, 1679155903.2849784, 97.52665328979492)
Test epoch: 13| Acc: 99.47 (9947/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005294 | Loss_in_diffu: 9.672721 | Loss_out_diffu: 11.558165 | Acc: 99.874800 (59829/59904)
(1679155903.8785868, 1679156001.1037376, 97.22515082359314)
Test epoch: 14| Acc: 99.49 (9949/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005169 | Loss_in_diffu: 9.639841 | Loss_out_diffu: 11.536472 | Acc: 99.854768 (59817/59904)
(1679156001.691523, 1679156098.1938407, 96.50231766700745)
Test epoch: 15| Acc: 99.49 (9949/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004178 | Loss_in_diffu: 9.607177 | Loss_out_diffu: 11.513510 | Acc: 99.896501 (59842/59904)
(1679156098.7713714, 1679156195.8115392, 97.04016780853271)
Test epoch: 16| Acc: 99.49 (9949/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004144 | Loss_in_diffu: 9.575216 | Loss_out_diffu: 11.490755 | Acc: 99.898170 (59843/59904)
(1679156196.3990662, 1679156292.8174016, 96.41833543777466)
Test epoch: 17| Acc: 99.44 (9944/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003956 | Loss_in_diffu: 9.544839 | Loss_out_diffu: 11.473485 | Acc: 99.898170 (59843/59904)
(1679156293.4022553, 1679156389.795823, 96.39356780052185)
Test epoch: 18| Acc: 99.55 (9955/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003408 | Loss_in_diffu: 9.516359 | Loss_out_diffu: 11.453448 | Acc: 99.916533 (59854/59904)
(1679156390.3719277, 1679156486.8270817, 96.45515394210815)
Test epoch: 19| Acc: 99.51 (9951/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002938 | Loss_in_diffu: 9.487359 | Loss_out_diffu: 11.439388 | Acc: 99.929888 (59862/59904)
(1679156487.4125276, 1679156584.1431086, 96.73058104515076)
Test epoch: 20| Acc: 99.42 (9942/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001956 | Loss_in_diffu: 9.471485 | Loss_out_diffu: 11.429536 | Acc: 99.964944 (59883/59904)
(1679156584.731592, 1679156681.4768658, 96.74527382850647)
Test epoch: 21| Acc: 99.58 (9958/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001650 | Loss_in_diffu: 9.467892 | Loss_out_diffu: 11.427597 | Acc: 99.979968 (59892/59904)
(1679156682.0655892, 1679156779.4162557, 97.35066652297974)
Test epoch: 22| Acc: 99.55 (9955/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001568 | Loss_in_diffu: 9.464584 | Loss_out_diffu: 11.425171 | Acc: 99.979968 (59892/59904)
(1679156779.99663, 1679156877.2603135, 97.26368355751038)
Test epoch: 23| Acc: 99.57 (9957/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001479 | Loss_in_diffu: 9.459973 | Loss_out_diffu: 11.422410 | Acc: 99.983307 (59894/59904)
(1679156877.8359082, 1679156974.9770236, 97.14111542701721)
Test epoch: 24| Acc: 99.56 (9956/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001422 | Loss_in_diffu: 9.455786 | Loss_out_diffu: 11.419928 | Acc: 99.984976 (59895/59904)
(1679156975.5523307, 1679157072.2744288, 96.72209811210632)
Test epoch: 25| Acc: 99.55 (9955/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001397 | Loss_in_diffu: 9.450764 | Loss_out_diffu: 11.416847 | Acc: 99.983307 (59894/59904)
(1679157072.8613727, 1679157170.4766078, 97.61523509025574)
Test epoch: 26| Acc: 99.55 (9955/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001366 | Loss_in_diffu: 9.446421 | Loss_out_diffu: 11.413781 | Acc: 99.981637 (59893/59904)
(1679157171.0646107, 1679157268.3816738, 97.31706309318542)
Test epoch: 27| Acc: 99.52 (9952/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001311 | Loss_in_diffu: 9.441428 | Loss_out_diffu: 11.411463 | Acc: 99.984976 (59895/59904)
(1679157268.9612439, 1679157365.6409974, 96.67975354194641)
Test epoch: 28| Acc: 99.53 (9953/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001284 | Loss_in_diffu: 9.436756 | Loss_out_diffu: 11.408174 | Acc: 99.986645 (59896/59904)
(1679157366.2174375, 1679157462.9206467, 96.70320916175842)
Test epoch: 29| Acc: 99.56 (9956/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001245 | Loss_in_diffu: 9.431900 | Loss_out_diffu: 11.406028 | Acc: 99.984976 (59895/59904)
(1679157463.5039203, 1679157560.7303145, 97.22639417648315)
Test epoch: 30| Acc: 99.56 (9956/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001176 | Loss_in_diffu: 9.429106 | Loss_out_diffu: 11.404622 | Acc: 99.988315 (59897/59904)
(1679157561.3085558, 1679157657.956971, 96.64841508865356)
Test epoch: 31| Acc: 99.54 (9954/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001156 | Loss_in_diffu: 9.428933 | Loss_out_diffu: 11.404704 | Acc: 99.988315 (59897/59904)
(1679157658.5438297, 1679157755.2445714, 96.7007417678833)
Test epoch: 32| Acc: 99.54 (9954/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001161 | Loss_in_diffu: 9.428300 | Loss_out_diffu: 11.404450 | Acc: 99.988315 (59897/59904)
(1679157755.8286598, 1679157852.4615111, 96.6328513622284)
Test epoch: 33| Acc: 99.56 (9956/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001149 | Loss_in_diffu: 9.427708 | Loss_out_diffu: 11.404309 | Acc: 99.988315 (59897/59904)
(1679157853.0502756, 1679157950.186088, 97.13581252098083)
Test epoch: 34| Acc: 99.53 (9953/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001145 | Loss_in_diffu: 9.427391 | Loss_out_diffu: 11.404176 | Acc: 99.988315 (59897/59904)
(1679157950.7721007, 1679158047.4864388, 96.71433806419373)
Test epoch: 35| Acc: 99.54 (9954/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001146 | Loss_in_diffu: 9.426701 | Loss_out_diffu: 11.403906 | Acc: 99.988315 (59897/59904)
(1679158048.061909, 1679158145.135954, 97.07404494285583)
Test epoch: 36| Acc: 99.54 (9954/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001145 | Loss_in_diffu: 9.425842 | Loss_out_diffu: 11.403554 | Acc: 99.988315 (59897/59904)
(1679158145.712119, 1679158242.3602998, 96.64818072319031)
Test epoch: 37| Acc: 99.54 (9954/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001138 | Loss_in_diffu: 9.425484 | Loss_out_diffu: 11.403715 | Acc: 99.988315 (59897/59904)
(1679158242.9347303, 1679158339.5528526, 96.61812233924866)
Test epoch: 38| Acc: 99.54 (9954/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001131 | Loss_in_diffu: 9.425145 | Loss_out_diffu: 11.403192 | Acc: 99.988315 (59897/59904)
(1679158340.128073, 1679158436.7794685, 96.65139555931091)
Test epoch: 39| Acc: 99.54 (9954/10000) 
