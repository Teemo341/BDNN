True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.653423 | Loss_in_diffu: 11.574901 | Loss_out_diffu: 12.049048 | Acc: 85.074452 (50963/59904)
(1679153452.401311, 1679153686.1824374, 233.78112649917603)
Test epoch: 0| Acc: 96.91 (9691/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.113455 | Loss_in_diffu: 10.996105 | Loss_out_diffu: 12.367037 | Acc: 97.035256 (58128/59904)
(1679153687.3321779, 1679153916.5277255, 229.195547580719)
Test epoch: 1| Acc: 98.03 (9803/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.073559 | Loss_in_diffu: 10.860943 | Loss_out_diffu: 12.339055 | Acc: 97.980101 (58694/59904)
(1679153917.6660585, 1679154147.391258, 229.72519946098328)
Test epoch: 2| Acc: 98.28 (9828/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.057480 | Loss_in_diffu: 10.728695 | Loss_out_diffu: 12.249001 | Acc: 98.384081 (58936/59904)
(1679154148.5268948, 1679154379.5963774, 231.06948256492615)
Test epoch: 3| Acc: 99.0 (9900/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048110 | Loss_in_diffu: 10.595887 | Loss_out_diffu: 12.132538 | Acc: 98.627804 (59082/59904)
(1679154380.7506225, 1679154615.3063312, 234.5557086467743)
Test epoch: 4| Acc: 98.84 (9884/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.042450 | Loss_in_diffu: 10.458269 | Loss_out_diffu: 11.983992 | Acc: 98.773037 (59169/59904)
(1679154616.4564807, 1679154845.570314, 229.11383318901062)
Test epoch: 5| Acc: 99.08 (9908/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037321 | Loss_in_diffu: 10.319988 | Loss_out_diffu: 11.882955 | Acc: 98.898237 (59244/59904)
(1679154846.7257712, 1679155078.6413577, 231.91558647155762)
Test epoch: 6| Acc: 99.05 (9905/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.034162 | Loss_in_diffu: 10.192508 | Loss_out_diffu: 11.777514 | Acc: 98.966680 (59285/59904)
(1679155079.847248, 1679155308.965761, 229.11851286888123)
Test epoch: 7| Acc: 99.07 (9907/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.029188 | Loss_in_diffu: 10.064147 | Loss_out_diffu: 11.682621 | Acc: 99.153646 (59397/59904)
(1679155310.1016407, 1679155545.315489, 235.21384835243225)
Test epoch: 8| Acc: 99.1 (9910/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.029658 | Loss_in_diffu: 9.936706 | Loss_out_diffu: 11.696764 | Acc: 99.103566 (59367/59904)
(1679155546.4601974, 1679155775.5449142, 229.084716796875)
Test epoch: 9| Acc: 99.0 (9900/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026291 | Loss_in_diffu: 9.805888 | Loss_out_diffu: 11.578607 | Acc: 99.255475 (59458/59904)
(1679155776.686578, 1679156007.4583828, 230.7718048095703)
Test epoch: 10| Acc: 98.56 (9856/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009820 | Loss_in_diffu: 9.719255 | Loss_out_diffu: 11.550776 | Acc: 99.727898 (59741/59904)
(1679156008.5908182, 1679156238.8747852, 230.28396701812744)
Test epoch: 11| Acc: 99.57 (9957/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006978 | Loss_in_diffu: 9.691510 | Loss_out_diffu: 11.524444 | Acc: 99.813034 (59792/59904)
(1679156240.0164747, 1679156470.9009738, 230.88449907302856)
Test epoch: 12| Acc: 99.55 (9955/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006030 | Loss_in_diffu: 9.662064 | Loss_out_diffu: 11.500884 | Acc: 99.853098 (59816/59904)
(1679156472.0315871, 1679156703.427315, 231.3957278728485)
Test epoch: 13| Acc: 99.49 (9949/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005342 | Loss_in_diffu: 9.630589 | Loss_out_diffu: 11.470697 | Acc: 99.873130 (59828/59904)
(1679156704.572133, 1679156934.2795238, 229.70739078521729)
Test epoch: 14| Acc: 99.5 (9950/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004692 | Loss_in_diffu: 9.598651 | Loss_out_diffu: 11.445029 | Acc: 99.889824 (59838/59904)
(1679156935.401542, 1679157166.0056398, 230.60409784317017)
Test epoch: 15| Acc: 99.48 (9948/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004260 | Loss_in_diffu: 9.567262 | Loss_out_diffu: 11.416021 | Acc: 99.893162 (59840/59904)
(1679157167.154334, 1679157399.119918, 231.9655840396881)
Test epoch: 16| Acc: 99.56 (9956/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003826 | Loss_in_diffu: 9.535647 | Loss_out_diffu: 11.391857 | Acc: 99.918202 (59855/59904)
(1679157400.2801018, 1679157633.1252, 232.84509825706482)
Test epoch: 17| Acc: 99.51 (9951/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003401 | Loss_in_diffu: 9.505734 | Loss_out_diffu: 11.376917 | Acc: 99.913194 (59852/59904)
(1679157634.2441058, 1679157820.924182, 186.68007612228394)
Test epoch: 18| Acc: 99.46 (9946/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002547 | Loss_in_diffu: 9.477276 | Loss_out_diffu: 11.351649 | Acc: 99.951589 (59875/59904)
(1679157822.0133288, 1679158052.2442977, 230.23096895217896)
Test epoch: 19| Acc: 99.44 (9944/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002992 | Loss_in_diffu: 9.447183 | Loss_out_diffu: 11.330085 | Acc: 99.933226 (59864/59904)
(1679158053.3330932, 1679158194.6276298, 141.29453659057617)
Test epoch: 20| Acc: 99.5 (9950/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001780 | Loss_in_diffu: 9.431102 | Loss_out_diffu: 11.320445 | Acc: 99.971621 (59887/59904)
(1679158195.7815409, 1679158365.3031979, 169.52165699005127)
Test epoch: 21| Acc: 99.53 (9953/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001464 | Loss_in_diffu: 9.427489 | Loss_out_diffu: 11.317549 | Acc: 99.976629 (59890/59904)
(1679158366.45765, 1679158597.252523, 230.79487299919128)
Test epoch: 22| Acc: 99.54 (9954/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001414 | Loss_in_diffu: 9.424297 | Loss_out_diffu: 11.314785 | Acc: 99.978299 (59891/59904)
(1679158598.389852, 1679158816.901883, 218.51203083992004)
Test epoch: 23| Acc: 99.49 (9949/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001328 | Loss_in_diffu: 9.419861 | Loss_out_diffu: 11.311320 | Acc: 99.984976 (59895/59904)
(1679158818.0400293, 1679159051.5522807, 233.5122513771057)
Test epoch: 24| Acc: 99.55 (9955/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001272 | Loss_in_diffu: 9.415886 | Loss_out_diffu: 11.308218 | Acc: 99.984976 (59895/59904)
(1679159052.7766395, 1679159281.0552952, 228.2786557674408)
Test epoch: 25| Acc: 99.53 (9953/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001223 | Loss_in_diffu: 9.411079 | Loss_out_diffu: 11.304361 | Acc: 99.986645 (59896/59904)
(1679159282.1856713, 1679159512.2091508, 230.02347946166992)
Test epoch: 26| Acc: 99.52 (9952/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001190 | Loss_in_diffu: 9.406970 | Loss_out_diffu: 11.300819 | Acc: 99.986645 (59896/59904)
(1679159513.3640082, 1679159739.8480413, 226.48403310775757)
Test epoch: 27| Acc: 99.54 (9954/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001142 | Loss_in_diffu: 9.402229 | Loss_out_diffu: 11.297726 | Acc: 99.986645 (59896/59904)
(1679159740.9227693, 1679159973.239458, 232.31668877601624)
Test epoch: 28| Acc: 99.53 (9953/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001090 | Loss_in_diffu: 9.397762 | Loss_out_diffu: 11.293791 | Acc: 99.989984 (59898/59904)
(1679159974.38648, 1679160203.7786686, 229.39218854904175)
Test epoch: 29| Acc: 99.52 (9952/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001059 | Loss_in_diffu: 9.393159 | Loss_out_diffu: 11.290754 | Acc: 99.989984 (59898/59904)
(1679160204.905146, 1679160436.3831043, 231.47795844078064)
Test epoch: 30| Acc: 99.52 (9952/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.000987 | Loss_in_diffu: 9.390473 | Loss_out_diffu: 11.288819 | Acc: 99.991653 (59899/59904)
(1679160437.5150864, 1679160668.7580125, 231.24292612075806)
Test epoch: 31| Acc: 99.53 (9953/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.000984 | Loss_in_diffu: 9.390308 | Loss_out_diffu: 11.288980 | Acc: 99.991653 (59899/59904)
(1679160669.8694465, 1679160900.4297464, 230.56029987335205)
Test epoch: 32| Acc: 99.51 (9951/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.000980 | Loss_in_diffu: 9.389703 | Loss_out_diffu: 11.288547 | Acc: 99.991653 (59899/59904)
(1679160901.5726378, 1679161130.1329238, 228.56028604507446)
Test epoch: 33| Acc: 99.5 (9950/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.000974 | Loss_in_diffu: 9.389129 | Loss_out_diffu: 11.288255 | Acc: 99.991653 (59899/59904)
(1679161131.2509701, 1679161267.8076959, 136.55672574043274)
Test epoch: 34| Acc: 99.54 (9954/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.000968 | Loss_in_diffu: 9.388827 | Loss_out_diffu: 11.288003 | Acc: 99.991653 (59899/59904)
(1679161268.9439273, 1679161405.7640936, 136.820166349411)
Test epoch: 35| Acc: 99.53 (9953/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.000962 | Loss_in_diffu: 9.388161 | Loss_out_diffu: 11.287714 | Acc: 99.991653 (59899/59904)
(1679161406.8956494, 1679161543.6572194, 136.76156997680664)
Test epoch: 36| Acc: 99.54 (9954/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.000967 | Loss_in_diffu: 9.387314 | Loss_out_diffu: 11.287357 | Acc: 99.991653 (59899/59904)
(1679161544.696276, 1679161776.6226301, 231.92635416984558)
Test epoch: 37| Acc: 99.53 (9953/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.000960 | Loss_in_diffu: 9.386977 | Loss_out_diffu: 11.287360 | Acc: 99.991653 (59899/59904)
(1679161777.761844, 1679162011.0127378, 233.25089383125305)
Test epoch: 38| Acc: 99.53 (9953/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.000954 | Loss_in_diffu: 9.386648 | Loss_out_diffu: 11.286847 | Acc: 99.991653 (59899/59904)
(1679162012.092506, 1679162244.0709217, 231.97841572761536)
Test epoch: 39| Acc: 99.52 (9952/10000) 
