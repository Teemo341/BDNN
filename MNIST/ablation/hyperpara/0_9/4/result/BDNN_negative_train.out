True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.676607 | Loss_in_diffu: 11.606346 | Loss_out_diffu: 12.004022 | Acc: 84.551950 (50650/59904)
(1679154599.7706642, 1679154692.885639, 93.11497473716736)
Test epoch: 0| Acc: 96.29 (9629/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.117118 | Loss_in_diffu: 11.017501 | Loss_out_diffu: 12.347704 | Acc: 96.926749 (58063/59904)
(1679154693.3646202, 1679154784.4116874, 91.04706716537476)
Test epoch: 1| Acc: 98.1 (9810/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.078736 | Loss_in_diffu: 10.881932 | Loss_out_diffu: 12.335920 | Acc: 97.796474 (58584/59904)
(1679154785.0678236, 1679154878.0708106, 93.00298690795898)
Test epoch: 2| Acc: 97.95 (9795/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.059463 | Loss_in_diffu: 10.749331 | Loss_out_diffu: 12.258611 | Acc: 98.272236 (58869/59904)
(1679154878.5556443, 1679154970.4546556, 91.8990113735199)
Test epoch: 3| Acc: 98.76 (9876/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049480 | Loss_in_diffu: 10.614875 | Loss_out_diffu: 12.172534 | Acc: 98.574386 (59050/59904)
(1679154970.9486327, 1679155066.9538522, 96.00521945953369)
Test epoch: 4| Acc: 98.21 (9821/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.044992 | Loss_in_diffu: 10.479628 | Loss_out_diffu: 12.047817 | Acc: 98.687901 (59118/59904)
(1679155067.4509437, 1679155159.7266681, 92.27572441101074)
Test epoch: 5| Acc: 99.01 (9901/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037978 | Loss_in_diffu: 10.349526 | Loss_out_diffu: 11.961592 | Acc: 98.926616 (59261/59904)
(1679155160.2420843, 1679155253.101982, 92.85989785194397)
Test epoch: 6| Acc: 98.88 (9888/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.038283 | Loss_in_diffu: 10.229797 | Loss_out_diffu: 11.852031 | Acc: 98.836472 (59207/59904)
(1679155253.6639876, 1679155346.0303838, 92.36639618873596)
Test epoch: 7| Acc: 98.93 (9893/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.031367 | Loss_in_diffu: 10.110126 | Loss_out_diffu: 11.726836 | Acc: 99.145299 (59392/59904)
(1679155346.5103285, 1679155438.0237012, 91.51337265968323)
Test epoch: 8| Acc: 98.68 (9868/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.030806 | Loss_in_diffu: 9.992211 | Loss_out_diffu: 11.634171 | Acc: 99.135283 (59386/59904)
(1679155438.6006677, 1679155532.5581462, 93.9574785232544)
Test epoch: 9| Acc: 99.15 (9915/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.029282 | Loss_in_diffu: 9.877686 | Loss_out_diffu: 11.524174 | Acc: 99.126936 (59381/59904)
(1679155533.0741746, 1679155625.481096, 92.40692138671875)
Test epoch: 10| Acc: 98.97 (9897/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.010783 | Loss_in_diffu: 9.801218 | Loss_out_diffu: 11.510357 | Acc: 99.694511 (59721/59904)
(1679155625.9832754, 1679155716.5298948, 90.5466194152832)
Test epoch: 11| Acc: 99.49 (9949/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007960 | Loss_in_diffu: 9.774443 | Loss_out_diffu: 11.486962 | Acc: 99.794671 (59781/59904)
(1679155717.1207247, 1679155807.9697497, 90.84902501106262)
Test epoch: 12| Acc: 99.49 (9949/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006759 | Loss_in_diffu: 9.745598 | Loss_out_diffu: 11.464958 | Acc: 99.834736 (59805/59904)
(1679155808.4708993, 1679155900.765961, 92.29506158828735)
Test epoch: 13| Acc: 99.51 (9951/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005886 | Loss_in_diffu: 9.714347 | Loss_out_diffu: 11.437927 | Acc: 99.864784 (59823/59904)
(1679155901.269509, 1679155996.299973, 95.0304639339447)
Test epoch: 14| Acc: 99.51 (9951/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005478 | Loss_in_diffu: 9.683275 | Loss_out_diffu: 11.413771 | Acc: 99.854768 (59817/59904)
(1679155996.7870107, 1679156089.2626517, 92.47564101219177)
Test epoch: 15| Acc: 99.51 (9951/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004507 | Loss_in_diffu: 9.651853 | Loss_out_diffu: 11.386936 | Acc: 99.888154 (59837/59904)
(1679156089.7630038, 1679156181.341824, 91.57882022857666)
Test epoch: 16| Acc: 99.51 (9951/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004297 | Loss_in_diffu: 9.620415 | Loss_out_diffu: 11.363764 | Acc: 99.894832 (59841/59904)
(1679156181.8208196, 1679156275.4374268, 93.61660718917847)
Test epoch: 17| Acc: 99.53 (9953/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004469 | Loss_in_diffu: 9.591000 | Loss_out_diffu: 11.342659 | Acc: 99.889824 (59838/59904)
(1679156275.917919, 1679156369.7670784, 93.84915947914124)
Test epoch: 18| Acc: 99.42 (9942/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003569 | Loss_in_diffu: 9.564494 | Loss_out_diffu: 11.321748 | Acc: 99.913194 (59852/59904)
(1679156370.2402048, 1679156460.5779562, 90.3377513885498)
Test epoch: 19| Acc: 99.45 (9945/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002711 | Loss_in_diffu: 9.536369 | Loss_out_diffu: 11.304140 | Acc: 99.936565 (59866/59904)
(1679156461.0906832, 1679156549.9074688, 88.81678557395935)
Test epoch: 20| Acc: 99.49 (9949/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001923 | Loss_in_diffu: 9.519999 | Loss_out_diffu: 11.290707 | Acc: 99.963275 (59882/59904)
(1679156550.407439, 1679156640.7979836, 90.39054465293884)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001714 | Loss_in_diffu: 9.516370 | Loss_out_diffu: 11.288237 | Acc: 99.971621 (59887/59904)
(1679156641.2967436, 1679156734.1583822, 92.86163854598999)
Test epoch: 22| Acc: 99.51 (9951/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001673 | Loss_in_diffu: 9.513060 | Loss_out_diffu: 11.285514 | Acc: 99.976629 (59890/59904)
(1679156734.6648085, 1679156826.891949, 92.22714042663574)
Test epoch: 23| Acc: 99.54 (9954/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001575 | Loss_in_diffu: 9.508564 | Loss_out_diffu: 11.282626 | Acc: 99.983307 (59894/59904)
(1679156827.3853931, 1679156917.6083398, 90.22294664382935)
Test epoch: 24| Acc: 99.51 (9951/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001517 | Loss_in_diffu: 9.504615 | Loss_out_diffu: 11.279417 | Acc: 99.979968 (59892/59904)
(1679156918.0893269, 1679157010.0456738, 91.95634698867798)
Test epoch: 25| Acc: 99.53 (9953/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001477 | Loss_in_diffu: 9.499952 | Loss_out_diffu: 11.275906 | Acc: 99.983307 (59894/59904)
(1679157010.5425575, 1679157102.7526329, 92.21007537841797)
Test epoch: 26| Acc: 99.54 (9954/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001444 | Loss_in_diffu: 9.496066 | Loss_out_diffu: 11.271945 | Acc: 99.979968 (59892/59904)
(1679157103.2596269, 1679157195.0376067, 91.77797985076904)
Test epoch: 27| Acc: 99.52 (9952/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001363 | Loss_in_diffu: 9.491603 | Loss_out_diffu: 11.268974 | Acc: 99.986645 (59896/59904)
(1679157195.5355058, 1679157287.8967202, 92.36121439933777)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001331 | Loss_in_diffu: 9.487464 | Loss_out_diffu: 11.264693 | Acc: 99.984976 (59895/59904)
(1679157288.5006695, 1679157381.5759363, 93.07526683807373)
Test epoch: 29| Acc: 99.51 (9951/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001238 | Loss_in_diffu: 9.483208 | Loss_out_diffu: 11.261665 | Acc: 99.984976 (59895/59904)
(1679157382.0634544, 1679157475.6480038, 93.58454942703247)
Test epoch: 30| Acc: 99.54 (9954/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001142 | Loss_in_diffu: 9.480741 | Loss_out_diffu: 11.259536 | Acc: 99.991653 (59899/59904)
(1679157476.1473, 1679157568.9589705, 92.8116705417633)
Test epoch: 31| Acc: 99.52 (9952/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001144 | Loss_in_diffu: 9.480605 | Loss_out_diffu: 11.259159 | Acc: 99.991653 (59899/59904)
(1679157569.454485, 1679157661.3924885, 91.93800354003906)
Test epoch: 32| Acc: 99.49 (9949/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001141 | Loss_in_diffu: 9.480009 | Loss_out_diffu: 11.258746 | Acc: 99.989984 (59898/59904)
(1679157661.8818307, 1679157755.3807313, 93.49890065193176)
Test epoch: 33| Acc: 99.53 (9953/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001126 | Loss_in_diffu: 9.479459 | Loss_out_diffu: 11.258399 | Acc: 99.989984 (59898/59904)
(1679157755.8881264, 1679157847.985084, 92.09695768356323)
Test epoch: 34| Acc: 99.53 (9953/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001128 | Loss_in_diffu: 9.479173 | Loss_out_diffu: 11.257895 | Acc: 99.991653 (59899/59904)
(1679157848.4816153, 1679157940.4003801, 91.91876482963562)
Test epoch: 35| Acc: 99.5 (9950/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001121 | Loss_in_diffu: 9.478526 | Loss_out_diffu: 11.257456 | Acc: 99.989984 (59898/59904)
(1679157940.8970275, 1679158031.9918706, 91.09484314918518)
Test epoch: 36| Acc: 99.51 (9951/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001119 | Loss_in_diffu: 9.477694 | Loss_out_diffu: 11.256817 | Acc: 99.991653 (59899/59904)
(1679158032.5828693, 1679158122.0434577, 89.4605884552002)
Test epoch: 37| Acc: 99.5 (9950/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001108 | Loss_in_diffu: 9.477373 | Loss_out_diffu: 11.256987 | Acc: 99.989984 (59898/59904)
(1679158122.5408185, 1679158212.0341127, 89.49329423904419)
Test epoch: 38| Acc: 99.5 (9950/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001105 | Loss_in_diffu: 9.477064 | Loss_out_diffu: 11.256212 | Acc: 99.991653 (59899/59904)
(1679158212.5306726, 1679158300.1505966, 87.61992406845093)
Test epoch: 39| Acc: 99.52 (9952/10000) 
