True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.719982 | Loss_in_diffu: 11.670356 | Loss_out_diffu: 12.038654 | Acc: 82.967748 (49701/59904)
(1679156054.9567053, 1679156152.0521936, 97.09548830986023)
Test epoch: 0| Acc: 96.29 (9629/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.130161 | Loss_in_diffu: 11.083413 | Loss_out_diffu: 12.480402 | Acc: 96.507746 (57812/59904)
(1679156152.6349623, 1679156250.43159, 97.79662775993347)
Test epoch: 1| Acc: 97.04 (9704/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.082149 | Loss_in_diffu: 10.943784 | Loss_out_diffu: 12.489800 | Acc: 97.647903 (58495/59904)
(1679156251.0086193, 1679156348.7554512, 97.7468318939209)
Test epoch: 2| Acc: 98.19 (9819/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.063477 | Loss_in_diffu: 10.807072 | Loss_out_diffu: 12.410821 | Acc: 98.232171 (58845/59904)
(1679156349.3327734, 1679156446.659825, 97.32705163955688)
Test epoch: 3| Acc: 98.96 (9896/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.052493 | Loss_in_diffu: 10.663162 | Loss_out_diffu: 12.305728 | Acc: 98.484241 (58996/59904)
(1679156447.234813, 1679156544.6490703, 97.41425728797913)
Test epoch: 4| Acc: 98.94 (9894/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.045395 | Loss_in_diffu: 10.518506 | Loss_out_diffu: 12.164751 | Acc: 98.669538 (59107/59904)
(1679156545.2278206, 1679156642.3309324, 97.103111743927)
Test epoch: 5| Acc: 98.28 (9828/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.040236 | Loss_in_diffu: 10.370512 | Loss_out_diffu: 12.039889 | Acc: 98.836472 (59207/59904)
(1679156642.9095056, 1679156740.0232713, 97.11376571655273)
Test epoch: 6| Acc: 98.58 (9858/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.036343 | Loss_in_diffu: 10.233726 | Loss_out_diffu: 11.923396 | Acc: 98.909923 (59251/59904)
(1679156740.5897267, 1679156838.1681423, 97.57841563224792)
Test epoch: 7| Acc: 98.58 (9858/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.035024 | Loss_in_diffu: 10.108273 | Loss_out_diffu: 11.765923 | Acc: 99.000067 (59305/59904)
(1679156838.7467754, 1679156936.483937, 97.73716163635254)
Test epoch: 8| Acc: 98.5 (9850/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.030799 | Loss_in_diffu: 9.984675 | Loss_out_diffu: 11.643978 | Acc: 99.110243 (59371/59904)
(1679156937.0501583, 1679157034.3836465, 97.33348822593689)
Test epoch: 9| Acc: 98.8 (9880/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.030591 | Loss_in_diffu: 9.866915 | Loss_out_diffu: 11.601022 | Acc: 99.093550 (59361/59904)
(1679157034.9532714, 1679157132.282588, 97.32931661605835)
Test epoch: 10| Acc: 98.82 (9882/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.011223 | Loss_in_diffu: 9.799018 | Loss_out_diffu: 11.764087 | Acc: 99.694511 (59721/59904)
(1679157132.8627243, 1679157230.0814037, 97.21867942810059)
Test epoch: 11| Acc: 99.49 (9949/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.008651 | Loss_in_diffu: 9.773512 | Loss_out_diffu: 11.752805 | Acc: 99.782986 (59774/59904)
(1679157230.664235, 1679157328.7206774, 98.05644226074219)
Test epoch: 12| Acc: 99.51 (9951/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.007453 | Loss_in_diffu: 9.745639 | Loss_out_diffu: 11.735417 | Acc: 99.814704 (59793/59904)
(1679157329.2998748, 1679157426.7788842, 97.47900938987732)
Test epoch: 13| Acc: 99.44 (9944/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006464 | Loss_in_diffu: 9.715780 | Loss_out_diffu: 11.714170 | Acc: 99.841413 (59809/59904)
(1679157427.3581557, 1679157525.4547772, 98.0966215133667)
Test epoch: 14| Acc: 99.49 (9949/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006151 | Loss_in_diffu: 9.685196 | Loss_out_diffu: 11.693663 | Acc: 99.846421 (59812/59904)
(1679157526.0342708, 1679157623.287061, 97.25279021263123)
Test epoch: 15| Acc: 99.51 (9951/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005583 | Loss_in_diffu: 9.654854 | Loss_out_diffu: 11.672254 | Acc: 99.856437 (59818/59904)
(1679157623.8688626, 1679157721.5263634, 97.65750074386597)
Test epoch: 16| Acc: 99.5 (9950/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.005223 | Loss_in_diffu: 9.625576 | Loss_out_diffu: 11.651029 | Acc: 99.871461 (59827/59904)
(1679157722.1039264, 1679157819.295442, 97.19151568412781)
Test epoch: 17| Acc: 99.47 (9947/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004277 | Loss_in_diffu: 9.596774 | Loss_out_diffu: 11.635581 | Acc: 99.894832 (59841/59904)
(1679157819.8770242, 1679157917.9892464, 98.11222219467163)
Test epoch: 18| Acc: 99.38 (9938/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004157 | Loss_in_diffu: 9.569946 | Loss_out_diffu: 11.612327 | Acc: 99.891493 (59839/59904)
(1679157918.5689025, 1679158016.1629922, 97.59408974647522)
Test epoch: 19| Acc: 99.47 (9947/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003466 | Loss_in_diffu: 9.541698 | Loss_out_diffu: 11.594676 | Acc: 99.933226 (59864/59904)
(1679158016.7295265, 1679158114.367666, 97.63813948631287)
Test epoch: 20| Acc: 99.48 (9948/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002253 | Loss_in_diffu: 9.525732 | Loss_out_diffu: 11.586982 | Acc: 99.959936 (59880/59904)
(1679158114.9470177, 1679158212.421582, 97.47456431388855)
Test epoch: 21| Acc: 99.51 (9951/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002073 | Loss_in_diffu: 9.522146 | Loss_out_diffu: 11.584312 | Acc: 99.961605 (59881/59904)
(1679158213.0009353, 1679158310.4409742, 97.44003891944885)
Test epoch: 22| Acc: 99.51 (9951/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.002001 | Loss_in_diffu: 9.518875 | Loss_out_diffu: 11.581730 | Acc: 99.966613 (59884/59904)
(1679158311.0193815, 1679158408.7405913, 97.72120976448059)
Test epoch: 23| Acc: 99.54 (9954/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001920 | Loss_in_diffu: 9.514428 | Loss_out_diffu: 11.579089 | Acc: 99.964944 (59883/59904)
(1679158409.3206408, 1679158506.479447, 97.15880608558655)
Test epoch: 24| Acc: 99.49 (9949/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001865 | Loss_in_diffu: 9.510549 | Loss_out_diffu: 11.576464 | Acc: 99.973291 (59888/59904)
(1679158507.057731, 1679158604.2969074, 97.23917651176453)
Test epoch: 25| Acc: 99.52 (9952/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001815 | Loss_in_diffu: 9.505888 | Loss_out_diffu: 11.573258 | Acc: 99.971621 (59887/59904)
(1679158604.8744724, 1679158702.625358, 97.75088572502136)
Test epoch: 26| Acc: 99.5 (9950/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001748 | Loss_in_diffu: 9.501934 | Loss_out_diffu: 11.570287 | Acc: 99.974960 (59889/59904)
(1679158703.204669, 1679158800.6479304, 97.44326138496399)
Test epoch: 27| Acc: 99.47 (9947/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001730 | Loss_in_diffu: 9.497327 | Loss_out_diffu: 11.567389 | Acc: 99.969952 (59886/59904)
(1679158801.2275553, 1679158898.646327, 97.41877174377441)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001672 | Loss_in_diffu: 9.493047 | Loss_out_diffu: 11.564320 | Acc: 99.974960 (59889/59904)
(1679158899.2134492, 1679158996.066284, 96.85283470153809)
Test epoch: 29| Acc: 99.51 (9951/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001582 | Loss_in_diffu: 9.488580 | Loss_out_diffu: 11.561799 | Acc: 99.978299 (59891/59904)
(1679158996.6468623, 1679159094.0739107, 97.42704844474792)
Test epoch: 30| Acc: 99.5 (9950/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001498 | Loss_in_diffu: 9.485993 | Loss_out_diffu: 11.559871 | Acc: 99.983307 (59894/59904)
(1679159094.6515305, 1679159191.7091925, 97.05766201019287)
Test epoch: 31| Acc: 99.5 (9950/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001487 | Loss_in_diffu: 9.485842 | Loss_out_diffu: 11.559782 | Acc: 99.984976 (59895/59904)
(1679159192.2895904, 1679159289.1390145, 96.84942412376404)
Test epoch: 32| Acc: 99.53 (9953/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001488 | Loss_in_diffu: 9.485232 | Loss_out_diffu: 11.559300 | Acc: 99.984976 (59895/59904)
(1679159289.7170198, 1679159387.0894458, 97.37242603302002)
Test epoch: 33| Acc: 99.55 (9955/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001473 | Loss_in_diffu: 9.484670 | Loss_out_diffu: 11.559200 | Acc: 99.984976 (59895/59904)
(1679159387.6622517, 1679159485.0076334, 97.34538173675537)
Test epoch: 34| Acc: 99.5 (9950/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001478 | Loss_in_diffu: 9.484393 | Loss_out_diffu: 11.558962 | Acc: 99.983307 (59894/59904)
(1679159485.5885086, 1679159583.2446516, 97.65614295005798)
Test epoch: 35| Acc: 99.52 (9952/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001461 | Loss_in_diffu: 9.483738 | Loss_out_diffu: 11.558677 | Acc: 99.984976 (59895/59904)
(1679159583.8127985, 1679159681.5078325, 97.69503402709961)
Test epoch: 36| Acc: 99.55 (9955/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001465 | Loss_in_diffu: 9.482906 | Loss_out_diffu: 11.558151 | Acc: 99.984976 (59895/59904)
(1679159682.0754066, 1679159779.8957586, 97.82035207748413)
Test epoch: 37| Acc: 99.53 (9953/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001452 | Loss_in_diffu: 9.482574 | Loss_out_diffu: 11.558411 | Acc: 99.984976 (59895/59904)
(1679159780.474489, 1679159878.3246465, 97.85015749931335)
Test epoch: 38| Acc: 99.53 (9953/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001452 | Loss_in_diffu: 9.482263 | Loss_out_diffu: 11.557925 | Acc: 99.984976 (59895/59904)
(1679159878.8978415, 1679159975.7245822, 96.82674074172974)
Test epoch: 39| Acc: 99.53 (9953/10000) 
