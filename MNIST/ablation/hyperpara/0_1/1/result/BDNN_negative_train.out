True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.608188 | Loss_in_diffu: 10.716836 | Loss_out_diffu: 11.072009 | Acc: 86.022636 (51531/59904)
(1639032982.1823797, 1639033081.8621004, 99.6797206401825)
Test epoch: 0| Acc: 96.47 (9647/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.097220 | Loss_in_diffu: 9.423822 | Loss_out_diffu: 10.563724 | Acc: 97.452591 (58378/59904)
(1639033082.445749, 1639033180.9204268, 98.4746778011322)
Test epoch: 1| Acc: 98.46 (9846/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.066199 | Loss_in_diffu: 8.639067 | Loss_out_diffu: 9.956813 | Acc: 98.248865 (58855/59904)
(1639033181.638181, 1639033280.3392987, 98.70111775398254)
Test epoch: 2| Acc: 97.92 (9792/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.055740 | Loss_in_diffu: 7.911084 | Loss_out_diffu: 9.293136 | Acc: 98.429153 (58963/59904)
(1639033280.935307, 1639033379.6904914, 98.75518441200256)
Test epoch: 3| Acc: 98.72 (9872/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049223 | Loss_in_diffu: 7.236640 | Loss_out_diffu: 8.670560 | Acc: 98.622796 (59079/59904)
(1639033380.2864053, 1639033479.2487173, 98.96231198310852)
Test epoch: 4| Acc: 98.93 (9893/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.043062 | Loss_in_diffu: 6.597189 | Loss_out_diffu: 8.058409 | Acc: 98.751335 (59156/59904)
(1639033479.9566152, 1639033578.999472, 99.04285669326782)
Test epoch: 5| Acc: 98.88 (9888/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.038535 | Loss_in_diffu: 5.982389 | Loss_out_diffu: 7.459891 | Acc: 98.916600 (59255/59904)
(1639033579.7040997, 1639033678.6656344, 98.96153473854065)
Test epoch: 6| Acc: 99.13 (9913/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.036824 | Loss_in_diffu: 5.391258 | Loss_out_diffu: 6.870254 | Acc: 98.939971 (59269/59904)
(1639033679.30889, 1639033778.3683028, 99.05941271781921)
Test epoch: 7| Acc: 98.98 (9898/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.031516 | Loss_in_diffu: 4.817720 | Loss_out_diffu: 6.283103 | Acc: 99.086872 (59357/59904)
(1639033779.0815165, 1639033877.987522, 98.90600538253784)
Test epoch: 8| Acc: 98.7 (9870/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.029887 | Loss_in_diffu: 4.262329 | Loss_out_diffu: 5.715115 | Acc: 99.151976 (59396/59904)
(1639033878.5897472, 1639033977.39834, 98.80859279632568)
Test epoch: 9| Acc: 98.78 (9878/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.027406 | Loss_in_diffu: 3.721895 | Loss_out_diffu: 5.173973 | Acc: 99.215411 (59434/59904)
(1639033978.0952003, 1639034077.1414094, 99.04620909690857)
Test epoch: 10| Acc: 98.81 (9881/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.010222 | Loss_in_diffu: 3.421220 | Loss_out_diffu: 4.908403 | Acc: 99.732906 (59744/59904)
(1639034077.7336028, 1639034176.8658793, 99.13227653503418)
Test epoch: 11| Acc: 99.53 (9953/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007388 | Loss_in_diffu: 3.357945 | Loss_out_diffu: 4.853301 | Acc: 99.819712 (59796/59904)
(1639034177.459407, 1639034276.8424227, 99.3830156326294)
Test epoch: 12| Acc: 99.53 (9953/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006859 | Loss_in_diffu: 3.296435 | Loss_out_diffu: 4.795767 | Acc: 99.836405 (59806/59904)
(1639034277.434302, 1639034376.225613, 98.7913110256195)
Test epoch: 13| Acc: 99.5 (9950/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005621 | Loss_in_diffu: 3.235537 | Loss_out_diffu: 4.743390 | Acc: 99.868122 (59825/59904)
(1639034376.8122323, 1639034476.7705128, 99.95828056335449)
Test epoch: 14| Acc: 99.5 (9950/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005142 | Loss_in_diffu: 3.176153 | Loss_out_diffu: 4.691126 | Acc: 99.874800 (59829/59904)
(1639034477.364438, 1639034576.7536292, 99.38919115066528)
Test epoch: 15| Acc: 99.56 (9956/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004849 | Loss_in_diffu: 3.118304 | Loss_out_diffu: 4.640717 | Acc: 99.878138 (59831/59904)
(1639034577.3504124, 1639034676.8574512, 99.50703883171082)
Test epoch: 16| Acc: 99.47 (9947/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004207 | Loss_in_diffu: 3.061064 | Loss_out_diffu: 4.590282 | Acc: 99.901509 (59845/59904)
(1639034677.4543152, 1639034777.0127857, 99.5584704875946)
Test epoch: 17| Acc: 99.47 (9947/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004270 | Loss_in_diffu: 3.005284 | Loss_out_diffu: 4.535010 | Acc: 99.888154 (59837/59904)
(1639034777.6139035, 1639034877.0520396, 99.43813610076904)
Test epoch: 18| Acc: 99.51 (9951/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004166 | Loss_in_diffu: 2.951170 | Loss_out_diffu: 4.483938 | Acc: 99.896501 (59842/59904)
(1639034877.7597132, 1639034976.455995, 98.69628190994263)
Test epoch: 19| Acc: 99.41 (9941/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003561 | Loss_in_diffu: 2.896444 | Loss_out_diffu: 4.428933 | Acc: 99.933226 (59864/59904)
(1639034977.0534365, 1639035075.928966, 98.87552952766418)
Test epoch: 20| Acc: 99.51 (9951/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002049 | Loss_in_diffu: 2.865801 | Loss_out_diffu: 4.404965 | Acc: 99.969952 (59886/59904)
(1639035076.6439815, 1639035175.6320865, 98.98810505867004)
Test epoch: 21| Acc: 99.46 (9946/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001939 | Loss_in_diffu: 2.859690 | Loss_out_diffu: 4.400898 | Acc: 99.969952 (59886/59904)
(1639035176.239544, 1639035275.0739307, 98.83438682556152)
Test epoch: 22| Acc: 99.47 (9947/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001880 | Loss_in_diffu: 2.854190 | Loss_out_diffu: 4.395298 | Acc: 99.973291 (59888/59904)
(1639035275.783256, 1639035375.780789, 99.99753284454346)
Test epoch: 23| Acc: 99.52 (9952/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001833 | Loss_in_diffu: 2.847782 | Loss_out_diffu: 4.390360 | Acc: 99.973291 (59888/59904)
(1639035376.4994993, 1639035476.2323406, 99.73284125328064)
Test epoch: 24| Acc: 99.48 (9948/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001799 | Loss_in_diffu: 2.842086 | Loss_out_diffu: 4.385334 | Acc: 99.974960 (59889/59904)
(1639035476.8170996, 1639035575.6608691, 98.84376955032349)
Test epoch: 25| Acc: 99.43 (9943/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001818 | Loss_in_diffu: 2.835716 | Loss_out_diffu: 4.379846 | Acc: 99.973291 (59888/59904)
(1639035576.268457, 1639035675.6625414, 99.39408445358276)
Test epoch: 26| Acc: 99.5 (9950/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001828 | Loss_in_diffu: 2.830237 | Loss_out_diffu: 4.374909 | Acc: 99.979968 (59892/59904)
(1639035676.3710787, 1639035776.3207252, 99.94964647293091)
Test epoch: 27| Acc: 99.44 (9944/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001746 | Loss_in_diffu: 2.824285 | Loss_out_diffu: 4.369930 | Acc: 99.978299 (59891/59904)
(1639035776.9053164, 1639035876.2958858, 99.39056944847107)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001747 | Loss_in_diffu: 2.818531 | Loss_out_diffu: 4.364840 | Acc: 99.976629 (59890/59904)
(1639035877.0005603, 1639035976.3016636, 99.30110335350037)
Test epoch: 29| Acc: 99.54 (9954/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001776 | Loss_in_diffu: 2.812717 | Loss_out_diffu: 4.360142 | Acc: 99.976629 (59890/59904)
(1639035977.0057497, 1639036075.8391109, 98.83336114883423)
Test epoch: 30| Acc: 99.46 (9946/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001556 | Loss_in_diffu: 2.809337 | Loss_out_diffu: 4.356480 | Acc: 99.978299 (59891/59904)
(1639036076.4315329, 1639036175.2119129, 98.78038001060486)
Test epoch: 31| Acc: 99.44 (9944/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001630 | Loss_in_diffu: 2.809065 | Loss_out_diffu: 4.356835 | Acc: 99.979968 (59892/59904)
(1639036175.8115215, 1639036274.497142, 98.68562054634094)
Test epoch: 32| Acc: 99.49 (9949/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001608 | Loss_in_diffu: 2.808271 | Loss_out_diffu: 4.356216 | Acc: 99.981637 (59893/59904)
(1639036275.2032309, 1639036374.0885298, 98.88529896736145)
Test epoch: 33| Acc: 99.47 (9947/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001602 | Loss_in_diffu: 2.807597 | Loss_out_diffu: 4.355572 | Acc: 99.981637 (59893/59904)
(1639036374.679211, 1639036473.6276546, 98.94844365119934)
Test epoch: 34| Acc: 99.5 (9950/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001558 | Loss_in_diffu: 2.807251 | Loss_out_diffu: 4.355145 | Acc: 99.978299 (59891/59904)
(1639036474.3338907, 1639036573.214162, 98.88027143478394)
Test epoch: 35| Acc: 99.5 (9950/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001513 | Loss_in_diffu: 2.806474 | Loss_out_diffu: 4.354625 | Acc: 99.979968 (59892/59904)
(1639036573.9240885, 1639036673.8116755, 99.88758707046509)
Test epoch: 36| Acc: 99.48 (9948/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001628 | Loss_in_diffu: 2.805505 | Loss_out_diffu: 4.354235 | Acc: 99.981637 (59893/59904)
(1639036674.40398, 1639036773.8451447, 99.44116473197937)
Test epoch: 37| Acc: 99.51 (9951/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001545 | Loss_in_diffu: 2.805010 | Loss_out_diffu: 4.353576 | Acc: 99.983307 (59894/59904)
(1639036774.5628817, 1639036873.2751422, 98.71226048469543)
Test epoch: 38| Acc: 99.49 (9949/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001528 | Loss_in_diffu: 2.804603 | Loss_out_diffu: 4.353120 | Acc: 99.981637 (59893/59904)
(1639036873.993296, 1639036973.2296999, 99.23640394210815)
Test epoch: 39| Acc: 99.47 (9947/10000) 
