True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.575246 | Loss_in_diffu: 10.709429 | Loss_out_diffu: 11.083883 | Acc: 87.055956 (52150/59904)
(1639033035.4654424, 1639033137.2130666, 101.74762415885925)
Test epoch: 0| Acc: 97.06 (9706/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.094119 | Loss_in_diffu: 9.425093 | Loss_out_diffu: 10.628004 | Acc: 97.606170 (58470/59904)
(1639033137.8278272, 1639033238.8939936, 101.06616640090942)
Test epoch: 1| Acc: 98.03 (9803/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.069876 | Loss_in_diffu: 8.640793 | Loss_out_diffu: 10.024755 | Acc: 98.160390 (58802/59904)
(1639033239.5093727, 1639033339.7729814, 100.26360869407654)
Test epoch: 2| Acc: 98.67 (9867/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.057744 | Loss_in_diffu: 7.917097 | Loss_out_diffu: 9.379056 | Acc: 98.392428 (58941/59904)
(1639033340.3921418, 1639033440.4373512, 100.0452094078064)
Test epoch: 3| Acc: 98.8 (9880/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048054 | Loss_in_diffu: 7.242180 | Loss_out_diffu: 8.767532 | Acc: 98.657853 (59100/59904)
(1639033441.0577126, 1639033541.544382, 100.48666954040527)
Test epoch: 4| Acc: 99.08 (9908/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.043077 | Loss_in_diffu: 6.600475 | Loss_out_diffu: 8.179041 | Acc: 98.754674 (59158/59904)
(1639033542.1534853, 1639033642.0893803, 99.93589496612549)
Test epoch: 5| Acc: 99.0 (9900/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037403 | Loss_in_diffu: 5.984261 | Loss_out_diffu: 7.605101 | Acc: 98.934963 (59266/59904)
(1639033642.7096336, 1639033742.6782215, 99.96858787536621)
Test epoch: 6| Acc: 99.01 (9901/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.039150 | Loss_in_diffu: 5.394027 | Loss_out_diffu: 7.033099 | Acc: 98.884882 (59236/59904)
(1639033743.3081007, 1639033843.4364781, 100.12837743759155)
Test epoch: 7| Acc: 99.08 (9908/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.033887 | Loss_in_diffu: 4.824632 | Loss_out_diffu: 6.461897 | Acc: 99.028446 (59322/59904)
(1639033844.0574467, 1639033944.9578168, 100.9003701210022)
Test epoch: 8| Acc: 99.07 (9907/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.028264 | Loss_in_diffu: 4.260267 | Loss_out_diffu: 5.950831 | Acc: 99.198718 (59424/59904)
(1639033945.5769985, 1639034045.4244826, 99.84748411178589)
Test epoch: 9| Acc: 98.92 (9892/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.028707 | Loss_in_diffu: 3.713957 | Loss_out_diffu: 5.452820 | Acc: 99.200387 (59425/59904)
(1639034046.0341663, 1639034145.8271103, 99.79294395446777)
Test epoch: 10| Acc: 99.18 (9918/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009506 | Loss_in_diffu: 3.409304 | Loss_out_diffu: 5.181231 | Acc: 99.757946 (59759/59904)
(1639034146.4453068, 1639034246.6194916, 100.17418479919434)
Test epoch: 11| Acc: 99.53 (9953/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006689 | Loss_in_diffu: 3.344776 | Loss_out_diffu: 5.119007 | Acc: 99.843082 (59810/59904)
(1639034247.2400932, 1639034347.2490754, 100.00898218154907)
Test epoch: 12| Acc: 99.53 (9953/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006151 | Loss_in_diffu: 3.282327 | Loss_out_diffu: 5.058638 | Acc: 99.849760 (59814/59904)
(1639034347.8669405, 1639034448.2918782, 100.42493772506714)
Test epoch: 13| Acc: 99.47 (9947/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005339 | Loss_in_diffu: 3.221560 | Loss_out_diffu: 5.004406 | Acc: 99.879808 (59832/59904)
(1639034448.9109433, 1639034548.7054265, 99.79448318481445)
Test epoch: 14| Acc: 99.53 (9953/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005321 | Loss_in_diffu: 3.162445 | Loss_out_diffu: 4.955501 | Acc: 99.871461 (59827/59904)
(1639034549.3246455, 1639034649.3869662, 100.06232070922852)
Test epoch: 15| Acc: 99.44 (9944/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004530 | Loss_in_diffu: 3.103629 | Loss_out_diffu: 4.910133 | Acc: 99.896501 (59842/59904)
(1639034650.0047967, 1639034749.9537168, 99.94892001152039)
Test epoch: 16| Acc: 99.44 (9944/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004804 | Loss_in_diffu: 3.046541 | Loss_out_diffu: 4.855408 | Acc: 99.891493 (59839/59904)
(1639034750.5728953, 1639034850.922403, 100.3495078086853)
Test epoch: 17| Acc: 99.37 (9937/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004196 | Loss_in_diffu: 2.990463 | Loss_out_diffu: 4.813058 | Acc: 99.901509 (59845/59904)
(1639034851.5320075, 1639034952.2833648, 100.75135731697083)
Test epoch: 18| Acc: 99.38 (9938/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003771 | Loss_in_diffu: 2.934700 | Loss_out_diffu: 4.768749 | Acc: 99.904848 (59847/59904)
(1639034952.891135, 1639035052.7357454, 99.84461045265198)
Test epoch: 19| Acc: 99.3 (9930/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003461 | Loss_in_diffu: 2.879335 | Loss_out_diffu: 4.724814 | Acc: 99.916533 (59854/59904)
(1639035053.352602, 1639035153.3420844, 99.98948240280151)
Test epoch: 20| Acc: 99.43 (9943/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002190 | Loss_in_diffu: 2.848133 | Loss_out_diffu: 4.700168 | Acc: 99.954928 (59877/59904)
(1639035153.955012, 1639035254.133555, 100.17854285240173)
Test epoch: 21| Acc: 99.48 (9948/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001917 | Loss_in_diffu: 2.841740 | Loss_out_diffu: 4.694805 | Acc: 99.969952 (59886/59904)
(1639035254.7541354, 1639035354.545635, 99.79149961471558)
Test epoch: 22| Acc: 99.46 (9946/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001798 | Loss_in_diffu: 2.836145 | Loss_out_diffu: 4.688589 | Acc: 99.974960 (59889/59904)
(1639035355.152535, 1639035455.9288802, 100.77634525299072)
Test epoch: 23| Acc: 99.5 (9950/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001902 | Loss_in_diffu: 2.829789 | Loss_out_diffu: 4.682539 | Acc: 99.971621 (59887/59904)
(1639035456.5354438, 1639035556.8601632, 100.32471942901611)
Test epoch: 24| Acc: 99.47 (9947/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001692 | Loss_in_diffu: 2.824215 | Loss_out_diffu: 4.677827 | Acc: 99.978299 (59891/59904)
(1639035557.4786677, 1639035657.8975472, 100.41887950897217)
Test epoch: 25| Acc: 99.47 (9947/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001761 | Loss_in_diffu: 2.817970 | Loss_out_diffu: 4.671852 | Acc: 99.976629 (59890/59904)
(1639035658.5084264, 1639035759.3348997, 100.82647323608398)
Test epoch: 26| Acc: 99.43 (9943/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001661 | Loss_in_diffu: 2.812547 | Loss_out_diffu: 4.667035 | Acc: 99.978299 (59891/59904)
(1639035759.9409003, 1639035860.5720484, 100.63114809989929)
Test epoch: 27| Acc: 99.47 (9947/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001628 | Loss_in_diffu: 2.806601 | Loss_out_diffu: 4.661417 | Acc: 99.981637 (59893/59904)
(1639035861.180704, 1639035961.4192872, 100.23858308792114)
Test epoch: 28| Acc: 99.43 (9943/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001597 | Loss_in_diffu: 2.800856 | Loss_out_diffu: 4.656960 | Acc: 99.983307 (59894/59904)
(1639035962.0427513, 1639036061.8429253, 99.80017399787903)
Test epoch: 29| Acc: 99.46 (9946/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001588 | Loss_in_diffu: 2.795072 | Loss_out_diffu: 4.651772 | Acc: 99.981637 (59893/59904)
(1639036062.4618824, 1639036162.6861286, 100.22424626350403)
Test epoch: 30| Acc: 99.5 (9950/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001533 | Loss_in_diffu: 2.791766 | Loss_out_diffu: 4.648820 | Acc: 99.983307 (59894/59904)
(1639036163.2967458, 1639036263.3578312, 100.06108546257019)
Test epoch: 31| Acc: 99.42 (9942/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001453 | Loss_in_diffu: 2.791470 | Loss_out_diffu: 4.648700 | Acc: 99.988315 (59897/59904)
(1639036263.9809089, 1639036364.6567857, 100.67587685585022)
Test epoch: 32| Acc: 99.5 (9950/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001443 | Loss_in_diffu: 2.790709 | Loss_out_diffu: 4.648537 | Acc: 99.983307 (59894/59904)
(1639036365.275057, 1639036466.1149452, 100.83988809585571)
Test epoch: 33| Acc: 99.48 (9948/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001425 | Loss_in_diffu: 2.790105 | Loss_out_diffu: 4.648366 | Acc: 99.984976 (59895/59904)
(1639036466.7215545, 1639036566.8883822, 100.16682767868042)
Test epoch: 34| Acc: 99.48 (9948/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001446 | Loss_in_diffu: 2.789632 | Loss_out_diffu: 4.647771 | Acc: 99.981637 (59893/59904)
(1639036567.5082388, 1639036667.9833612, 100.47512245178223)
Test epoch: 35| Acc: 99.48 (9948/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001458 | Loss_in_diffu: 2.788893 | Loss_out_diffu: 4.647155 | Acc: 99.986645 (59896/59904)
(1639036668.6036472, 1639036768.889936, 100.28628873825073)
Test epoch: 36| Acc: 99.46 (9946/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001498 | Loss_in_diffu: 2.787947 | Loss_out_diffu: 4.646907 | Acc: 99.986645 (59896/59904)
(1639036769.5073748, 1639036869.301079, 99.79370427131653)
Test epoch: 37| Acc: 99.41 (9941/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001406 | Loss_in_diffu: 2.787492 | Loss_out_diffu: 4.646643 | Acc: 99.986645 (59896/59904)
(1639036869.9201665, 1639036969.5965295, 99.67636299133301)
Test epoch: 38| Acc: 99.43 (9943/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001459 | Loss_in_diffu: 2.787053 | Loss_out_diffu: 4.646250 | Acc: 99.984976 (59895/59904)
(1639036970.2153559, 1639037070.138858, 99.92350220680237)
Test epoch: 39| Acc: 99.49 (9949/10000) 
