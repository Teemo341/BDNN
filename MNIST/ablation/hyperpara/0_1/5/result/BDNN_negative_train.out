True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.712201 | Loss_in_diffu: 11.244737 | Loss_out_diffu: 11.496145 | Acc: 83.475227 (50005/59904)
(1638892495.5287077, 1638892595.5688055, 100.04009771347046)
Test epoch: 0| Acc: 96.32 (9632/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.128966 | Loss_in_diffu: 10.283257 | Loss_out_diffu: 11.598182 | Acc: 96.481036 (57796/59904)
(1638892596.1622593, 1638892695.2621975, 99.09993815422058)
Test epoch: 1| Acc: 98.18 (9818/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.084480 | Loss_in_diffu: 9.782206 | Loss_out_diffu: 11.291426 | Acc: 97.627871 (58483/59904)
(1638892695.9751759, 1638892795.9305787, 99.95540285110474)
Test epoch: 2| Acc: 98.37 (9837/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.066530 | Loss_in_diffu: 9.302400 | Loss_out_diffu: 10.922600 | Acc: 98.096955 (58764/59904)
(1638892796.5377045, 1638892896.8306923, 100.29298782348633)
Test epoch: 3| Acc: 97.67 (9767/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.056516 | Loss_in_diffu: 8.850580 | Loss_out_diffu: 10.533691 | Acc: 98.392428 (58941/59904)
(1638892897.4403646, 1638892997.46843, 100.02806544303894)
Test epoch: 4| Acc: 98.25 (9825/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.051525 | Loss_in_diffu: 8.431053 | Loss_out_diffu: 10.155260 | Acc: 98.556023 (59039/59904)
(1638892998.179458, 1638893098.1960592, 100.01660132408142)
Test epoch: 5| Acc: 98.84 (9884/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.042328 | Loss_in_diffu: 8.030551 | Loss_out_diffu: 9.802086 | Acc: 98.753005 (59157/59904)
(1638893098.7976282, 1638893198.6141558, 99.81652760505676)
Test epoch: 6| Acc: 98.85 (9885/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.042227 | Loss_in_diffu: 7.657951 | Loss_out_diffu: 9.471106 | Acc: 98.758013 (59160/59904)
(1638893199.220213, 1638893298.4162045, 99.19599151611328)
Test epoch: 7| Acc: 99.05 (9905/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.037621 | Loss_in_diffu: 7.299480 | Loss_out_diffu: 9.133253 | Acc: 98.929955 (59263/59904)
(1638893299.1358767, 1638893398.723803, 99.58792638778687)
Test epoch: 8| Acc: 99.0 (9900/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.034770 | Loss_in_diffu: 6.954814 | Loss_out_diffu: 8.787111 | Acc: 98.971688 (59288/59904)
(1638893399.4445987, 1638893499.2079575, 99.76335883140564)
Test epoch: 9| Acc: 98.67 (9867/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.033189 | Loss_in_diffu: 6.617147 | Loss_out_diffu: 8.463677 | Acc: 99.040131 (59329/59904)
(1638893499.9288595, 1638893600.0605, 100.13164043426514)
Test epoch: 10| Acc: 98.74 (9874/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.011359 | Loss_in_diffu: 6.419087 | Loss_out_diffu: 8.304686 | Acc: 99.672810 (59708/59904)
(1638893600.7829003, 1638893700.483218, 99.70031762123108)
Test epoch: 11| Acc: 99.52 (9952/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.008524 | Loss_in_diffu: 6.374208 | Loss_out_diffu: 8.271003 | Acc: 99.782986 (59774/59904)
(1638893701.0826526, 1638893800.1842756, 99.10162305831909)
Test epoch: 12| Acc: 99.49 (9949/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.007914 | Loss_in_diffu: 6.329684 | Loss_out_diffu: 8.234780 | Acc: 99.798010 (59783/59904)
(1638893800.903196, 1638893900.2002027, 99.29700660705566)
Test epoch: 13| Acc: 99.51 (9951/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006622 | Loss_in_diffu: 6.285058 | Loss_out_diffu: 8.199158 | Acc: 99.808026 (59789/59904)
(1638893900.914876, 1638894001.263702, 100.34882593154907)
Test epoch: 14| Acc: 99.4 (9940/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006946 | Loss_in_diffu: 6.243110 | Loss_out_diffu: 8.165406 | Acc: 99.823050 (59798/59904)
(1638894001.8634167, 1638894101.5689104, 99.70549368858337)
Test epoch: 15| Acc: 99.56 (9956/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005797 | Loss_in_diffu: 6.201933 | Loss_out_diffu: 8.133794 | Acc: 99.844752 (59811/59904)
(1638894102.179821, 1638894202.343096, 100.16327500343323)
Test epoch: 16| Acc: 99.44 (9944/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.005739 | Loss_in_diffu: 6.162526 | Loss_out_diffu: 8.102176 | Acc: 99.853098 (59816/59904)
(1638894203.0508835, 1638894302.8386908, 99.78780722618103)
Test epoch: 17| Acc: 99.44 (9944/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.005293 | Loss_in_diffu: 6.124158 | Loss_out_diffu: 8.069531 | Acc: 99.848090 (59813/59904)
(1638894303.453127, 1638894402.5983365, 99.14520955085754)
Test epoch: 18| Acc: 99.5 (9950/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.005096 | Loss_in_diffu: 6.087309 | Loss_out_diffu: 8.039995 | Acc: 99.864784 (59823/59904)
(1638894403.2088873, 1638894502.5298836, 99.32099628448486)
Test epoch: 19| Acc: 99.38 (9938/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004472 | Loss_in_diffu: 6.050099 | Loss_out_diffu: 8.011681 | Acc: 99.894832 (59841/59904)
(1638894503.2376137, 1638894603.1226666, 99.88505291938782)
Test epoch: 20| Acc: 99.46 (9946/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002493 | Loss_in_diffu: 6.028695 | Loss_out_diffu: 7.995008 | Acc: 99.958267 (59879/59904)
(1638894603.7224348, 1638894702.8183463, 99.09591150283813)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002198 | Loss_in_diffu: 6.024309 | Loss_out_diffu: 7.991237 | Acc: 99.968283 (59885/59904)
(1638894703.5395374, 1638894802.7113943, 99.17185688018799)
Test epoch: 22| Acc: 99.5 (9950/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.002125 | Loss_in_diffu: 6.020454 | Loss_out_diffu: 7.987966 | Acc: 99.969952 (59886/59904)
(1638894803.4330745, 1638894902.5753746, 99.14230012893677)
Test epoch: 23| Acc: 99.53 (9953/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.002110 | Loss_in_diffu: 6.015663 | Loss_out_diffu: 7.984318 | Acc: 99.968283 (59885/59904)
(1638894903.1849055, 1638895002.4636316, 99.27872610092163)
Test epoch: 24| Acc: 99.51 (9951/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001999 | Loss_in_diffu: 6.011525 | Loss_out_diffu: 7.980865 | Acc: 99.969952 (59886/59904)
(1638895003.185249, 1638895103.4887908, 100.30354166030884)
Test epoch: 25| Acc: 99.48 (9948/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001917 | Loss_in_diffu: 6.006673 | Loss_out_diffu: 7.977321 | Acc: 99.973291 (59888/59904)
(1638895104.2002528, 1638895204.429143, 100.22889018058777)
Test epoch: 26| Acc: 99.48 (9948/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001875 | Loss_in_diffu: 6.002577 | Loss_out_diffu: 7.973762 | Acc: 99.974960 (59889/59904)
(1638895205.0314417, 1638895304.1089237, 99.07748198509216)
Test epoch: 27| Acc: 99.48 (9948/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001775 | Loss_in_diffu: 5.997954 | Loss_out_diffu: 7.970624 | Acc: 99.971621 (59887/59904)
(1638895304.82297, 1638895405.0752673, 100.25229740142822)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001724 | Loss_in_diffu: 5.993652 | Loss_out_diffu: 7.967100 | Acc: 99.979968 (59892/59904)
(1638895405.7890224, 1638895505.5736141, 99.78459167480469)
Test epoch: 29| Acc: 99.53 (9953/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001716 | Loss_in_diffu: 5.989216 | Loss_out_diffu: 7.963894 | Acc: 99.981637 (59893/59904)
(1638895506.315773, 1638895606.1559052, 99.84013223648071)
Test epoch: 30| Acc: 99.5 (9950/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001537 | Loss_in_diffu: 5.986607 | Loss_out_diffu: 7.962136 | Acc: 99.984976 (59895/59904)
(1638895606.752277, 1638895706.3865526, 99.63427567481995)
Test epoch: 31| Acc: 99.5 (9950/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001546 | Loss_in_diffu: 5.986506 | Loss_out_diffu: 7.962295 | Acc: 99.981637 (59893/59904)
(1638895706.996886, 1638895806.1157236, 99.11883759498596)
Test epoch: 32| Acc: 99.51 (9951/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001536 | Loss_in_diffu: 5.985906 | Loss_out_diffu: 7.961907 | Acc: 99.979968 (59892/59904)
(1638895806.8334918, 1638895907.0866456, 100.25315380096436)
Test epoch: 33| Acc: 99.5 (9950/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001555 | Loss_in_diffu: 5.985406 | Loss_out_diffu: 7.961761 | Acc: 99.981637 (59893/59904)
(1638895907.6973658, 1638896007.3951573, 99.6977915763855)
Test epoch: 34| Acc: 99.5 (9950/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001501 | Loss_in_diffu: 5.985142 | Loss_out_diffu: 7.961440 | Acc: 99.984976 (59895/59904)
(1638896008.0018744, 1638896107.715533, 99.71365857124329)
Test epoch: 35| Acc: 99.49 (9949/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001495 | Loss_in_diffu: 5.984486 | Loss_out_diffu: 7.961116 | Acc: 99.983307 (59894/59904)
(1638896108.3233118, 1638896207.4602673, 99.13695549964905)
Test epoch: 36| Acc: 99.54 (9954/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001534 | Loss_in_diffu: 5.983699 | Loss_out_diffu: 7.960610 | Acc: 99.983307 (59894/59904)
(1638896208.070349, 1638896307.8826246, 99.81227564811707)
Test epoch: 37| Acc: 99.51 (9951/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001522 | Loss_in_diffu: 5.983401 | Loss_out_diffu: 7.960789 | Acc: 99.983307 (59894/59904)
(1638896308.471871, 1638896408.4007175, 99.92884659767151)
Test epoch: 38| Acc: 99.52 (9952/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001506 | Loss_in_diffu: 5.983129 | Loss_out_diffu: 7.960275 | Acc: 99.983307 (59894/59904)
(1638896409.0048027, 1638896508.0114865, 99.00668382644653)
Test epoch: 39| Acc: 99.54 (9954/10000) 
