True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.588523 | Loss_in_diffu: 11.557223 | Loss_out_diffu: 12.066997 | Acc: 87.106036 (52180/59904)
(1679158488.6578395, 1679158768.6781104, 280.0202708244324)
Test epoch: 0| Acc: 96.73 (9673/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.100438 | Loss_in_diffu: 11.119636 | Loss_out_diffu: 12.397681 | Acc: 97.364116 (58325/59904)
(1679158769.929623, 1679159048.035934, 278.10631108283997)
Test epoch: 1| Acc: 96.7 (9670/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.070118 | Loss_in_diffu: 11.063816 | Loss_out_diffu: 12.434053 | Acc: 98.127003 (58782/59904)
(1679159049.2865, 1679159328.082803, 278.79630303382874)
Test epoch: 2| Acc: 98.73 (9873/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.054211 | Loss_in_diffu: 11.008885 | Loss_out_diffu: 12.408076 | Acc: 98.454193 (58978/59904)
(1679159329.2842689, 1679159607.002455, 277.7181861400604)
Test epoch: 3| Acc: 98.57 (9857/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.047840 | Loss_in_diffu: 10.956588 | Loss_out_diffu: 12.384301 | Acc: 98.626135 (59081/59904)
(1679159608.2217798, 1679159887.7429843, 279.52120447158813)
Test epoch: 4| Acc: 98.88 (9888/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.039709 | Loss_in_diffu: 10.896841 | Loss_out_diffu: 12.366303 | Acc: 98.843149 (59211/59904)
(1679159888.9816353, 1679160167.6849034, 278.70326805114746)
Test epoch: 5| Acc: 98.78 (9878/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.034917 | Loss_in_diffu: 10.827411 | Loss_out_diffu: 12.330538 | Acc: 99.006744 (59309/59904)
(1679160168.9010692, 1679160444.4008098, 275.49974060058594)
Test epoch: 6| Acc: 99.05 (9905/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.032694 | Loss_in_diffu: 10.753937 | Loss_out_diffu: 12.296964 | Acc: 99.018429 (59316/59904)
(1679160445.6106966, 1679160723.868293, 278.25759649276733)
Test epoch: 7| Acc: 98.65 (9865/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.027404 | Loss_in_diffu: 10.680395 | Loss_out_diffu: 12.233285 | Acc: 99.205395 (59428/59904)
(1679160725.1126678, 1679161003.7774282, 278.66476035118103)
Test epoch: 8| Acc: 98.29 (9829/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.027980 | Loss_in_diffu: 10.608091 | Loss_out_diffu: 12.165732 | Acc: 99.158654 (59400/59904)
(1679161005.022504, 1679161283.8668125, 278.84430837631226)
Test epoch: 9| Acc: 99.17 (9917/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026801 | Loss_in_diffu: 10.528841 | Loss_out_diffu: 12.105704 | Acc: 99.238782 (59448/59904)
(1679161285.0846863, 1679161564.0952187, 279.0105323791504)
Test epoch: 10| Acc: 99.22 (9922/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009294 | Loss_in_diffu: 10.474203 | Loss_out_diffu: 12.094624 | Acc: 99.779647 (59772/59904)
(1679161565.33699, 1679161844.557818, 279.22082781791687)
Test epoch: 11| Acc: 99.55 (9955/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006522 | Loss_in_diffu: 10.452777 | Loss_out_diffu: 12.077395 | Acc: 99.823050 (59798/59904)
(1679161845.7643921, 1679162123.0490282, 277.2846360206604)
Test epoch: 12| Acc: 99.49 (9949/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005648 | Loss_in_diffu: 10.430203 | Loss_out_diffu: 12.062059 | Acc: 99.849760 (59814/59904)
(1679162124.297276, 1679162401.645066, 277.3477900028229)
Test epoch: 13| Acc: 99.5 (9950/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004723 | Loss_in_diffu: 10.405552 | Loss_out_diffu: 12.041483 | Acc: 99.894832 (59841/59904)
(1679162402.8653042, 1679162676.7130153, 273.8477110862732)
Test epoch: 14| Acc: 99.45 (9945/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004746 | Loss_in_diffu: 10.381149 | Loss_out_diffu: 12.019710 | Acc: 99.883146 (59834/59904)
(1679162677.9345975, 1679162952.056983, 274.1223855018616)
Test epoch: 15| Acc: 99.46 (9946/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003407 | Loss_in_diffu: 10.355330 | Loss_out_diffu: 12.001456 | Acc: 99.933226 (59864/59904)
(1679162953.256915, 1679163231.5399413, 278.2830262184143)
Test epoch: 16| Acc: 99.43 (9943/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003290 | Loss_in_diffu: 10.328950 | Loss_out_diffu: 11.982535 | Acc: 99.926549 (59860/59904)
(1679163232.7901819, 1679163510.7212372, 277.9310553073883)
Test epoch: 17| Acc: 99.4 (9940/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003227 | Loss_in_diffu: 10.303096 | Loss_out_diffu: 11.964286 | Acc: 99.923210 (59858/59904)
(1679163511.9686553, 1679163791.991095, 280.02243971824646)
Test epoch: 18| Acc: 99.44 (9944/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002800 | Loss_in_diffu: 10.278991 | Loss_out_diffu: 11.938519 | Acc: 99.943243 (59870/59904)
(1679163793.1968174, 1679164068.734052, 275.537234544754)
Test epoch: 19| Acc: 99.45 (9945/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002611 | Loss_in_diffu: 10.253658 | Loss_out_diffu: 11.920895 | Acc: 99.943243 (59870/59904)
(1679164069.9899669, 1679164348.9919274, 279.00196051597595)
Test epoch: 20| Acc: 99.42 (9942/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001863 | Loss_in_diffu: 10.239591 | Loss_out_diffu: 11.911919 | Acc: 99.973291 (59888/59904)
(1679164350.237633, 1679164630.3429472, 280.10531425476074)
Test epoch: 21| Acc: 99.48 (9948/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001602 | Loss_in_diffu: 10.236430 | Loss_out_diffu: 11.909943 | Acc: 99.979968 (59892/59904)
(1679164631.5450358, 1679164911.3089168, 279.7638809680939)
Test epoch: 22| Acc: 99.47 (9947/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001558 | Loss_in_diffu: 10.233756 | Loss_out_diffu: 11.907770 | Acc: 99.981637 (59893/59904)
(1679164912.5397978, 1679165190.592107, 278.05230927467346)
Test epoch: 23| Acc: 99.46 (9946/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001486 | Loss_in_diffu: 10.229960 | Loss_out_diffu: 11.905370 | Acc: 99.981637 (59893/59904)
(1679165191.8396115, 1679165470.1836603, 278.3440487384796)
Test epoch: 24| Acc: 99.48 (9948/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001451 | Loss_in_diffu: 10.226804 | Loss_out_diffu: 11.903110 | Acc: 99.979968 (59892/59904)
(1679165471.4344018, 1679165750.8050377, 279.3706359863281)
Test epoch: 25| Acc: 99.47 (9947/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001418 | Loss_in_diffu: 10.222899 | Loss_out_diffu: 11.900609 | Acc: 99.983307 (59894/59904)
(1679165752.0375466, 1679166030.757045, 278.7194983959198)
Test epoch: 26| Acc: 99.5 (9950/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001370 | Loss_in_diffu: 10.219739 | Loss_out_diffu: 11.897334 | Acc: 99.983307 (59894/59904)
(1679166031.9605184, 1679166314.898891, 282.9383726119995)
Test epoch: 27| Acc: 99.47 (9947/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001339 | Loss_in_diffu: 10.216030 | Loss_out_diffu: 11.895696 | Acc: 99.984976 (59895/59904)
(1679166316.1388175, 1679166595.6762044, 279.5373868942261)
Test epoch: 28| Acc: 99.48 (9948/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001310 | Loss_in_diffu: 10.212630 | Loss_out_diffu: 11.892684 | Acc: 99.986645 (59896/59904)
(1679166596.8899927, 1679166877.2968426, 280.406849861145)
Test epoch: 29| Acc: 99.48 (9948/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001259 | Loss_in_diffu: 10.209115 | Loss_out_diffu: 11.890919 | Acc: 99.984976 (59895/59904)
(1679166878.5142407, 1679167158.1827235, 279.66848278045654)
Test epoch: 30| Acc: 99.49 (9949/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001180 | Loss_in_diffu: 10.207080 | Loss_out_diffu: 11.890045 | Acc: 99.986645 (59896/59904)
(1679167159.4225118, 1679167438.281843, 278.85933113098145)
Test epoch: 31| Acc: 99.47 (9947/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001174 | Loss_in_diffu: 10.207038 | Loss_out_diffu: 11.890024 | Acc: 99.986645 (59896/59904)
(1679167439.5006406, 1679167720.4344754, 280.9338347911835)
Test epoch: 32| Acc: 99.46 (9946/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001171 | Loss_in_diffu: 10.206547 | Loss_out_diffu: 11.889585 | Acc: 99.986645 (59896/59904)
(1679167721.6186104, 1679168002.1130593, 280.4944489002228)
Test epoch: 33| Acc: 99.46 (9946/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001158 | Loss_in_diffu: 10.206106 | Loss_out_diffu: 11.889519 | Acc: 99.986645 (59896/59904)
(1679168003.3597667, 1679168283.876509, 280.51674222946167)
Test epoch: 34| Acc: 99.47 (9947/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001152 | Loss_in_diffu: 10.205939 | Loss_out_diffu: 11.889282 | Acc: 99.986645 (59896/59904)
(1679168285.1280348, 1679168565.8282185, 280.7001836299896)
Test epoch: 35| Acc: 99.46 (9946/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001149 | Loss_in_diffu: 10.205410 | Loss_out_diffu: 11.888936 | Acc: 99.986645 (59896/59904)
(1679168567.0688136, 1679168847.0849838, 280.0161702632904)
Test epoch: 36| Acc: 99.47 (9947/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001147 | Loss_in_diffu: 10.204708 | Loss_out_diffu: 11.888765 | Acc: 99.986645 (59896/59904)
(1679168848.303586, 1679169127.7321894, 279.4286034107208)
Test epoch: 37| Acc: 99.47 (9947/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001136 | Loss_in_diffu: 10.204499 | Loss_out_diffu: 11.888992 | Acc: 99.986645 (59896/59904)
(1679169128.9750257, 1679169282.9453015, 153.97027587890625)
Test epoch: 38| Acc: 99.47 (9947/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001126 | Loss_in_diffu: 10.204305 | Loss_out_diffu: 11.888597 | Acc: 99.986645 (59896/59904)
(1679169284.159551, 1679169438.548019, 154.38846802711487)
Test epoch: 39| Acc: 99.47 (9947/10000) 
