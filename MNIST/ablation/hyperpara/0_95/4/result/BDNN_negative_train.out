True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.639960 | Loss_in_diffu: 11.339791 | Loss_out_diffu: 11.702964 | Acc: 85.606971 (51282/59904)
(1679147840.9615455, 1679147941.736093, 100.7745475769043)
Test epoch: 0| Acc: 96.93 (9693/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.110879 | Loss_in_diffu: 10.560227 | Loss_out_diffu: 11.742553 | Acc: 97.068643 (58148/59904)
(1679147942.3051057, 1679148039.257091, 96.9519853591919)
Test epoch: 1| Acc: 97.4 (9740/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.075478 | Loss_in_diffu: 10.217224 | Loss_out_diffu: 11.542948 | Acc: 97.914997 (58655/59904)
(1679148039.8268437, 1679148136.7714229, 96.94457912445068)
Test epoch: 2| Acc: 98.34 (9834/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.060563 | Loss_in_diffu: 9.884013 | Loss_out_diffu: 11.271841 | Acc: 98.255542 (58859/59904)
(1679148137.3332336, 1679148234.9538374, 97.62060379981995)
Test epoch: 3| Acc: 98.6 (9860/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.047381 | Loss_in_diffu: 9.556353 | Loss_out_diffu: 10.992876 | Acc: 98.671207 (59108/59904)
(1679148235.5257342, 1679148333.388916, 97.86318182945251)
Test epoch: 4| Acc: 98.74 (9874/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.047497 | Loss_in_diffu: 9.254881 | Loss_out_diffu: 10.722441 | Acc: 98.652845 (59097/59904)
(1679148333.9543571, 1679148431.706488, 97.75213074684143)
Test epoch: 5| Acc: 98.24 (9824/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.041610 | Loss_in_diffu: 8.974444 | Loss_out_diffu: 10.567500 | Acc: 98.816440 (59195/59904)
(1679148432.2654214, 1679148529.931975, 97.66655349731445)
Test epoch: 6| Acc: 99.0 (9900/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.040531 | Loss_in_diffu: 8.719770 | Loss_out_diffu: 10.443089 | Acc: 98.806424 (59189/59904)
(1679148530.4919276, 1679148628.1627765, 97.67084884643555)
Test epoch: 7| Acc: 98.91 (9891/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.033443 | Loss_in_diffu: 8.473214 | Loss_out_diffu: 10.214058 | Acc: 99.006744 (59309/59904)
(1679148628.7217195, 1679148726.1908035, 97.46908402442932)
Test epoch: 8| Acc: 98.67 (9867/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.031483 | Loss_in_diffu: 8.235713 | Loss_out_diffu: 9.970414 | Acc: 99.085203 (59356/59904)
(1679148726.7509243, 1679148823.8999283, 97.14900398254395)
Test epoch: 9| Acc: 99.2 (9920/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.030523 | Loss_in_diffu: 8.005781 | Loss_out_diffu: 9.767101 | Acc: 99.145299 (59392/59904)
(1679148824.4701226, 1679148922.1051686, 97.63504600524902)
Test epoch: 10| Acc: 99.18 (9918/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.010649 | Loss_in_diffu: 7.871559 | Loss_out_diffu: 9.659605 | Acc: 99.722890 (59738/59904)
(1679148922.6782386, 1679149019.9950597, 97.31682109832764)
Test epoch: 11| Acc: 99.51 (9951/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.008141 | Loss_in_diffu: 7.837215 | Loss_out_diffu: 9.632524 | Acc: 99.794671 (59781/59904)
(1679149020.5723572, 1679149117.8699923, 97.29763507843018)
Test epoch: 12| Acc: 99.5 (9950/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.007299 | Loss_in_diffu: 7.802297 | Loss_out_diffu: 9.603159 | Acc: 99.808026 (59789/59904)
(1679149118.4431863, 1679149216.2470512, 97.8038649559021)
Test epoch: 13| Acc: 99.52 (9952/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006157 | Loss_in_diffu: 7.767089 | Loss_out_diffu: 9.576098 | Acc: 99.846421 (59812/59904)
(1679149216.815191, 1679149314.1348948, 97.31970381736755)
Test epoch: 14| Acc: 99.39 (9939/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005869 | Loss_in_diffu: 7.733766 | Loss_out_diffu: 9.550254 | Acc: 99.846421 (59812/59904)
(1679149314.6983507, 1679149411.7277217, 97.0293710231781)
Test epoch: 15| Acc: 99.45 (9945/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004803 | Loss_in_diffu: 7.701364 | Loss_out_diffu: 9.525141 | Acc: 99.878138 (59831/59904)
(1679149412.2869525, 1679149509.292476, 97.00552344322205)
Test epoch: 16| Acc: 99.42 (9942/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004690 | Loss_in_diffu: 7.671175 | Loss_out_diffu: 9.502151 | Acc: 99.874800 (59829/59904)
(1679149509.8648093, 1679149606.9366171, 97.07180786132812)
Test epoch: 17| Acc: 99.42 (9942/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004401 | Loss_in_diffu: 7.642353 | Loss_out_diffu: 9.481320 | Acc: 99.868122 (59825/59904)
(1679149607.5086381, 1679149704.6745389, 97.16590070724487)
Test epoch: 18| Acc: 99.47 (9947/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003469 | Loss_in_diffu: 7.614824 | Loss_out_diffu: 9.461154 | Acc: 99.918202 (59855/59904)
(1679149705.2343156, 1679149802.8728495, 97.6385338306427)
Test epoch: 19| Acc: 99.34 (9934/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004273 | Loss_in_diffu: 7.588168 | Loss_out_diffu: 9.442277 | Acc: 99.886485 (59836/59904)
(1679149803.4436803, 1679149900.9133213, 97.4696409702301)
Test epoch: 20| Acc: 99.48 (9948/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002287 | Loss_in_diffu: 7.573057 | Loss_out_diffu: 9.432200 | Acc: 99.961605 (59881/59904)
(1679149901.4868753, 1679149999.1374574, 97.65058207511902)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001842 | Loss_in_diffu: 7.569734 | Loss_out_diffu: 9.430228 | Acc: 99.976629 (59890/59904)
(1679149999.709016, 1679150096.7726066, 97.06359052658081)
Test epoch: 22| Acc: 99.51 (9951/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001720 | Loss_in_diffu: 7.567020 | Loss_out_diffu: 9.427911 | Acc: 99.974960 (59889/59904)
(1679150097.3435261, 1679150194.4433346, 97.09980845451355)
Test epoch: 23| Acc: 99.5 (9950/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001623 | Loss_in_diffu: 7.563195 | Loss_out_diffu: 9.425141 | Acc: 99.979968 (59892/59904)
(1679150195.0141835, 1679150292.10994, 97.09575653076172)
Test epoch: 24| Acc: 99.51 (9951/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001539 | Loss_in_diffu: 7.559922 | Loss_out_diffu: 9.422372 | Acc: 99.984976 (59895/59904)
(1679150292.6760032, 1679150389.7616892, 97.08568596839905)
Test epoch: 25| Acc: 99.48 (9948/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001520 | Loss_in_diffu: 7.555870 | Loss_out_diffu: 9.419264 | Acc: 99.979968 (59892/59904)
(1679150390.3226228, 1679150487.4792776, 97.15665483474731)
Test epoch: 26| Acc: 99.49 (9949/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001444 | Loss_in_diffu: 7.552503 | Loss_out_diffu: 9.416186 | Acc: 99.983307 (59894/59904)
(1679150488.042705, 1679150586.014746, 97.97204089164734)
Test epoch: 27| Acc: 99.49 (9949/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001400 | Loss_in_diffu: 7.548561 | Loss_out_diffu: 9.413562 | Acc: 99.984976 (59895/59904)
(1679150586.5763478, 1679150684.4967854, 97.9204375743866)
Test epoch: 28| Acc: 99.48 (9948/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001349 | Loss_in_diffu: 7.544920 | Loss_out_diffu: 9.410598 | Acc: 99.984976 (59895/59904)
(1679150685.0711484, 1679150783.0183308, 97.9471824169159)
Test epoch: 29| Acc: 99.53 (9953/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001306 | Loss_in_diffu: 7.541126 | Loss_out_diffu: 9.407769 | Acc: 99.984976 (59895/59904)
(1679150783.5877502, 1679150881.4711835, 97.88343334197998)
Test epoch: 30| Acc: 99.51 (9951/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001202 | Loss_in_diffu: 7.538931 | Loss_out_diffu: 9.406535 | Acc: 99.988315 (59897/59904)
(1679150882.04362, 1679150979.633726, 97.59010577201843)
Test epoch: 31| Acc: 99.51 (9951/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001192 | Loss_in_diffu: 7.538863 | Loss_out_diffu: 9.406720 | Acc: 99.989984 (59898/59904)
(1679150980.1970196, 1679151077.3010533, 97.10403370857239)
Test epoch: 32| Acc: 99.5 (9950/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001172 | Loss_in_diffu: 7.538338 | Loss_out_diffu: 9.406209 | Acc: 99.988315 (59897/59904)
(1679151077.860793, 1679151175.7140536, 97.85326051712036)
Test epoch: 33| Acc: 99.49 (9949/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001184 | Loss_in_diffu: 7.537865 | Loss_out_diffu: 9.406051 | Acc: 99.989984 (59898/59904)
(1679151176.2821457, 1679151274.1839159, 97.90177011489868)
Test epoch: 34| Acc: 99.46 (9946/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001175 | Loss_in_diffu: 7.537652 | Loss_out_diffu: 9.405952 | Acc: 99.991653 (59899/59904)
(1679151274.7560987, 1679151372.1885223, 97.43242359161377)
Test epoch: 35| Acc: 99.5 (9950/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001165 | Loss_in_diffu: 7.537085 | Loss_out_diffu: 9.405851 | Acc: 99.988315 (59897/59904)
(1679151372.7500885, 1679151470.420901, 97.67081260681152)
Test epoch: 36| Acc: 99.52 (9952/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001152 | Loss_in_diffu: 7.536325 | Loss_out_diffu: 9.405327 | Acc: 99.988315 (59897/59904)
(1679151470.9953172, 1679151568.8579848, 97.86266756057739)
Test epoch: 37| Acc: 99.49 (9949/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001164 | Loss_in_diffu: 7.536075 | Loss_out_diffu: 9.405439 | Acc: 99.988315 (59897/59904)
(1679151569.4284809, 1679151667.0534647, 97.62498378753662)
Test epoch: 38| Acc: 99.51 (9951/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001153 | Loss_in_diffu: 7.535860 | Loss_out_diffu: 9.404959 | Acc: 99.989984 (59898/59904)
(1679151667.6267197, 1679151765.3981137, 97.77139401435852)
Test epoch: 39| Acc: 99.52 (9952/10000) 
