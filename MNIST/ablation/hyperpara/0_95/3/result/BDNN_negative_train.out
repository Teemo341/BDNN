True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.690724 | Loss_in_diffu: 11.695529 | Loss_out_diffu: 12.121843 | Acc: 83.895900 (50257/59904)
(1679158440.489982, 1679158538.2056248, 97.71564292907715)
Test epoch: 0| Acc: 96.39 (9639/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.115683 | Loss_in_diffu: 11.170940 | Loss_out_diffu: 12.590823 | Acc: 96.990184 (58101/59904)
(1679158538.795985, 1679158636.8633978, 98.06741285324097)
Test epoch: 1| Acc: 97.63 (9763/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.073182 | Loss_in_diffu: 11.107407 | Loss_out_diffu: 12.665026 | Acc: 97.948384 (58675/59904)
(1679158637.4415276, 1679158734.6620293, 97.22050166130066)
Test epoch: 2| Acc: 98.38 (9838/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.056864 | Loss_in_diffu: 11.048660 | Loss_out_diffu: 12.677672 | Acc: 98.409121 (58951/59904)
(1679158735.2433066, 1679158832.874436, 97.63112926483154)
Test epoch: 3| Acc: 99.03 (9903/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048456 | Loss_in_diffu: 10.991257 | Loss_out_diffu: 12.645100 | Acc: 98.647837 (59094/59904)
(1679158833.4643638, 1679158931.1066287, 97.64226484298706)
Test epoch: 4| Acc: 98.5 (9850/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.041966 | Loss_in_diffu: 10.930520 | Loss_out_diffu: 12.589155 | Acc: 98.779714 (59173/59904)
(1679158931.6976016, 1679159029.5250025, 97.82740092277527)
Test epoch: 5| Acc: 98.94 (9894/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037486 | Loss_in_diffu: 10.868580 | Loss_out_diffu: 12.549689 | Acc: 98.921608 (59258/59904)
(1679159030.1133232, 1679159127.5532515, 97.43992829322815)
Test epoch: 6| Acc: 99.12 (9912/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.033461 | Loss_in_diffu: 10.805127 | Loss_out_diffu: 12.511899 | Acc: 99.020099 (59317/59904)
(1679159128.1431234, 1679159226.1444085, 98.00128507614136)
Test epoch: 7| Acc: 98.7 (9870/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.029471 | Loss_in_diffu: 10.740967 | Loss_out_diffu: 12.414723 | Acc: 99.145299 (59392/59904)
(1679159226.721052, 1679159323.7633774, 97.04232549667358)
Test epoch: 8| Acc: 99.16 (9916/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.028212 | Loss_in_diffu: 10.676814 | Loss_out_diffu: 12.376402 | Acc: 99.198718 (59424/59904)
(1679159324.3449295, 1679159422.302823, 97.95789361000061)
Test epoch: 9| Acc: 99.26 (9926/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026999 | Loss_in_diffu: 10.611898 | Loss_out_diffu: 12.320491 | Acc: 99.197049 (59423/59904)
(1679159422.8923833, 1679159520.9471803, 98.05479693412781)
Test epoch: 10| Acc: 99.11 (9911/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009636 | Loss_in_diffu: 10.563803 | Loss_out_diffu: 12.308482 | Acc: 99.749599 (59754/59904)
(1679159521.5377438, 1679159619.3498132, 97.81206941604614)
Test epoch: 11| Acc: 99.44 (9944/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006922 | Loss_in_diffu: 10.542626 | Loss_out_diffu: 12.292529 | Acc: 99.831397 (59803/59904)
(1679159619.9397638, 1679159718.036616, 98.09685230255127)
Test epoch: 12| Acc: 99.46 (9946/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006106 | Loss_in_diffu: 10.520572 | Loss_out_diffu: 12.277671 | Acc: 99.856437 (59818/59904)
(1679159718.6156871, 1679159816.0528965, 97.43720936775208)
Test epoch: 13| Acc: 99.46 (9946/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005436 | Loss_in_diffu: 10.496433 | Loss_out_diffu: 12.261055 | Acc: 99.869792 (59826/59904)
(1679159816.6409786, 1679159914.2389867, 97.59800815582275)
Test epoch: 14| Acc: 99.47 (9947/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005018 | Loss_in_diffu: 10.472283 | Loss_out_diffu: 12.245871 | Acc: 99.871461 (59827/59904)
(1679159914.8297148, 1679160012.9028876, 98.07317280769348)
Test epoch: 15| Acc: 99.31 (9931/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004409 | Loss_in_diffu: 10.447946 | Loss_out_diffu: 12.231337 | Acc: 99.896501 (59842/59904)
(1679160013.491016, 1679160110.538232, 97.0472161769867)
Test epoch: 16| Acc: 99.51 (9951/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003776 | Loss_in_diffu: 10.422798 | Loss_out_diffu: 12.217409 | Acc: 99.911525 (59851/59904)
(1679160111.1280723, 1679160208.2698162, 97.14174389839172)
Test epoch: 17| Acc: 99.37 (9937/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003545 | Loss_in_diffu: 10.397408 | Loss_out_diffu: 12.200170 | Acc: 99.918202 (59855/59904)
(1679160208.8580272, 1679160306.3247423, 97.46671509742737)
Test epoch: 18| Acc: 99.42 (9942/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003044 | Loss_in_diffu: 10.373039 | Loss_out_diffu: 12.179961 | Acc: 99.941573 (59869/59904)
(1679160306.9039724, 1679160404.5879512, 97.68397879600525)
Test epoch: 19| Acc: 99.44 (9944/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002936 | Loss_in_diffu: 10.347302 | Loss_out_diffu: 12.164847 | Acc: 99.931557 (59863/59904)
(1679160405.1785002, 1679160502.2059863, 97.02748608589172)
Test epoch: 20| Acc: 99.51 (9951/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002035 | Loss_in_diffu: 10.333171 | Loss_out_diffu: 12.156696 | Acc: 99.969952 (59886/59904)
(1679160502.7926838, 1679160600.7036507, 97.91096687316895)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001847 | Loss_in_diffu: 10.330044 | Loss_out_diffu: 12.154854 | Acc: 99.973291 (59888/59904)
(1679160601.2851696, 1679160698.6624491, 97.37727952003479)
Test epoch: 22| Acc: 99.52 (9952/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001788 | Loss_in_diffu: 10.327397 | Loss_out_diffu: 12.153037 | Acc: 99.973291 (59888/59904)
(1679160699.2492633, 1679160796.3090422, 97.05977892875671)
Test epoch: 23| Acc: 99.51 (9951/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001706 | Loss_in_diffu: 10.323628 | Loss_out_diffu: 12.151019 | Acc: 99.978299 (59891/59904)
(1679160796.8971376, 1679160894.0188932, 97.12175559997559)
Test epoch: 24| Acc: 99.5 (9950/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001664 | Loss_in_diffu: 10.320527 | Loss_out_diffu: 12.148658 | Acc: 99.974960 (59889/59904)
(1679160894.5980716, 1679160991.694686, 97.09661436080933)
Test epoch: 25| Acc: 99.5 (9950/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001596 | Loss_in_diffu: 10.316717 | Loss_out_diffu: 12.146283 | Acc: 99.976629 (59890/59904)
(1679160992.2867315, 1679161090.3285954, 98.04186391830444)
Test epoch: 26| Acc: 99.46 (9946/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001525 | Loss_in_diffu: 10.313652 | Loss_out_diffu: 12.143711 | Acc: 99.979968 (59892/59904)
(1679161090.9196033, 1679161187.9583309, 97.03872752189636)
Test epoch: 27| Acc: 99.48 (9948/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001484 | Loss_in_diffu: 10.310055 | Loss_out_diffu: 12.141452 | Acc: 99.981637 (59893/59904)
(1679161188.5376496, 1679161285.7585618, 97.22091221809387)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001447 | Loss_in_diffu: 10.306762 | Loss_out_diffu: 12.138722 | Acc: 99.979968 (59892/59904)
(1679161286.3485372, 1679161383.3919194, 97.04338216781616)
Test epoch: 29| Acc: 99.5 (9950/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001385 | Loss_in_diffu: 10.303305 | Loss_out_diffu: 12.136853 | Acc: 99.979968 (59892/59904)
(1679161383.9694743, 1679161481.0061924, 97.0367181301117)
Test epoch: 30| Acc: 99.48 (9948/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001279 | Loss_in_diffu: 10.301298 | Loss_out_diffu: 12.135268 | Acc: 99.983307 (59894/59904)
(1679161481.59893, 1679161579.147877, 97.54894709587097)
Test epoch: 31| Acc: 99.49 (9949/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001267 | Loss_in_diffu: 10.301256 | Loss_out_diffu: 12.135162 | Acc: 99.984976 (59895/59904)
(1679161579.737529, 1679161677.8741908, 98.1366617679596)
Test epoch: 32| Acc: 99.47 (9947/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001267 | Loss_in_diffu: 10.300773 | Loss_out_diffu: 12.134849 | Acc: 99.984976 (59895/59904)
(1679161678.461721, 1679161775.5218527, 97.06013178825378)
Test epoch: 33| Acc: 99.48 (9948/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001256 | Loss_in_diffu: 10.300329 | Loss_out_diffu: 12.134808 | Acc: 99.984976 (59895/59904)
(1679161776.1044998, 1679161873.1938424, 97.08934259414673)
Test epoch: 34| Acc: 99.48 (9948/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001255 | Loss_in_diffu: 10.300157 | Loss_out_diffu: 12.134451 | Acc: 99.984976 (59895/59904)
(1679161873.7811093, 1679161971.8867867, 98.10567736625671)
Test epoch: 35| Acc: 99.49 (9949/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001244 | Loss_in_diffu: 10.299622 | Loss_out_diffu: 12.134122 | Acc: 99.984976 (59895/59904)
(1679161972.4804184, 1679162069.6103082, 97.1298897266388)
Test epoch: 36| Acc: 99.49 (9949/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001241 | Loss_in_diffu: 10.298918 | Loss_out_diffu: 12.133888 | Acc: 99.984976 (59895/59904)
(1679162070.2005842, 1679162167.7210882, 97.52050399780273)
Test epoch: 37| Acc: 99.51 (9951/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001232 | Loss_in_diffu: 10.298706 | Loss_out_diffu: 12.133959 | Acc: 99.984976 (59895/59904)
(1679162168.3106754, 1679162265.4099967, 97.09932136535645)
Test epoch: 38| Acc: 99.5 (9950/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001219 | Loss_in_diffu: 10.298513 | Loss_out_diffu: 12.133431 | Acc: 99.984976 (59895/59904)
(1679162265.9886656, 1679162363.0641854, 97.07551980018616)
Test epoch: 39| Acc: 99.51 (9951/10000) 
