True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.666333 | Loss_in_diffu: 11.387306 | Loss_out_diffu: 11.779369 | Acc: 84.778980 (50786/59904)
(1679150629.0119278, 1679150726.4745357, 97.46260786056519)
Test epoch: 0| Acc: 95.98 (9598/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.120277 | Loss_in_diffu: 10.583073 | Loss_out_diffu: 11.913178 | Acc: 96.696381 (57925/59904)
(1679150727.1165113, 1679150824.0572793, 96.94076800346375)
Test epoch: 1| Acc: 97.36 (9736/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.075386 | Loss_in_diffu: 10.228238 | Loss_out_diffu: 11.674174 | Acc: 97.956731 (58680/59904)
(1679150824.644193, 1679150921.4601984, 96.81600546836853)
Test epoch: 2| Acc: 98.58 (9858/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.060500 | Loss_in_diffu: 9.885335 | Loss_out_diffu: 11.395031 | Acc: 98.260550 (58862/59904)
(1679150922.036546, 1679151018.7671297, 96.73058366775513)
Test epoch: 3| Acc: 98.71 (9871/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.052793 | Loss_in_diffu: 9.566983 | Loss_out_diffu: 11.116611 | Acc: 98.494257 (59002/59904)
(1679151019.3444736, 1679151116.100868, 96.7563943862915)
Test epoch: 4| Acc: 98.81 (9881/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.043937 | Loss_in_diffu: 9.265090 | Loss_out_diffu: 10.838935 | Acc: 98.717949 (59136/59904)
(1679151116.6876483, 1679151213.6355407, 96.94789242744446)
Test epoch: 5| Acc: 98.67 (9867/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.040486 | Loss_in_diffu: 8.982470 | Loss_out_diffu: 10.600715 | Acc: 98.831464 (59204/59904)
(1679151214.2229135, 1679151311.7075987, 97.48468518257141)
Test epoch: 6| Acc: 98.74 (9874/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.040882 | Loss_in_diffu: 8.729783 | Loss_out_diffu: 10.458455 | Acc: 98.799746 (59185/59904)
(1679151312.2975972, 1679151409.228243, 96.93064594268799)
Test epoch: 7| Acc: 99.15 (9915/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.034985 | Loss_in_diffu: 8.489034 | Loss_out_diffu: 10.275680 | Acc: 98.980035 (59293/59904)
(1679151409.8045464, 1679151506.4788947, 96.6743483543396)
Test epoch: 8| Acc: 99.08 (9908/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.031481 | Loss_in_diffu: 8.250646 | Loss_out_diffu: 10.074597 | Acc: 99.058494 (59340/59904)
(1679151507.0667348, 1679151603.680523, 96.61378812789917)
Test epoch: 9| Acc: 98.87 (9887/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.029896 | Loss_in_diffu: 8.023442 | Loss_out_diffu: 9.877499 | Acc: 99.138622 (59388/59904)
(1679151604.3131392, 1679151701.9465005, 97.63336133956909)
Test epoch: 10| Acc: 99.22 (9922/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.011566 | Loss_in_diffu: 7.894679 | Loss_out_diffu: 9.787397 | Acc: 99.687834 (59717/59904)
(1679151702.5243819, 1679151799.2865334, 96.76215147972107)
Test epoch: 11| Acc: 99.49 (9949/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.008907 | Loss_in_diffu: 7.859459 | Loss_out_diffu: 9.763004 | Acc: 99.767962 (59765/59904)
(1679151799.8643873, 1679151896.677105, 96.81271767616272)
Test epoch: 12| Acc: 99.44 (9944/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.007442 | Loss_in_diffu: 7.823640 | Loss_out_diffu: 9.738715 | Acc: 99.804688 (59787/59904)
(1679151897.258265, 1679151994.3994586, 97.14119362831116)
Test epoch: 13| Acc: 99.49 (9949/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006111 | Loss_in_diffu: 7.787501 | Loss_out_diffu: 9.710334 | Acc: 99.858106 (59819/59904)
(1679151994.9772718, 1679152092.5613396, 97.58406782150269)
Test epoch: 14| Acc: 99.4 (9940/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006220 | Loss_in_diffu: 7.752628 | Loss_out_diffu: 9.683702 | Acc: 99.843082 (59810/59904)
(1679152093.1516902, 1679152190.7768881, 97.62519788742065)
Test epoch: 15| Acc: 99.51 (9951/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005464 | Loss_in_diffu: 7.720025 | Loss_out_diffu: 9.664613 | Acc: 99.851429 (59815/59904)
(1679152191.364754, 1679152288.2212596, 96.85650563240051)
Test epoch: 16| Acc: 99.41 (9941/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004805 | Loss_in_diffu: 7.688340 | Loss_out_diffu: 9.644322 | Acc: 99.873130 (59828/59904)
(1679152288.8071234, 1679152385.5796776, 96.77255415916443)
Test epoch: 17| Acc: 99.36 (9936/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004420 | Loss_in_diffu: 7.658244 | Loss_out_diffu: 9.629228 | Acc: 99.889824 (59838/59904)
(1679152386.1663358, 1679152483.475929, 97.3095932006836)
Test epoch: 18| Acc: 99.37 (9937/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004277 | Loss_in_diffu: 7.630210 | Loss_out_diffu: 9.610757 | Acc: 99.876469 (59830/59904)
(1679152484.0617805, 1679152580.7977073, 96.73592686653137)
Test epoch: 19| Acc: 99.42 (9942/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004068 | Loss_in_diffu: 7.601586 | Loss_out_diffu: 9.594648 | Acc: 99.894832 (59841/59904)
(1679152581.3824596, 1679152678.0762093, 96.69374966621399)
Test epoch: 20| Acc: 99.37 (9937/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002535 | Loss_in_diffu: 7.586097 | Loss_out_diffu: 9.588241 | Acc: 99.949920 (59874/59904)
(1679152678.663068, 1679152775.4234385, 96.76037049293518)
Test epoch: 21| Acc: 99.45 (9945/10000) 

Epoch: 22
