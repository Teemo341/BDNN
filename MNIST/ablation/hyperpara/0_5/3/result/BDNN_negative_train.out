True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.609425 | Loss_in_diffu: 11.102272 | Loss_out_diffu: 11.493747 | Acc: 86.404915 (51760/59904)
(1638888561.5208116, 1638888662.3723717, 100.85156011581421)
Test epoch: 0| Acc: 96.79 (9679/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.110096 | Loss_in_diffu: 10.148768 | Loss_out_diffu: 11.410685 | Acc: 97.140425 (58191/59904)
(1638888662.9805458, 1638888762.7975028, 99.81695699691772)
Test epoch: 1| Acc: 97.45 (9745/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.074161 | Loss_in_diffu: 9.653590 | Loss_out_diffu: 11.067202 | Acc: 97.923344 (58660/59904)
(1638888763.4208486, 1638888864.3520377, 100.93118906021118)
Test epoch: 2| Acc: 98.58 (9858/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.059498 | Loss_in_diffu: 9.177208 | Loss_out_diffu: 10.687365 | Acc: 98.325654 (58901/59904)
(1638888864.973233, 1638888964.8978589, 99.92462587356567)
Test epoch: 3| Acc: 98.81 (9881/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.050731 | Loss_in_diffu: 8.731623 | Loss_out_diffu: 10.307795 | Acc: 98.567708 (59046/59904)
(1638888965.5127835, 1638889065.2794762, 99.76669263839722)
Test epoch: 4| Acc: 99.02 (9902/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.044493 | Loss_in_diffu: 8.310997 | Loss_out_diffu: 9.958564 | Acc: 98.701255 (59126/59904)
(1638889065.896847, 1638889166.5467699, 100.6499228477478)
Test epoch: 5| Acc: 98.91 (9891/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.038081 | Loss_in_diffu: 7.915044 | Loss_out_diffu: 9.577314 | Acc: 98.906584 (59249/59904)
(1638889167.1691072, 1638889268.0069745, 100.83786725997925)
Test epoch: 6| Acc: 98.83 (9883/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.040167 | Loss_in_diffu: 7.546777 | Loss_out_diffu: 9.233551 | Acc: 98.789730 (59179/59904)
(1638889268.6386871, 1638889369.7151794, 101.07649230957031)
Test epoch: 7| Acc: 98.92 (9892/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.034333 | Loss_in_diffu: 7.189341 | Loss_out_diffu: 8.890727 | Acc: 98.988381 (59298/59904)
(1638889370.3379936, 1638889470.8429089, 100.50491523742676)
Test epoch: 8| Acc: 99.18 (9918/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.032492 | Loss_in_diffu: 6.841301 | Loss_out_diffu: 8.561671 | Acc: 99.108574 (59370/59904)
(1638889471.4674234, 1638889571.983747, 100.51632356643677)
Test epoch: 9| Acc: 98.75 (9875/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.029754 | Loss_in_diffu: 6.509380 | Loss_out_diffu: 8.188844 | Acc: 99.143630 (59391/59904)
(1638889572.6066873, 1638889673.4203656, 100.81367826461792)
Test epoch: 10| Acc: 98.78 (9878/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.010640 | Loss_in_diffu: 6.313939 | Loss_out_diffu: 7.983096 | Acc: 99.707866 (59729/59904)
(1638889674.0297666, 1638889773.89806, 99.86829352378845)
Test epoch: 11| Acc: 99.57 (9957/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007637 | Loss_in_diffu: 6.269502 | Loss_out_diffu: 7.950195 | Acc: 99.796341 (59782/59904)
(1638889774.530158, 1638889874.34447, 99.81431198120117)
Test epoch: 12| Acc: 99.53 (9953/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006774 | Loss_in_diffu: 6.225791 | Loss_out_diffu: 7.915747 | Acc: 99.826389 (59800/59904)
(1638889874.9551964, 1638889975.2037847, 100.24858832359314)
Test epoch: 13| Acc: 99.47 (9947/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005738 | Loss_in_diffu: 6.182209 | Loss_out_diffu: 7.884088 | Acc: 99.858106 (59819/59904)
(1638889975.824247, 1638890075.7000363, 99.8757894039154)
Test epoch: 14| Acc: 99.49 (9949/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005843 | Loss_in_diffu: 6.141054 | Loss_out_diffu: 7.852999 | Acc: 99.854768 (59817/59904)
(1638890076.321643, 1638890176.2374012, 99.91575813293457)
Test epoch: 15| Acc: 99.48 (9948/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004826 | Loss_in_diffu: 6.100442 | Loss_out_diffu: 7.821606 | Acc: 99.883146 (59834/59904)
(1638890176.8509018, 1638890276.79519, 99.94428825378418)
Test epoch: 16| Acc: 99.48 (9948/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004803 | Loss_in_diffu: 6.061882 | Loss_out_diffu: 7.794532 | Acc: 99.883146 (59834/59904)
(1638890277.417424, 1638890377.469732, 100.05230808258057)
Test epoch: 17| Acc: 99.39 (9939/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004417 | Loss_in_diffu: 6.023706 | Loss_out_diffu: 7.769211 | Acc: 99.886485 (59836/59904)
(1638890378.082881, 1638890478.0134776, 99.93059659004211)
Test epoch: 18| Acc: 99.41 (9941/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004069 | Loss_in_diffu: 5.987018 | Loss_out_diffu: 7.740906 | Acc: 99.914864 (59853/59904)
(1638890478.6328015, 1638890579.0431862, 100.41038465499878)
Test epoch: 19| Acc: 99.48 (9948/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003834 | Loss_in_diffu: 5.950405 | Loss_out_diffu: 7.709970 | Acc: 99.904848 (59847/59904)
(1638890579.6650128, 1638890680.7533226, 101.08830976486206)
Test epoch: 20| Acc: 99.3 (9930/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002525 | Loss_in_diffu: 5.930119 | Loss_out_diffu: 7.695798 | Acc: 99.944912 (59871/59904)
(1638890681.376804, 1638890781.5795395, 100.20273542404175)
Test epoch: 21| Acc: 99.51 (9951/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002080 | Loss_in_diffu: 5.925767 | Loss_out_diffu: 7.692757 | Acc: 99.958267 (59879/59904)
(1638890782.2043269, 1638890883.2448013, 101.04047441482544)
Test epoch: 22| Acc: 99.47 (9947/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001982 | Loss_in_diffu: 5.922204 | Loss_out_diffu: 7.689782 | Acc: 99.964944 (59883/59904)
(1638890883.8599398, 1638890984.1001518, 100.24021196365356)
Test epoch: 23| Acc: 99.52 (9952/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001872 | Loss_in_diffu: 5.917656 | Loss_out_diffu: 7.686876 | Acc: 99.969952 (59886/59904)
(1638890984.721931, 1638891084.9767451, 100.25481414794922)
Test epoch: 24| Acc: 99.45 (9945/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001813 | Loss_in_diffu: 5.913834 | Loss_out_diffu: 7.683527 | Acc: 99.969952 (59886/59904)
(1638891085.5942593, 1638891185.4265006, 99.83224129676819)
Test epoch: 25| Acc: 99.5 (9950/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001773 | Loss_in_diffu: 5.909235 | Loss_out_diffu: 7.679907 | Acc: 99.971621 (59887/59904)
(1638891186.0437446, 1638891286.5234091, 100.47966456413269)
Test epoch: 26| Acc: 99.48 (9948/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001678 | Loss_in_diffu: 5.905492 | Loss_out_diffu: 7.676633 | Acc: 99.974960 (59889/59904)
(1638891287.1347651, 1638891387.0016398, 99.86687469482422)
Test epoch: 27| Acc: 99.52 (9952/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001687 | Loss_in_diffu: 5.901183 | Loss_out_diffu: 7.673515 | Acc: 99.971621 (59887/59904)
(1638891387.6237893, 1638891487.4515877, 99.82779836654663)
Test epoch: 28| Acc: 99.5 (9950/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001632 | Loss_in_diffu: 5.897220 | Loss_out_diffu: 7.669921 | Acc: 99.978299 (59891/59904)
(1638891488.0729127, 1638891587.9673162, 99.8944034576416)
Test epoch: 29| Acc: 99.49 (9949/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001545 | Loss_in_diffu: 5.893100 | Loss_out_diffu: 7.666582 | Acc: 99.983307 (59894/59904)
(1638891588.5895457, 1638891688.439151, 99.84960532188416)
Test epoch: 30| Acc: 99.54 (9954/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001457 | Loss_in_diffu: 5.890730 | Loss_out_diffu: 7.664717 | Acc: 99.981637 (59893/59904)
(1638891689.0610628, 1638891789.7951632, 100.73410034179688)
Test epoch: 31| Acc: 99.49 (9949/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001439 | Loss_in_diffu: 5.890631 | Loss_out_diffu: 7.664889 | Acc: 99.978299 (59891/59904)
(1638891790.408896, 1638891890.6112854, 100.20238947868347)
Test epoch: 32| Acc: 99.5 (9950/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001425 | Loss_in_diffu: 5.890083 | Loss_out_diffu: 7.664433 | Acc: 99.979968 (59892/59904)
(1638891891.2233274, 1638891991.1305704, 99.90724301338196)
Test epoch: 33| Acc: 99.48 (9948/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001425 | Loss_in_diffu: 5.889576 | Loss_out_diffu: 7.664268 | Acc: 99.986645 (59896/59904)
(1638891991.7540197, 1638892092.3047752, 100.55075550079346)
Test epoch: 34| Acc: 99.48 (9948/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001431 | Loss_in_diffu: 5.889360 | Loss_out_diffu: 7.663896 | Acc: 99.983307 (59894/59904)
(1638892092.935651, 1638892193.8760219, 100.94037079811096)
Test epoch: 35| Acc: 99.47 (9947/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001433 | Loss_in_diffu: 5.888766 | Loss_out_diffu: 7.663534 | Acc: 99.981637 (59893/59904)
(1638892194.499535, 1638892295.2771158, 100.77758073806763)
Test epoch: 36| Acc: 99.53 (9953/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001361 | Loss_in_diffu: 5.887997 | Loss_out_diffu: 7.663117 | Acc: 99.984976 (59895/59904)
(1638892295.8980901, 1638892396.9055035, 101.00741338729858)
Test epoch: 37| Acc: 99.47 (9947/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001411 | Loss_in_diffu: 5.887729 | Loss_out_diffu: 7.663111 | Acc: 99.984976 (59895/59904)
(1638892397.514656, 1638892497.914675, 100.40001893043518)
Test epoch: 38| Acc: 99.47 (9947/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001364 | Loss_in_diffu: 5.887455 | Loss_out_diffu: 7.662645 | Acc: 99.981637 (59893/59904)
(1638892498.5374293, 1638892598.7635374, 100.22610807418823)
Test epoch: 39| Acc: 99.51 (9951/10000) 
