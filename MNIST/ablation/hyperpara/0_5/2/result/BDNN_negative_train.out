True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.585202 | Loss_in_diffu: 11.056673 | Loss_out_diffu: 11.494981 | Acc: 87.152778 (52208/59904)
(1638888545.8964317, 1638888645.613327, 99.71689534187317)
Test epoch: 0| Acc: 96.68 (9668/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.104429 | Loss_in_diffu: 10.099205 | Loss_out_diffu: 11.280237 | Acc: 97.292334 (58282/59904)
(1638888646.3332367, 1638888746.6420538, 100.30881714820862)
Test epoch: 1| Acc: 98.49 (9849/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.073693 | Loss_in_diffu: 9.588026 | Loss_out_diffu: 10.891866 | Acc: 98.020166 (58718/59904)
(1638888747.3477097, 1638888847.4626107, 100.11490106582642)
Test epoch: 2| Acc: 98.46 (9846/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.057571 | Loss_in_diffu: 9.111347 | Loss_out_diffu: 10.469267 | Acc: 98.318977 (58897/59904)
(1638888848.1697795, 1638888947.8144925, 99.64471292495728)
Test epoch: 3| Acc: 98.46 (9846/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049439 | Loss_in_diffu: 8.664379 | Loss_out_diffu: 10.071416 | Acc: 98.559362 (59041/59904)
(1638888948.5305018, 1638889047.442505, 98.91200304031372)
Test epoch: 4| Acc: 99.12 (9912/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.044146 | Loss_in_diffu: 8.243821 | Loss_out_diffu: 9.662905 | Acc: 98.753005 (59157/59904)
(1638889048.1565776, 1638889148.2771788, 100.12060117721558)
Test epoch: 5| Acc: 98.65 (9865/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.039140 | Loss_in_diffu: 7.846506 | Loss_out_diffu: 9.270085 | Acc: 98.873197 (59229/59904)
(1638889148.8716083, 1638889247.9814851, 99.10987687110901)
Test epoch: 6| Acc: 99.03 (9903/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.039708 | Loss_in_diffu: 7.475876 | Loss_out_diffu: 9.204450 | Acc: 98.873197 (59229/59904)
(1638889248.701007, 1638889347.942482, 99.24147510528564)
Test epoch: 7| Acc: 99.09 (9909/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.032905 | Loss_in_diffu: 7.116541 | Loss_out_diffu: 8.894426 | Acc: 99.025107 (59320/59904)
(1638889348.5517592, 1638889447.745697, 99.1939377784729)
Test epoch: 8| Acc: 98.32 (9832/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.031961 | Loss_in_diffu: 6.767778 | Loss_out_diffu: 8.611353 | Acc: 99.096888 (59363/59904)
(1638889448.4554493, 1638889548.9265761, 100.47112679481506)
Test epoch: 9| Acc: 98.96 (9896/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.027166 | Loss_in_diffu: 6.423758 | Loss_out_diffu: 8.330625 | Acc: 99.182025 (59414/59904)
(1638889549.646352, 1638889649.10382, 99.45746803283691)
Test epoch: 10| Acc: 99.06 (9906/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009952 | Loss_in_diffu: 6.229521 | Loss_out_diffu: 8.184121 | Acc: 99.721221 (59737/59904)
(1638889649.701886, 1638889749.550521, 99.84863495826721)
Test epoch: 11| Acc: 99.45 (9945/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007236 | Loss_in_diffu: 6.186419 | Loss_out_diffu: 8.148731 | Acc: 99.813034 (59792/59904)
(1638889750.160193, 1638889849.5904315, 99.4302384853363)
Test epoch: 12| Acc: 99.45 (9945/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006490 | Loss_in_diffu: 6.144439 | Loss_out_diffu: 8.111999 | Acc: 99.841413 (59809/59904)
(1638889850.3049326, 1638889950.182362, 99.87742948532104)
Test epoch: 13| Acc: 99.47 (9947/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005605 | Loss_in_diffu: 6.102933 | Loss_out_diffu: 8.079868 | Acc: 99.854768 (59817/59904)
(1638889950.7671707, 1638890050.0597448, 99.29257416725159)
Test epoch: 14| Acc: 99.41 (9941/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005383 | Loss_in_diffu: 6.063549 | Loss_out_diffu: 8.047027 | Acc: 99.848090 (59813/59904)
(1638890050.7657516, 1638890150.0032907, 99.23753905296326)
Test epoch: 15| Acc: 99.4 (9940/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004087 | Loss_in_diffu: 6.024299 | Loss_out_diffu: 8.018632 | Acc: 99.913194 (59852/59904)
(1638890150.7117069, 1638890250.6216106, 99.90990376472473)
Test epoch: 16| Acc: 99.36 (9936/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003975 | Loss_in_diffu: 5.986837 | Loss_out_diffu: 7.990299 | Acc: 99.908186 (59849/59904)
(1638890251.331961, 1638890351.2659454, 99.93398451805115)
Test epoch: 17| Acc: 99.3 (9930/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003781 | Loss_in_diffu: 5.949528 | Loss_out_diffu: 7.963299 | Acc: 99.903178 (59846/59904)
(1638890351.9840949, 1638890452.123816, 100.13972115516663)
Test epoch: 18| Acc: 99.38 (9938/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003321 | Loss_in_diffu: 5.914081 | Loss_out_diffu: 7.933345 | Acc: 99.904848 (59847/59904)
(1638890452.8436894, 1638890552.7513328, 99.90764331817627)
Test epoch: 19| Acc: 99.37 (9937/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004357 | Loss_in_diffu: 5.879088 | Loss_out_diffu: 7.905090 | Acc: 99.879808 (59832/59904)
(1638890553.401648, 1638890652.629407, 99.22775888442993)
Test epoch: 20| Acc: 99.47 (9947/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001966 | Loss_in_diffu: 5.858778 | Loss_out_diffu: 7.893470 | Acc: 99.971621 (59887/59904)
(1638890653.3382392, 1638890753.8301523, 100.49191308021545)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001723 | Loss_in_diffu: 5.854672 | Loss_out_diffu: 7.890287 | Acc: 99.973291 (59888/59904)
(1638890754.553472, 1638890854.9018366, 100.34836459159851)
Test epoch: 22| Acc: 99.5 (9950/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001682 | Loss_in_diffu: 5.851150 | Loss_out_diffu: 7.886841 | Acc: 99.969952 (59886/59904)
(1638890855.490961, 1638890954.747854, 99.2568929195404)
Test epoch: 23| Acc: 99.47 (9947/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001581 | Loss_in_diffu: 5.846666 | Loss_out_diffu: 7.883828 | Acc: 99.976629 (59890/59904)
(1638890955.4672644, 1638891055.869208, 100.40194368362427)
Test epoch: 24| Acc: 99.49 (9949/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001543 | Loss_in_diffu: 5.842898 | Loss_out_diffu: 7.880524 | Acc: 99.979968 (59892/59904)
(1638891056.4778788, 1638891156.457841, 99.97996211051941)
Test epoch: 25| Acc: 99.49 (9949/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001536 | Loss_in_diffu: 5.838420 | Loss_out_diffu: 7.876997 | Acc: 99.978299 (59891/59904)
(1638891157.0445216, 1638891256.652061, 99.6075394153595)
Test epoch: 26| Acc: 99.48 (9948/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001461 | Loss_in_diffu: 5.834734 | Loss_out_diffu: 7.873607 | Acc: 99.981637 (59893/59904)
(1638891257.362162, 1638891357.3820496, 100.01988744735718)
Test epoch: 27| Acc: 99.49 (9949/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001427 | Loss_in_diffu: 5.830466 | Loss_out_diffu: 7.870759 | Acc: 99.981637 (59893/59904)
(1638891357.979011, 1638891457.2072275, 99.22821640968323)
Test epoch: 28| Acc: 99.49 (9949/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001407 | Loss_in_diffu: 5.826626 | Loss_out_diffu: 7.867069 | Acc: 99.981637 (59893/59904)
(1638891457.8044486, 1638891557.67421, 99.86976146697998)
Test epoch: 29| Acc: 99.48 (9948/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001363 | Loss_in_diffu: 5.822657 | Loss_out_diffu: 7.864193 | Acc: 99.984976 (59895/59904)
(1638891558.392296, 1638891658.0597389, 99.6674427986145)
Test epoch: 30| Acc: 99.46 (9946/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001189 | Loss_in_diffu: 5.820336 | Loss_out_diffu: 7.862547 | Acc: 99.988315 (59897/59904)
(1638891658.6577356, 1638891757.7741187, 99.11638307571411)
Test epoch: 31| Acc: 99.47 (9947/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001228 | Loss_in_diffu: 5.820251 | Loss_out_diffu: 7.862628 | Acc: 99.984976 (59895/59904)
(1638891758.3634825, 1638891858.6034634, 100.23998093605042)
Test epoch: 32| Acc: 99.48 (9948/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001239 | Loss_in_diffu: 5.819726 | Loss_out_diffu: 7.862185 | Acc: 99.984976 (59895/59904)
(1638891859.3114362, 1638891958.740701, 99.42926478385925)
Test epoch: 33| Acc: 99.48 (9948/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001181 | Loss_in_diffu: 5.819256 | Loss_out_diffu: 7.861960 | Acc: 99.986645 (59896/59904)
(1638891959.3373027, 1638892059.137695, 99.80039238929749)
Test epoch: 34| Acc: 99.47 (9947/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001184 | Loss_in_diffu: 5.819048 | Loss_out_diffu: 7.861745 | Acc: 99.986645 (59896/59904)
(1638892059.744956, 1638892159.0619395, 99.31698346138)
Test epoch: 35| Acc: 99.48 (9948/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001206 | Loss_in_diffu: 5.818467 | Loss_out_diffu: 7.861495 | Acc: 99.988315 (59897/59904)
(1638892159.791202, 1638892259.1188593, 99.3276572227478)
Test epoch: 36| Acc: 99.48 (9948/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001157 | Loss_in_diffu: 5.817745 | Loss_out_diffu: 7.860996 | Acc: 99.986645 (59896/59904)
(1638892259.7179232, 1638892359.969276, 100.25135278701782)
Test epoch: 37| Acc: 99.46 (9946/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001170 | Loss_in_diffu: 5.817478 | Loss_out_diffu: 7.861059 | Acc: 99.984976 (59895/59904)
(1638892360.5640006, 1638892459.7850513, 99.22105073928833)
Test epoch: 38| Acc: 99.45 (9945/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001149 | Loss_in_diffu: 5.817246 | Loss_out_diffu: 7.860514 | Acc: 99.988315 (59897/59904)
(1638892460.502, 1638892560.7363203, 100.2343201637268)
Test epoch: 39| Acc: 99.46 (9946/10000) 
