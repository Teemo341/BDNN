True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.657898 | Loss_in_diffu: 11.171085 | Loss_out_diffu: 11.513709 | Acc: 84.932559 (50878/59904)
(1638888493.7614954, 1638888593.5648987, 99.80340337753296)
Test epoch: 0| Acc: 96.74 (9674/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.120753 | Loss_in_diffu: 10.185996 | Loss_out_diffu: 11.464537 | Acc: 96.871661 (58030/59904)
(1638888594.2826574, 1638888693.4095137, 99.12685632705688)
Test epoch: 1| Acc: 97.82 (9782/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.077601 | Loss_in_diffu: 9.675110 | Loss_out_diffu: 11.125703 | Acc: 97.911659 (58653/59904)
(1638888694.1260417, 1638888792.6665835, 98.54054188728333)
Test epoch: 2| Acc: 98.75 (9875/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.062027 | Loss_in_diffu: 9.197904 | Loss_out_diffu: 10.730584 | Acc: 98.243857 (58852/59904)
(1638888793.3895054, 1638888892.0980914, 98.70858597755432)
Test epoch: 3| Acc: 98.94 (9894/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.052149 | Loss_in_diffu: 8.751962 | Loss_out_diffu: 10.355556 | Acc: 98.514290 (59014/59904)
(1638888892.8082736, 1638888991.279541, 98.47126746177673)
Test epoch: 4| Acc: 98.26 (9826/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.048083 | Loss_in_diffu: 8.338100 | Loss_out_diffu: 9.979282 | Acc: 98.592748 (59061/59904)
(1638888991.995198, 1638889091.0635064, 99.06830835342407)
Test epoch: 5| Acc: 98.99 (9899/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.041398 | Loss_in_diffu: 7.940065 | Loss_out_diffu: 9.614946 | Acc: 98.834802 (59206/59904)
(1638889091.781907, 1638889190.4814136, 98.69950652122498)
Test epoch: 6| Acc: 98.93 (9893/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.042103 | Loss_in_diffu: 7.577578 | Loss_out_diffu: 9.251627 | Acc: 98.768029 (59166/59904)
(1638889191.0697145, 1638889290.8882122, 99.81849765777588)
Test epoch: 7| Acc: 99.1 (9910/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.034824 | Loss_in_diffu: 7.215042 | Loss_out_diffu: 8.913598 | Acc: 99.015091 (59314/59904)
(1638889291.4861214, 1638889391.0340688, 99.5479474067688)
Test epoch: 8| Acc: 99.04 (9904/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.034190 | Loss_in_diffu: 6.866748 | Loss_out_diffu: 8.564756 | Acc: 99.000067 (59305/59904)
(1638889391.6339564, 1638889491.0580926, 99.4241361618042)
Test epoch: 9| Acc: 99.25 (9925/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.029819 | Loss_in_diffu: 6.525443 | Loss_out_diffu: 8.238827 | Acc: 99.131944 (59384/59904)
(1638889491.6437154, 1638889590.4266195, 98.7829041481018)
Test epoch: 10| Acc: 98.54 (9854/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.011133 | Loss_in_diffu: 6.327184 | Loss_out_diffu: 8.053207 | Acc: 99.682826 (59714/59904)
(1638889591.0342958, 1638889690.0154393, 98.98114347457886)
Test epoch: 11| Acc: 99.48 (9948/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007874 | Loss_in_diffu: 6.282675 | Loss_out_diffu: 8.020639 | Acc: 99.799679 (59784/59904)
(1638889690.7360406, 1638889789.770336, 99.03429532051086)
Test epoch: 12| Acc: 99.52 (9952/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.007363 | Loss_in_diffu: 6.239383 | Loss_out_diffu: 7.987262 | Acc: 99.813034 (59792/59904)
(1638889790.4828017, 1638889889.3332102, 98.85040855407715)
Test epoch: 13| Acc: 99.41 (9941/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006358 | Loss_in_diffu: 6.196370 | Loss_out_diffu: 7.955928 | Acc: 99.838074 (59807/59904)
(1638889890.0390408, 1638889988.8965669, 98.85752606391907)
Test epoch: 14| Acc: 99.47 (9947/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006451 | Loss_in_diffu: 6.155255 | Loss_out_diffu: 7.927500 | Acc: 99.836405 (59806/59904)
(1638889989.4954526, 1638890088.8723218, 99.37686920166016)
Test epoch: 15| Acc: 99.5 (9950/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005336 | Loss_in_diffu: 6.114725 | Loss_out_diffu: 7.899653 | Acc: 99.873130 (59828/59904)
(1638890089.4819765, 1638890189.2427711, 99.7607946395874)
Test epoch: 16| Acc: 99.37 (9937/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004922 | Loss_in_diffu: 6.076184 | Loss_out_diffu: 7.872822 | Acc: 99.888154 (59837/59904)
(1638890189.8406782, 1638890288.7438402, 98.90316200256348)
Test epoch: 17| Acc: 99.42 (9942/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.005245 | Loss_in_diffu: 6.038996 | Loss_out_diffu: 7.848001 | Acc: 99.861445 (59821/59904)
(1638890289.3401642, 1638890388.0916545, 98.75149035453796)
Test epoch: 18| Acc: 99.39 (9939/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004292 | Loss_in_diffu: 6.002936 | Loss_out_diffu: 7.822635 | Acc: 99.888154 (59837/59904)
(1638890388.813921, 1638890487.8151562, 99.00123524665833)
Test epoch: 19| Acc: 99.46 (9946/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003835 | Loss_in_diffu: 5.966355 | Loss_out_diffu: 7.798770 | Acc: 99.898170 (59843/59904)
(1638890488.423424, 1638890588.2748652, 99.85144114494324)
Test epoch: 20| Acc: 99.43 (9943/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002439 | Loss_in_diffu: 5.945811 | Loss_out_diffu: 7.788660 | Acc: 99.951589 (59875/59904)
(1638890588.9823265, 1638890689.0160255, 100.03369903564453)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002043 | Loss_in_diffu: 5.941453 | Loss_out_diffu: 7.785634 | Acc: 99.969952 (59886/59904)
(1638890689.725447, 1638890788.575951, 98.85050415992737)
Test epoch: 22| Acc: 99.49 (9949/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001942 | Loss_in_diffu: 5.937787 | Loss_out_diffu: 7.783093 | Acc: 99.969952 (59886/59904)
(1638890789.2833145, 1638890888.4036002, 99.12028574943542)
Test epoch: 23| Acc: 99.5 (9950/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001891 | Loss_in_diffu: 5.933220 | Loss_out_diffu: 7.780542 | Acc: 99.971621 (59887/59904)
(1638890889.1244826, 1638890989.0742757, 99.94979310035706)
Test epoch: 24| Acc: 99.45 (9945/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001873 | Loss_in_diffu: 5.929347 | Loss_out_diffu: 7.778157 | Acc: 99.968283 (59885/59904)
(1638890989.7946224, 1638891089.218664, 99.4240415096283)
Test epoch: 25| Acc: 99.48 (9948/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001787 | Loss_in_diffu: 5.924749 | Loss_out_diffu: 7.775467 | Acc: 99.978299 (59891/59904)
(1638891089.9274154, 1638891189.5344267, 99.60701131820679)
Test epoch: 26| Acc: 99.49 (9949/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001700 | Loss_in_diffu: 5.920988 | Loss_out_diffu: 7.772812 | Acc: 99.976629 (59890/59904)
(1638891190.2478695, 1638891290.1637282, 99.91585874557495)
Test epoch: 27| Acc: 99.47 (9947/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001698 | Loss_in_diffu: 5.916585 | Loss_out_diffu: 7.770360 | Acc: 99.978299 (59891/59904)
(1638891290.875243, 1638891389.7000537, 98.82481074333191)
Test epoch: 28| Acc: 99.47 (9947/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001660 | Loss_in_diffu: 5.912551 | Loss_out_diffu: 7.767613 | Acc: 99.976629 (59890/59904)
(1638891390.3917146, 1638891489.9956937, 99.60397911071777)
Test epoch: 29| Acc: 99.43 (9943/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001624 | Loss_in_diffu: 5.908372 | Loss_out_diffu: 7.765138 | Acc: 99.979968 (59892/59904)
(1638891490.7171009, 1638891590.5984027, 99.88130187988281)
Test epoch: 30| Acc: 99.41 (9941/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001471 | Loss_in_diffu: 5.905931 | Loss_out_diffu: 7.763440 | Acc: 99.984976 (59895/59904)
(1638891591.3085186, 1638891690.7971392, 99.48862051963806)
Test epoch: 31| Acc: 99.45 (9945/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001469 | Loss_in_diffu: 5.905839 | Loss_out_diffu: 7.763645 | Acc: 99.984976 (59895/59904)
(1638891691.5140676, 1638891790.3394582, 98.82539057731628)
Test epoch: 32| Acc: 99.46 (9946/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001486 | Loss_in_diffu: 5.905270 | Loss_out_diffu: 7.763345 | Acc: 99.984976 (59895/59904)
(1638891791.0520902, 1638891890.0359879, 98.98389768600464)
Test epoch: 33| Acc: 99.45 (9945/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001485 | Loss_in_diffu: 5.904778 | Loss_out_diffu: 7.763101 | Acc: 99.984976 (59895/59904)
(1638891890.753527, 1638891989.5564237, 98.80289673805237)
Test epoch: 34| Acc: 99.45 (9945/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001465 | Loss_in_diffu: 5.904542 | Loss_out_diffu: 7.762916 | Acc: 99.984976 (59895/59904)
(1638891990.263622, 1638892089.0471027, 98.78348064422607)
Test epoch: 35| Acc: 99.43 (9943/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001440 | Loss_in_diffu: 5.903938 | Loss_out_diffu: 7.762580 | Acc: 99.983307 (59894/59904)
(1638892089.7619753, 1638892189.413517, 99.6515417098999)
Test epoch: 36| Acc: 99.45 (9945/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001439 | Loss_in_diffu: 5.903182 | Loss_out_diffu: 7.762121 | Acc: 99.983307 (59894/59904)
(1638892190.1229908, 1638892289.7026076, 99.57961678504944)
Test epoch: 37| Acc: 99.41 (9941/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001467 | Loss_in_diffu: 5.902906 | Loss_out_diffu: 7.762243 | Acc: 99.984976 (59895/59904)
(1638892290.300473, 1638892390.1224418, 99.82196879386902)
Test epoch: 38| Acc: 99.44 (9944/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001439 | Loss_in_diffu: 5.902640 | Loss_out_diffu: 7.761857 | Acc: 99.983307 (59894/59904)
(1638892390.8298535, 1638892489.6621437, 98.8322901725769)
Test epoch: 39| Acc: 99.47 (9947/10000) 
