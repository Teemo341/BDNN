True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.678142 | Loss_in_diffu: 11.205788 | Loss_out_diffu: 11.504274 | Acc: 84.289864 (50493/59904)
(1638888602.0993612, 1638888704.5473185, 102.44795727729797)
Test epoch: 0| Acc: 96.06 (9606/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.121490 | Loss_in_diffu: 10.221661 | Loss_out_diffu: 11.530515 | Acc: 96.773170 (57971/59904)
(1638888705.2676556, 1638888805.495473, 100.22781729698181)
Test epoch: 1| Acc: 96.89 (9689/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.079675 | Loss_in_diffu: 9.713005 | Loss_out_diffu: 11.202548 | Acc: 97.776442 (58572/59904)
(1638888806.097455, 1638888907.6517189, 101.55426383018494)
Test epoch: 2| Acc: 98.57 (9857/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.064929 | Loss_in_diffu: 9.238379 | Loss_out_diffu: 10.812222 | Acc: 98.197115 (58824/59904)
(1638888908.3659048, 1638889008.8752592, 100.50935435295105)
Test epoch: 3| Acc: 98.85 (9885/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.050936 | Loss_in_diffu: 8.788132 | Loss_out_diffu: 10.417984 | Acc: 98.549346 (59035/59904)
(1638889009.582858, 1638889110.6405528, 101.05769467353821)
Test epoch: 4| Acc: 98.23 (9823/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.049726 | Loss_in_diffu: 8.378283 | Loss_out_diffu: 10.054286 | Acc: 98.552684 (59037/59904)
(1638889111.2854733, 1638889211.9876747, 100.70220136642456)
Test epoch: 5| Acc: 98.94 (9894/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.044092 | Loss_in_diffu: 7.987955 | Loss_out_diffu: 9.687418 | Acc: 98.679554 (59113/59904)
(1638889212.5911596, 1638889313.7745123, 101.18335270881653)
Test epoch: 6| Acc: 98.67 (9867/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.040813 | Loss_in_diffu: 7.618508 | Loss_out_diffu: 9.341680 | Acc: 98.786392 (59177/59904)
(1638889314.4821415, 1638889414.9281468, 100.44600534439087)
Test epoch: 7| Acc: 98.82 (9882/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.036287 | Loss_in_diffu: 7.261640 | Loss_out_diffu: 8.987784 | Acc: 98.960003 (59281/59904)
(1638889415.524127, 1638889516.1264052, 100.60227823257446)
Test epoch: 8| Acc: 98.89 (9889/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.032862 | Loss_in_diffu: 6.914578 | Loss_out_diffu: 8.642629 | Acc: 99.033454 (59325/59904)
(1638889516.8340368, 1638889617.3765655, 100.54252862930298)
Test epoch: 9| Acc: 99.29 (9929/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.034538 | Loss_in_diffu: 6.584695 | Loss_out_diffu: 8.277053 | Acc: 98.966680 (59285/59904)
(1638889617.962794, 1638889718.1442983, 100.18150424957275)
Test epoch: 10| Acc: 99.2 (9920/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.011613 | Loss_in_diffu: 6.388011 | Loss_out_diffu: 8.103056 | Acc: 99.686165 (59716/59904)
(1638889718.733933, 1638889818.6340818, 99.90014886856079)
Test epoch: 11| Acc: 99.48 (9948/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.008975 | Loss_in_diffu: 6.343608 | Loss_out_diffu: 8.069943 | Acc: 99.777978 (59771/59904)
(1638889819.339647, 1638889919.9342027, 100.59455561637878)
Test epoch: 12| Acc: 99.54 (9954/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.008301 | Loss_in_diffu: 6.299288 | Loss_out_diffu: 8.034027 | Acc: 99.793002 (59780/59904)
(1638889920.6139092, 1638890021.722519, 101.10860967636108)
Test epoch: 13| Acc: 99.5 (9950/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.007308 | Loss_in_diffu: 6.255268 | Loss_out_diffu: 7.999298 | Acc: 99.801349 (59785/59904)
(1638890022.4444256, 1638890122.4051256, 99.96070003509521)
Test epoch: 14| Acc: 99.51 (9951/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.007299 | Loss_in_diffu: 6.213658 | Loss_out_diffu: 7.967473 | Acc: 99.803018 (59786/59904)
(1638890123.110355, 1638890223.1207397, 100.01038479804993)
Test epoch: 15| Acc: 99.56 (9956/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.006402 | Loss_in_diffu: 6.172990 | Loss_out_diffu: 7.935798 | Acc: 99.828058 (59801/59904)
(1638890223.7058363, 1638890323.8467882, 100.14095187187195)
Test epoch: 16| Acc: 99.42 (9942/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.006409 | Loss_in_diffu: 6.133933 | Loss_out_diffu: 7.906534 | Acc: 99.826389 (59800/59904)
(1638890324.5544848, 1638890425.5585344, 101.00404953956604)
Test epoch: 17| Acc: 99.53 (9953/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.005608 | Loss_in_diffu: 6.095657 | Loss_out_diffu: 7.878875 | Acc: 99.858106 (59819/59904)
(1638890426.1640415, 1638890526.0503228, 99.88628125190735)
Test epoch: 18| Acc: 99.51 (9951/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.005519 | Loss_in_diffu: 6.059082 | Loss_out_diffu: 7.851101 | Acc: 99.863114 (59822/59904)
(1638890526.636183, 1638890626.9902475, 100.35406446456909)
Test epoch: 19| Acc: 99.45 (9945/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004972 | Loss_in_diffu: 6.022144 | Loss_out_diffu: 7.820824 | Acc: 99.878138 (59831/59904)
(1638890627.7095275, 1638890728.1451356, 100.43560814857483)
Test epoch: 20| Acc: 99.39 (9939/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.003173 | Loss_in_diffu: 6.001201 | Loss_out_diffu: 7.806445 | Acc: 99.929888 (59862/59904)
(1638890728.86451, 1638890829.122783, 100.25827288627625)
Test epoch: 21| Acc: 99.49 (9949/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002752 | Loss_in_diffu: 5.996778 | Loss_out_diffu: 7.803365 | Acc: 99.953259 (59876/59904)
(1638890829.7295895, 1638890930.2513075, 100.52171802520752)
Test epoch: 22| Acc: 99.49 (9949/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.002620 | Loss_in_diffu: 5.993009 | Loss_out_diffu: 7.800185 | Acc: 99.944912 (59871/59904)
(1638890930.9707623, 1638891031.5943265, 100.62356424331665)
Test epoch: 23| Acc: 99.52 (9952/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.002557 | Loss_in_diffu: 5.988380 | Loss_out_diffu: 7.797411 | Acc: 99.953259 (59876/59904)
(1638891032.1937277, 1638891132.1008048, 99.9070770740509)
Test epoch: 24| Acc: 99.53 (9953/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.002437 | Loss_in_diffu: 5.984410 | Loss_out_diffu: 7.794211 | Acc: 99.956597 (59878/59904)
(1638891132.8201988, 1638891233.3197405, 100.49954175949097)
Test epoch: 25| Acc: 99.51 (9951/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.002423 | Loss_in_diffu: 5.979760 | Loss_out_diffu: 7.790710 | Acc: 99.959936 (59880/59904)
(1638891234.0403354, 1638891335.1008532, 101.06051778793335)
Test epoch: 26| Acc: 99.5 (9950/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.002356 | Loss_in_diffu: 5.975929 | Loss_out_diffu: 7.787393 | Acc: 99.958267 (59879/59904)
(1638891335.7502666, 1638891436.2983866, 100.54812002182007)
Test epoch: 27| Acc: 99.51 (9951/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.002214 | Loss_in_diffu: 5.971519 | Loss_out_diffu: 7.784876 | Acc: 99.961605 (59881/59904)
(1638891436.885583, 1638891537.3738668, 100.48828387260437)
Test epoch: 28| Acc: 99.52 (9952/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.002170 | Loss_in_diffu: 5.967439 | Loss_out_diffu: 7.781582 | Acc: 99.964944 (59883/59904)
(1638891537.9814384, 1638891637.890719, 99.90928053855896)
Test epoch: 29| Acc: 99.54 (9954/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.002141 | Loss_in_diffu: 5.963301 | Loss_out_diffu: 7.778808 | Acc: 99.966613 (59884/59904)
(1638891638.4962165, 1638891738.3410943, 99.84487771987915)
Test epoch: 30| Acc: 99.54 (9954/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001998 | Loss_in_diffu: 5.960877 | Loss_out_diffu: 7.777181 | Acc: 99.969952 (59886/59904)
(1638891738.925384, 1638891839.2678537, 100.34246969223022)
Test epoch: 31| Acc: 99.53 (9953/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.002003 | Loss_in_diffu: 5.960771 | Loss_out_diffu: 7.777336 | Acc: 99.973291 (59888/59904)
(1638891839.9864624, 1638891941.1086562, 101.12219381332397)
Test epoch: 32| Acc: 99.53 (9953/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001931 | Loss_in_diffu: 5.960229 | Loss_out_diffu: 7.776951 | Acc: 99.973291 (59888/59904)
(1638891941.7160442, 1638892042.3831155, 100.66707134246826)
Test epoch: 33| Acc: 99.57 (9957/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001995 | Loss_in_diffu: 5.959699 | Loss_out_diffu: 7.776917 | Acc: 99.964944 (59883/59904)
(1638892043.0890949, 1638892143.0484366, 99.95934176445007)
Test epoch: 34| Acc: 99.55 (9955/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001994 | Loss_in_diffu: 5.959478 | Loss_out_diffu: 7.776764 | Acc: 99.969952 (59886/59904)
(1638892143.646815, 1638892243.5831418, 99.93632674217224)
Test epoch: 35| Acc: 99.54 (9954/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001918 | Loss_in_diffu: 5.958886 | Loss_out_diffu: 7.776529 | Acc: 99.974960 (59889/59904)
(1638892244.179739, 1638892344.7255032, 100.54576420783997)
Test epoch: 36| Acc: 99.5 (9950/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001951 | Loss_in_diffu: 5.958085 | Loss_out_diffu: 7.776133 | Acc: 99.969952 (59886/59904)
(1638892345.4408414, 1638892445.4469607, 100.00611925125122)
Test epoch: 37| Acc: 99.57 (9957/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001982 | Loss_in_diffu: 5.957824 | Loss_out_diffu: 7.776243 | Acc: 99.969952 (59886/59904)
(1638892446.031138, 1638892545.9517667, 99.92062878608704)
Test epoch: 38| Acc: 99.55 (9955/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001973 | Loss_in_diffu: 5.957569 | Loss_out_diffu: 7.775834 | Acc: 99.973291 (59888/59904)
(1638892546.6604373, 1638892646.6291366, 99.96869921684265)
Test epoch: 39| Acc: 99.55 (9955/10000) 
