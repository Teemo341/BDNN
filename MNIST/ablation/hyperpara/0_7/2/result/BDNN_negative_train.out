True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.632556 | Loss_in_diffu: 11.337214 | Loss_out_diffu: 11.722272 | Acc: 85.812300 (51405/59904)
(1679147010.4515433, 1679147265.5186949, 255.06715154647827)
Test epoch: 0| Acc: 97.01 (9701/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.103516 | Loss_in_diffu: 10.531450 | Loss_out_diffu: 11.736410 | Acc: 97.339076 (58310/59904)
(1679147266.670152, 1679147519.7907963, 253.1206443309784)
Test epoch: 1| Acc: 98.16 (9816/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.073030 | Loss_in_diffu: 10.178849 | Loss_out_diffu: 11.501620 | Acc: 97.948384 (58675/59904)
(1679147520.934116, 1679147773.457744, 252.5236279964447)
Test epoch: 2| Acc: 98.17 (9817/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.056270 | Loss_in_diffu: 9.835152 | Loss_out_diffu: 11.254365 | Acc: 98.470887 (58988/59904)
(1679147774.7028992, 1679148027.766369, 253.06346988677979)
Test epoch: 3| Acc: 98.84 (9884/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048421 | Loss_in_diffu: 9.510677 | Loss_out_diffu: 11.159788 | Acc: 98.677885 (59112/59904)
(1679148028.9088287, 1679148281.087279, 252.17845034599304)
Test epoch: 4| Acc: 98.52 (9852/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.045692 | Loss_in_diffu: 9.210458 | Loss_out_diffu: 10.925445 | Acc: 98.672877 (59109/59904)
(1679148282.2602022, 1679148535.0248997, 252.7646975517273)
Test epoch: 5| Acc: 99.14 (9914/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037286 | Loss_in_diffu: 8.924011 | Loss_out_diffu: 10.674916 | Acc: 98.939971 (59269/59904)
(1679148536.1824586, 1679148786.8971345, 250.7146759033203)
Test epoch: 6| Acc: 98.91 (9891/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.036997 | Loss_in_diffu: 8.662260 | Loss_out_diffu: 10.436860 | Acc: 98.919939 (59257/59904)
(1679148788.130993, 1679149036.0360727, 247.90507984161377)
Test epoch: 7| Acc: 98.66 (9866/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.033352 | Loss_in_diffu: 8.415431 | Loss_out_diffu: 10.218377 | Acc: 99.040131 (59329/59904)
(1679149037.2027602, 1679149284.8263652, 247.62360501289368)
Test epoch: 8| Acc: 98.91 (9891/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.028703 | Loss_in_diffu: 8.178876 | Loss_out_diffu: 10.020966 | Acc: 99.197049 (59423/59904)
(1679149286.0006223, 1679149534.5257745, 248.5251522064209)
Test epoch: 9| Acc: 99.14 (9914/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.028698 | Loss_in_diffu: 7.964030 | Loss_out_diffu: 9.791995 | Acc: 99.133614 (59385/59904)
(1679149535.697649, 1679149789.629273, 253.93162393569946)
Test epoch: 10| Acc: 99.23 (9923/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009414 | Loss_in_diffu: 7.829220 | Loss_out_diffu: 9.676719 | Acc: 99.752938 (59756/59904)
(1679149790.7904375, 1679150042.8410852, 252.0506477355957)
Test epoch: 11| Acc: 99.56 (9956/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006702 | Loss_in_diffu: 7.794220 | Loss_out_diffu: 9.650443 | Acc: 99.838074 (59807/59904)
(1679150044.0013864, 1679150295.4805148, 251.4791283607483)
Test epoch: 12| Acc: 99.54 (9954/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006114 | Loss_in_diffu: 7.759037 | Loss_out_diffu: 9.623865 | Acc: 99.849760 (59814/59904)
(1679150296.746358, 1679150548.388636, 251.6422781944275)
Test epoch: 13| Acc: 99.54 (9954/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005147 | Loss_in_diffu: 7.723193 | Loss_out_diffu: 9.598121 | Acc: 99.878138 (59831/59904)
(1679150549.5318446, 1679150797.8767798, 248.3449351787567)
Test epoch: 14| Acc: 99.48 (9948/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004930 | Loss_in_diffu: 7.689092 | Loss_out_diffu: 9.572954 | Acc: 99.871461 (59827/59904)
(1679150799.1088374, 1679151051.8494601, 252.74062275886536)
Test epoch: 15| Acc: 99.52 (9952/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003985 | Loss_in_diffu: 7.656752 | Loss_out_diffu: 9.551113 | Acc: 99.919872 (59856/59904)
(1679151053.0006874, 1679151306.1982887, 253.19760131835938)
Test epoch: 16| Acc: 99.52 (9952/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004084 | Loss_in_diffu: 7.625769 | Loss_out_diffu: 9.529430 | Acc: 99.899840 (59844/59904)
(1679151307.5033703, 1679151559.9503655, 252.4469952583313)
Test epoch: 17| Acc: 99.54 (9954/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004087 | Loss_in_diffu: 7.597181 | Loss_out_diffu: 9.511728 | Acc: 99.888154 (59837/59904)
(1679151560.962246, 1679151810.382423, 249.42017698287964)
Test epoch: 18| Acc: 99.55 (9955/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003450 | Loss_in_diffu: 7.570696 | Loss_out_diffu: 9.496476 | Acc: 99.919872 (59856/59904)
(1679151811.5417297, 1679152064.4948127, 252.95308303833008)
Test epoch: 19| Acc: 99.38 (9938/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002951 | Loss_in_diffu: 7.544080 | Loss_out_diffu: 9.480114 | Acc: 99.923210 (59858/59904)
(1679152065.6460228, 1679152318.6897159, 253.0436930656433)
Test epoch: 20| Acc: 99.42 (9942/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001857 | Loss_in_diffu: 7.529317 | Loss_out_diffu: 9.471736 | Acc: 99.969952 (59886/59904)
(1679152320.034269, 1679152571.1777802, 251.14351105690002)
Test epoch: 21| Acc: 99.59 (9959/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001552 | Loss_in_diffu: 7.526043 | Loss_out_diffu: 9.469768 | Acc: 99.979968 (59892/59904)
(1679152572.3152874, 1679152824.0268655, 251.71157813072205)
Test epoch: 22| Acc: 99.58 (9958/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001459 | Loss_in_diffu: 7.523294 | Loss_out_diffu: 9.467665 | Acc: 99.979968 (59892/59904)
(1679152825.248333, 1679153080.9201875, 255.6718544960022)
Test epoch: 23| Acc: 99.59 (9959/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001395 | Loss_in_diffu: 7.519463 | Loss_out_diffu: 9.465275 | Acc: 99.986645 (59896/59904)
(1679153082.0820403, 1679153335.657135, 253.57509469985962)
Test epoch: 24| Acc: 99.54 (9954/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001363 | Loss_in_diffu: 7.516289 | Loss_out_diffu: 9.463070 | Acc: 99.984976 (59895/59904)
(1679153336.885747, 1679153588.8300073, 251.94426035881042)
Test epoch: 25| Acc: 99.63 (9963/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001313 | Loss_in_diffu: 7.512343 | Loss_out_diffu: 9.460487 | Acc: 99.984976 (59895/59904)
(1679153589.9683743, 1679153843.6968598, 253.72848558425903)
Test epoch: 26| Acc: 99.56 (9956/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001272 | Loss_in_diffu: 7.509196 | Loss_out_diffu: 9.458256 | Acc: 99.988315 (59897/59904)
(1679153844.8493602, 1679154096.0616512, 251.21229100227356)
Test epoch: 27| Acc: 99.62 (9962/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001246 | Loss_in_diffu: 7.505463 | Loss_out_diffu: 9.456493 | Acc: 99.988315 (59897/59904)
(1679154097.180929, 1679154347.209302, 250.02837300300598)
Test epoch: 28| Acc: 99.57 (9957/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001189 | Loss_in_diffu: 7.502068 | Loss_out_diffu: 9.454268 | Acc: 99.989984 (59898/59904)
(1679154348.3897855, 1679154600.8987224, 252.50893688201904)
Test epoch: 29| Acc: 99.57 (9957/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001129 | Loss_in_diffu: 7.498530 | Loss_out_diffu: 9.452272 | Acc: 99.989984 (59898/59904)
(1679154602.0569744, 1679154850.6471028, 248.59012842178345)
Test epoch: 30| Acc: 99.57 (9957/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001046 | Loss_in_diffu: 7.496458 | Loss_out_diffu: 9.451206 | Acc: 99.989984 (59898/59904)
(1679154851.8233595, 1679155106.1827888, 254.35942935943604)
Test epoch: 31| Acc: 99.58 (9958/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001037 | Loss_in_diffu: 7.496425 | Loss_out_diffu: 9.451446 | Acc: 99.989984 (59898/59904)
(1679155107.3328967, 1679155359.653038, 252.3201413154602)
Test epoch: 32| Acc: 99.56 (9956/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001046 | Loss_in_diffu: 7.495926 | Loss_out_diffu: 9.451140 | Acc: 99.989984 (59898/59904)
(1679155360.825693, 1679155614.2982643, 253.47257137298584)
Test epoch: 33| Acc: 99.56 (9956/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001025 | Loss_in_diffu: 7.495483 | Loss_out_diffu: 9.451048 | Acc: 99.989984 (59898/59904)
(1679155615.6342227, 1679155866.5321524, 250.8979296684265)
Test epoch: 34| Acc: 99.57 (9957/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001022 | Loss_in_diffu: 7.495301 | Loss_out_diffu: 9.450901 | Acc: 99.989984 (59898/59904)
(1679155867.6974804, 1679156116.528647, 248.8311665058136)
Test epoch: 35| Acc: 99.57 (9957/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001020 | Loss_in_diffu: 7.494772 | Loss_out_diffu: 9.450777 | Acc: 99.989984 (59898/59904)
(1679156117.6837363, 1679156366.1738975, 248.49016118049622)
Test epoch: 36| Acc: 99.59 (9959/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001000 | Loss_in_diffu: 7.494045 | Loss_out_diffu: 9.450468 | Acc: 99.989984 (59898/59904)
(1679156367.453617, 1679156619.18, 251.72638297080994)
Test epoch: 37| Acc: 99.57 (9957/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.000996 | Loss_in_diffu: 7.493818 | Loss_out_diffu: 9.450634 | Acc: 99.989984 (59898/59904)
(1679156620.4115152, 1679156868.6145117, 248.20299649238586)
Test epoch: 38| Acc: 99.6 (9960/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.000997 | Loss_in_diffu: 7.493639 | Loss_out_diffu: 9.450326 | Acc: 99.989984 (59898/59904)
(1679156869.7836423, 1679157118.5652125, 248.78157019615173)
Test epoch: 39| Acc: 99.57 (9957/10000) 
