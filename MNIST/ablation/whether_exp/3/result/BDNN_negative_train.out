True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.676835 | Loss_in_diffu: 11.719177 | Loss_out_diffu: 12.145006 | Acc: 83.959335 (50295/59904)
(1642952495.7221663, 1642952596.3740926, 100.651926279068)
Test epoch: 0| Acc: 93.87 (9387/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.131830 | Loss_in_diffu: 11.331066 | Loss_out_diffu: 12.719309 | Acc: 96.496060 (57805/59904)
(1642952596.9659038, 1642952697.6536384, 100.68773460388184)
Test epoch: 1| Acc: 97.9 (9790/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.077016 | Loss_in_diffu: 11.331628 | Loss_out_diffu: 12.976383 | Acc: 97.849893 (58616/59904)
(1642952698.2489414, 1642952798.4425018, 100.19356036186218)
Test epoch: 2| Acc: 98.0 (9800/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.058099 | Loss_in_diffu: 11.371985 | Loss_out_diffu: 13.133910 | Acc: 98.337340 (58908/59904)
(1642952799.0247357, 1642952899.2599955, 100.23525977134705)
Test epoch: 3| Acc: 98.39 (9839/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.050762 | Loss_in_diffu: 11.431483 | Loss_out_diffu: 13.263842 | Acc: 98.547676 (59034/59904)
(1642952899.8376303, 1642952999.737947, 99.90031671524048)
Test epoch: 4| Acc: 98.62 (9862/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.043700 | Loss_in_diffu: 11.496792 | Loss_out_diffu: 13.391843 | Acc: 98.729634 (59143/59904)
(1642953000.319072, 1642953099.8143132, 99.49524116516113)
Test epoch: 5| Acc: 98.88 (9888/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037076 | Loss_in_diffu: 11.566993 | Loss_out_diffu: 13.519318 | Acc: 98.908253 (59250/59904)
(1642953100.3823483, 1642953200.3759236, 99.99357533454895)
Test epoch: 6| Acc: 98.87 (9887/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.034827 | Loss_in_diffu: 11.646902 | Loss_out_diffu: 13.691650 | Acc: 99.006744 (59309/59904)
(1642953200.9490213, 1642953300.3711715, 99.42215013504028)
Test epoch: 7| Acc: 99.11 (9911/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.032951 | Loss_in_diffu: 11.739782 | Loss_out_diffu: 13.815743 | Acc: 99.028446 (59322/59904)
(1642953300.9575055, 1642953401.096677, 100.1391716003418)
Test epoch: 8| Acc: 99.1 (9910/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.026926 | Loss_in_diffu: 11.833489 | Loss_out_diffu: 13.943177 | Acc: 99.223758 (59439/59904)
(1642953401.6799567, 1642953501.5593815, 99.87942481040955)
Test epoch: 9| Acc: 99.01 (9901/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.026810 | Loss_in_diffu: 11.919823 | Loss_out_diffu: 14.067398 | Acc: 99.222089 (59438/59904)
(1642953502.1462576, 1642953601.8903542, 99.74409651756287)
Test epoch: 10| Acc: 98.98 (9898/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009995 | Loss_in_diffu: 11.958070 | Loss_out_diffu: 14.137169 | Acc: 99.742922 (59750/59904)
(1642953602.4771104, 1642953701.890142, 99.41303157806396)
Test epoch: 11| Acc: 99.45 (9945/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007573 | Loss_in_diffu: 11.957735 | Loss_out_diffu: 14.152281 | Acc: 99.803018 (59786/59904)
(1642953702.4708343, 1642953801.7461114, 99.27527713775635)
Test epoch: 12| Acc: 99.51 (9951/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006824 | Loss_in_diffu: 11.959879 | Loss_out_diffu: 14.163925 | Acc: 99.841413 (59809/59904)
(1642953802.3265533, 1642953901.909444, 99.58289074897766)
Test epoch: 13| Acc: 99.49 (9949/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006028 | Loss_in_diffu: 11.961518 | Loss_out_diffu: 14.179581 | Acc: 99.838074 (59807/59904)
(1642953902.4780223, 1642954001.6235733, 99.14555096626282)
Test epoch: 14| Acc: 99.44 (9944/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005240 | Loss_in_diffu: 11.963607 | Loss_out_diffu: 14.192725 | Acc: 99.871461 (59827/59904)
(1642954002.191169, 1642954101.303451, 99.11228203773499)
Test epoch: 15| Acc: 99.45 (9945/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004428 | Loss_in_diffu: 11.965423 | Loss_out_diffu: 14.211262 | Acc: 99.901509 (59845/59904)
(1642954101.8843937, 1642954201.425765, 99.54137134552002)
Test epoch: 16| Acc: 99.4 (9940/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003944 | Loss_in_diffu: 11.967447 | Loss_out_diffu: 14.230707 | Acc: 99.908186 (59849/59904)
(1642954202.0126293, 1642954302.4349349, 100.42230558395386)
Test epoch: 17| Acc: 99.28 (9928/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003614 | Loss_in_diffu: 11.969871 | Loss_out_diffu: 14.250117 | Acc: 99.909856 (59850/59904)
(1642954303.016226, 1642954403.0429144, 100.02668833732605)
Test epoch: 18| Acc: 99.44 (9944/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003152 | Loss_in_diffu: 11.971458 | Loss_out_diffu: 14.267268 | Acc: 99.941573 (59869/59904)
(1642954403.625394, 1642954503.6785698, 100.05317568778992)
Test epoch: 19| Acc: 99.42 (9942/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002565 | Loss_in_diffu: 11.973144 | Loss_out_diffu: 14.289846 | Acc: 99.944912 (59871/59904)
(1642954504.2477548, 1642954604.2952914, 100.047536611557)
Test epoch: 20| Acc: 99.42 (9942/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001895 | Loss_in_diffu: 11.973733 | Loss_out_diffu: 14.299827 | Acc: 99.976629 (59890/59904)
(1642954604.8669894, 1642954704.8896706, 100.02268123626709)
Test epoch: 21| Acc: 99.47 (9947/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001780 | Loss_in_diffu: 11.973958 | Loss_out_diffu: 14.303592 | Acc: 99.979968 (59892/59904)
(1642954705.4711301, 1642954805.451149, 99.98001885414124)
Test epoch: 22| Acc: 99.46 (9946/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001728 | Loss_in_diffu: 11.974190 | Loss_out_diffu: 14.301036 | Acc: 99.979968 (59892/59904)
(1642954806.0189, 1642954905.5335577, 99.51465773582458)
Test epoch: 23| Acc: 99.47 (9947/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001675 | Loss_in_diffu: 11.973971 | Loss_out_diffu: 14.311723 | Acc: 99.981637 (59893/59904)
(1642954906.1125784, 1642955005.8164606, 99.70388221740723)
Test epoch: 24| Acc: 99.49 (9949/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001647 | Loss_in_diffu: 11.974366 | Loss_out_diffu: 14.312254 | Acc: 99.979968 (59892/59904)
(1642955006.390009, 1642955105.932772, 99.54276299476624)
Test epoch: 25| Acc: 99.49 (9949/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001613 | Loss_in_diffu: 11.974249 | Loss_out_diffu: 14.317736 | Acc: 99.981637 (59893/59904)
(1642955106.5149567, 1642955206.6279807, 100.11302399635315)
Test epoch: 26| Acc: 99.47 (9947/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001585 | Loss_in_diffu: 11.974404 | Loss_out_diffu: 14.319958 | Acc: 99.979968 (59892/59904)
(1642955207.2089841, 1642955306.8186355, 99.60965132713318)
Test epoch: 27| Acc: 99.5 (9950/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001542 | Loss_in_diffu: 11.974605 | Loss_out_diffu: 14.327089 | Acc: 99.983307 (59894/59904)
(1642955307.400749, 1642955407.6987166, 100.29796767234802)
Test epoch: 28| Acc: 99.5 (9950/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001515 | Loss_in_diffu: 11.974759 | Loss_out_diffu: 14.329731 | Acc: 99.984976 (59895/59904)
(1642955408.281183, 1642955507.7822168, 99.50103378295898)
Test epoch: 29| Acc: 99.5 (9950/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001483 | Loss_in_diffu: 11.974668 | Loss_out_diffu: 14.335229 | Acc: 99.984976 (59895/59904)
(1642955508.3535793, 1642955608.4507372, 100.09715795516968)
Test epoch: 30| Acc: 99.5 (9950/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001422 | Loss_in_diffu: 11.974724 | Loss_out_diffu: 14.334538 | Acc: 99.986645 (59896/59904)
(1642955609.0322933, 1642955708.602617, 99.57032370567322)
Test epoch: 31| Acc: 99.48 (9948/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001418 | Loss_in_diffu: 11.974735 | Loss_out_diffu: 14.334395 | Acc: 99.986645 (59896/59904)
(1642955709.171423, 1642955808.909746, 99.73832297325134)
Test epoch: 32| Acc: 99.49 (9949/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001413 | Loss_in_diffu: 11.974965 | Loss_out_diffu: 14.336103 | Acc: 99.986645 (59896/59904)
(1642955809.4896467, 1642955909.1858413, 99.69619464874268)
Test epoch: 33| Acc: 99.47 (9947/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001409 | Loss_in_diffu: 11.974771 | Loss_out_diffu: 14.339048 | Acc: 99.986645 (59896/59904)
(1642955909.7677531, 1642956009.3724217, 99.60466861724854)
Test epoch: 34| Acc: 99.5 (9950/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001403 | Loss_in_diffu: 11.975028 | Loss_out_diffu: 14.338451 | Acc: 99.986645 (59896/59904)
(1642956009.954013, 1642956110.1531782, 100.1991651058197)
Test epoch: 35| Acc: 99.48 (9948/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001403 | Loss_in_diffu: 11.974793 | Loss_out_diffu: 14.336693 | Acc: 99.986645 (59896/59904)
(1642956110.7226233, 1642956210.329376, 99.60675263404846)
Test epoch: 36| Acc: 99.48 (9948/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001399 | Loss_in_diffu: 11.974788 | Loss_out_diffu: 14.343336 | Acc: 99.986645 (59896/59904)
(1642956210.91577, 1642956310.4190617, 99.50329160690308)
Test epoch: 37| Acc: 99.47 (9947/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001394 | Loss_in_diffu: 11.975048 | Loss_out_diffu: 14.337785 | Acc: 99.986645 (59896/59904)
(1642956311.000315, 1642956410.6406944, 99.64037942886353)
Test epoch: 38| Acc: 99.48 (9948/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001390 | Loss_in_diffu: 11.974899 | Loss_out_diffu: 14.339678 | Acc: 99.986645 (59896/59904)
(1642956411.218923, 1642956511.2309124, 100.01198935508728)
Test epoch: 39| Acc: 99.48 (9948/10000) 
