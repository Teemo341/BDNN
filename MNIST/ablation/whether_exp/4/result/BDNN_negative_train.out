True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.626264 | Loss_in_diffu: 11.664056 | Loss_out_diffu: 12.160314 | Acc: 85.735510 (51359/59904)
(1642952503.1095572, 1642952602.8424137, 99.7328565120697)
Test epoch: 0| Acc: 96.94 (9694/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.103563 | Loss_in_diffu: 11.238285 | Loss_out_diffu: 12.760368 | Acc: 97.270633 (58269/59904)
(1642952603.4424047, 1642952703.8287635, 100.38635873794556)
Test epoch: 1| Acc: 97.62 (9762/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.067789 | Loss_in_diffu: 11.270221 | Loss_out_diffu: 13.015924 | Acc: 98.127003 (58782/59904)
(1642952704.4282336, 1642952804.5718718, 100.14363813400269)
Test epoch: 2| Acc: 98.94 (9894/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.053263 | Loss_in_diffu: 11.324435 | Loss_out_diffu: 13.199002 | Acc: 98.490919 (59000/59904)
(1642952805.1430395, 1642952904.3174539, 99.17441439628601)
Test epoch: 3| Acc: 98.69 (9869/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.043994 | Loss_in_diffu: 11.388563 | Loss_out_diffu: 13.346037 | Acc: 98.717949 (59136/59904)
(1642952905.0289044, 1642953004.64065, 99.611745595932)
Test epoch: 4| Acc: 98.69 (9869/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.042603 | Loss_in_diffu: 11.465457 | Loss_out_diffu: 13.488020 | Acc: 98.742989 (59151/59904)
(1642953005.2333722, 1642953105.5185015, 100.28512930870056)
Test epoch: 5| Acc: 98.88 (9888/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.035229 | Loss_in_diffu: 11.539667 | Loss_out_diffu: 13.610592 | Acc: 98.971688 (59288/59904)
(1642953106.1049268, 1642953205.951405, 99.84647822380066)
Test epoch: 6| Acc: 98.71 (9871/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.032935 | Loss_in_diffu: 11.626920 | Loss_out_diffu: 13.772523 | Acc: 99.021768 (59318/59904)
(1642953206.6640146, 1642953306.0830586, 99.41904401779175)
Test epoch: 7| Acc: 98.06 (9806/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.028403 | Loss_in_diffu: 11.719538 | Loss_out_diffu: 13.914682 | Acc: 99.187033 (59417/59904)
(1642953306.6932166, 1642953406.913864, 100.22064733505249)
Test epoch: 8| Acc: 99.02 (9902/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.026795 | Loss_in_diffu: 11.805692 | Loss_out_diffu: 14.067026 | Acc: 99.200387 (59425/59904)
(1642953407.4959362, 1642953506.9673514, 99.47141528129578)
Test epoch: 9| Acc: 99.11 (9911/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.025250 | Loss_in_diffu: 11.898397 | Loss_out_diffu: 14.181134 | Acc: 99.228766 (59442/59904)
(1642953507.5556228, 1642953607.0027246, 99.44710183143616)
Test epoch: 10| Acc: 98.99 (9899/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.008703 | Loss_in_diffu: 11.939670 | Loss_out_diffu: 14.239570 | Acc: 99.784655 (59775/59904)
(1642953607.5907996, 1642953707.3357646, 99.74496507644653)
Test epoch: 11| Acc: 99.45 (9945/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006470 | Loss_in_diffu: 11.939533 | Loss_out_diffu: 14.257045 | Acc: 99.846421 (59812/59904)
(1642953707.9225667, 1642953807.6598313, 99.73726463317871)
Test epoch: 12| Acc: 99.45 (9945/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005727 | Loss_in_diffu: 11.941430 | Loss_out_diffu: 14.270369 | Acc: 99.851429 (59815/59904)
(1642953808.2527685, 1642953907.9872484, 99.7344799041748)
Test epoch: 13| Acc: 99.43 (9943/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004634 | Loss_in_diffu: 11.942647 | Loss_out_diffu: 14.292493 | Acc: 99.891493 (59839/59904)
(1642953908.5752156, 1642954008.4814622, 99.90624666213989)
Test epoch: 14| Acc: 99.49 (9949/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004473 | Loss_in_diffu: 11.945190 | Loss_out_diffu: 14.309830 | Acc: 99.894832 (59841/59904)
(1642954009.0696094, 1642954108.5951207, 99.52551126480103)
Test epoch: 15| Acc: 99.49 (9949/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003536 | Loss_in_diffu: 11.946736 | Loss_out_diffu: 14.332920 | Acc: 99.926549 (59860/59904)
(1642954109.1827147, 1642954208.5868762, 99.40416145324707)
Test epoch: 16| Acc: 99.37 (9937/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003393 | Loss_in_diffu: 11.948996 | Loss_out_diffu: 14.354942 | Acc: 99.928218 (59861/59904)
(1642954209.1750042, 1642954308.3308256, 99.15582132339478)
Test epoch: 17| Acc: 99.43 (9943/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003138 | Loss_in_diffu: 11.951453 | Loss_out_diffu: 14.373981 | Acc: 99.926549 (59860/59904)
(1642954308.9191828, 1642954408.6254945, 99.70631170272827)
Test epoch: 18| Acc: 99.51 (9951/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002711 | Loss_in_diffu: 11.953021 | Loss_out_diffu: 14.394941 | Acc: 99.936565 (59866/59904)
(1642954409.322546, 1642954508.5939229, 99.27137684822083)
Test epoch: 19| Acc: 99.34 (9934/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002407 | Loss_in_diffu: 11.954885 | Loss_out_diffu: 14.417631 | Acc: 99.946581 (59872/59904)
(1642954509.2897894, 1642954609.3225372, 100.03274774551392)
Test epoch: 20| Acc: 99.5 (9950/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001565 | Loss_in_diffu: 11.955271 | Loss_out_diffu: 14.428154 | Acc: 99.978299 (59891/59904)
(1642954609.9166985, 1642954709.2445977, 99.32789921760559)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001461 | Loss_in_diffu: 11.955556 | Loss_out_diffu: 14.432951 | Acc: 99.978299 (59891/59904)
(1642954709.9524572, 1642954809.4181607, 99.46570348739624)
Test epoch: 22| Acc: 99.52 (9952/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001413 | Loss_in_diffu: 11.955789 | Loss_out_diffu: 14.430435 | Acc: 99.981637 (59893/59904)
(1642954810.1266248, 1642954909.5440059, 99.41738104820251)
Test epoch: 23| Acc: 99.5 (9950/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001360 | Loss_in_diffu: 11.955582 | Loss_out_diffu: 14.441472 | Acc: 99.983307 (59894/59904)
(1642954910.2651038, 1642955009.6749458, 99.40984201431274)
Test epoch: 24| Acc: 99.5 (9950/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001321 | Loss_in_diffu: 11.955978 | Loss_out_diffu: 14.442757 | Acc: 99.984976 (59895/59904)
(1642955010.3813806, 1642955110.181935, 99.80055451393127)
Test epoch: 25| Acc: 99.48 (9948/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001284 | Loss_in_diffu: 11.955854 | Loss_out_diffu: 14.448303 | Acc: 99.984976 (59895/59904)
(1642955110.8891592, 1642955210.2062728, 99.3171136379242)
Test epoch: 26| Acc: 99.47 (9947/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001253 | Loss_in_diffu: 11.956007 | Loss_out_diffu: 14.450349 | Acc: 99.983307 (59894/59904)
(1642955210.914427, 1642955310.148739, 99.23431205749512)
Test epoch: 27| Acc: 99.53 (9953/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001200 | Loss_in_diffu: 11.956198 | Loss_out_diffu: 14.458471 | Acc: 99.986645 (59896/59904)
(1642955310.846862, 1642955410.4244437, 99.57758164405823)
Test epoch: 28| Acc: 99.45 (9945/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001162 | Loss_in_diffu: 11.956340 | Loss_out_diffu: 14.461333 | Acc: 99.986645 (59896/59904)
(1642955411.1205146, 1642955511.0351644, 99.91464972496033)
Test epoch: 29| Acc: 99.45 (9945/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001138 | Loss_in_diffu: 11.956268 | Loss_out_diffu: 14.466062 | Acc: 99.984976 (59895/59904)
(1642955511.7438536, 1642955611.9045305, 100.16067695617676)
Test epoch: 30| Acc: 99.48 (9948/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001075 | Loss_in_diffu: 11.956290 | Loss_out_diffu: 14.465668 | Acc: 99.986645 (59896/59904)
(1642955612.6118913, 1642955712.751162, 100.1392707824707)
Test epoch: 31| Acc: 99.48 (9948/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001064 | Loss_in_diffu: 11.956319 | Loss_out_diffu: 14.465738 | Acc: 99.986645 (59896/59904)
(1642955713.448749, 1642955812.9080083, 99.4592592716217)
Test epoch: 32| Acc: 99.47 (9947/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001050 | Loss_in_diffu: 11.956556 | Loss_out_diffu: 14.468515 | Acc: 99.986645 (59896/59904)
(1642955813.4932396, 1642955913.1469884, 99.65374875068665)
Test epoch: 33| Acc: 99.46 (9946/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001046 | Loss_in_diffu: 11.956347 | Loss_out_diffu: 14.470741 | Acc: 99.986645 (59896/59904)
(1642955913.7309277, 1642956013.7573662, 100.02643847465515)
Test epoch: 34| Acc: 99.49 (9949/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001045 | Loss_in_diffu: 11.956610 | Loss_out_diffu: 14.470840 | Acc: 99.986645 (59896/59904)
(1642956014.4654791, 1642956114.0910754, 99.62559628486633)
Test epoch: 35| Acc: 99.46 (9946/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001044 | Loss_in_diffu: 11.956370 | Loss_out_diffu: 14.469110 | Acc: 99.988315 (59897/59904)
(1642956114.6872401, 1642956213.7529747, 99.06573462486267)
Test epoch: 36| Acc: 99.46 (9946/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001035 | Loss_in_diffu: 11.956363 | Loss_out_diffu: 14.475921 | Acc: 99.986645 (59896/59904)
(1642956214.3494725, 1642956313.4020772, 99.05260467529297)
Test epoch: 37| Acc: 99.47 (9947/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001031 | Loss_in_diffu: 11.956622 | Loss_out_diffu: 14.469892 | Acc: 99.988315 (59897/59904)
(1642956313.997022, 1642956413.0311744, 99.03415250778198)
Test epoch: 38| Acc: 99.47 (9947/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001028 | Loss_in_diffu: 11.956472 | Loss_out_diffu: 14.471785 | Acc: 99.989984 (59898/59904)
(1642956413.7389092, 1642956513.406286, 99.66737675666809)
Test epoch: 39| Acc: 99.45 (9945/10000) 
