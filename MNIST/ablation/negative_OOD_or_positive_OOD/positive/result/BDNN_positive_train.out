True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.510959 | Loss_in_diffu: 10.061041 | Loss_out_diffu: 10.084702 | Acc: 88.950654 (53285/59904)
(1638328529.7730958, 1638328630.362229, 100.58913326263428)
Test epoch: 0| Acc: 97.64 (9764/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.086919 | Loss_in_diffu: 8.413595 | Loss_out_diffu: 8.715811 | Acc: 97.743056 (58552/59904)
(1638328630.9689717, 1638328731.7878237, 100.81885194778442)
Test epoch: 1| Acc: 98.04 (9804/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.065147 | Loss_in_diffu: 7.345099 | Loss_out_diffu: 7.639531 | Acc: 98.260550 (58862/59904)
(1638328732.4954348, 1638328832.3090506, 99.8136157989502)
Test epoch: 2| Acc: 98.81 (9881/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.053855 | Loss_in_diffu: 6.355847 | Loss_out_diffu: 6.655486 | Acc: 98.542668 (59031/59904)
(1638328833.0116615, 1638328932.564154, 99.55249238014221)
Test epoch: 3| Acc: 98.39 (9839/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.045146 | Loss_in_diffu: 5.420232 | Loss_out_diffu: 5.719567 | Acc: 98.779714 (59173/59904)
(1638328933.1490598, 1638329032.6238823, 99.47482252120972)
Test epoch: 4| Acc: 98.74 (9874/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.039040 | Loss_in_diffu: 4.521701 | Loss_out_diffu: 4.823732 | Acc: 98.966680 (59285/59904)
(1638329033.331745, 1638329133.188033, 99.85628819465637)
Test epoch: 5| Acc: 98.66 (9866/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.037655 | Loss_in_diffu: 3.671487 | Loss_out_diffu: 3.994330 | Acc: 98.988381 (59298/59904)
(1638329133.7836623, 1638329234.2566462, 100.47298383712769)
Test epoch: 6| Acc: 98.82 (9882/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.032029 | Loss_in_diffu: 2.887148 | Loss_out_diffu: 3.201818 | Acc: 99.120259 (59377/59904)
(1638329234.842897, 1638329334.6570482, 99.81415128707886)
Test epoch: 7| Acc: 99.3 (9930/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.024380 | Loss_in_diffu: 2.151055 | Loss_out_diffu: 2.466869 | Acc: 99.337273 (59507/59904)
(1638329335.2624292, 1638329435.1682007, 99.90577149391174)
Test epoch: 8| Acc: 99.17 (9917/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.023585 | Loss_in_diffu: 1.513910 | Loss_out_diffu: 1.830706 | Acc: 99.322249 (59498/59904)
(1638329435.7687085, 1638329535.4061084, 99.6373999118805)
Test epoch: 9| Acc: 99.09 (9909/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.022812 | Loss_in_diffu: 1.012369 | Loss_out_diffu: 1.329326 | Acc: 99.365652 (59524/59904)
(1638329536.0036895, 1638329635.4179711, 99.4142816066742)
Test epoch: 10| Acc: 99.27 (9927/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009266 | Loss_in_diffu: 0.780839 | Loss_out_diffu: 1.100263 | Acc: 99.756277 (59758/59904)
(1638329636.0248158, 1638329735.892159, 99.86734318733215)
Test epoch: 11| Acc: 99.46 (9946/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006263 | Loss_in_diffu: 0.736252 | Loss_out_diffu: 1.059256 | Acc: 99.851429 (59815/59904)
(1638329736.4823184, 1638329836.1960666, 99.71374821662903)
Test epoch: 12| Acc: 99.41 (9941/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005825 | Loss_in_diffu: 0.695276 | Loss_out_diffu: 1.019029 | Acc: 99.868122 (59825/59904)
(1638329836.9022648, 1638329937.4372063, 100.53494143486023)
Test epoch: 13| Acc: 99.41 (9941/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005104 | Loss_in_diffu: 0.655275 | Loss_out_diffu: 0.979864 | Acc: 99.891493 (59839/59904)
(1638329938.0394504, 1638330037.6705961, 99.6311457157135)
Test epoch: 14| Acc: 99.51 (9951/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004891 | Loss_in_diffu: 0.617468 | Loss_out_diffu: 0.942215 | Acc: 99.886485 (59836/59904)
(1638330038.3738306, 1638330137.9311948, 99.55736422538757)
Test epoch: 15| Acc: 99.37 (9937/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004742 | Loss_in_diffu: 0.581725 | Loss_out_diffu: 0.907007 | Acc: 99.881477 (59833/59904)
(1638330138.6487663, 1638330238.15026, 99.50149369239807)
Test epoch: 16| Acc: 99.48 (9948/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004223 | Loss_in_diffu: 0.547851 | Loss_out_diffu: 0.873431 | Acc: 99.898170 (59843/59904)
(1638330238.754054, 1638330338.1166909, 99.36263680458069)
Test epoch: 17| Acc: 99.37 (9937/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004337 | Loss_in_diffu: 0.515685 | Loss_out_diffu: 0.842347 | Acc: 99.899840 (59844/59904)
(1638330338.8355355, 1638330438.9968421, 100.16130661964417)
Test epoch: 18| Acc: 99.34 (9934/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004292 | Loss_in_diffu: 0.486545 | Loss_out_diffu: 0.812958 | Acc: 99.896501 (59842/59904)
(1638330439.7064123, 1638330540.195667, 100.48925471305847)
Test epoch: 19| Acc: 99.42 (9942/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003957 | Loss_in_diffu: 0.458109 | Loss_out_diffu: 0.785247 | Acc: 99.903178 (59846/59904)
(1638330540.7956157, 1638330640.4755075, 99.67989182472229)
Test epoch: 20| Acc: 99.48 (9948/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002711 | Loss_in_diffu: 0.442475 | Loss_out_diffu: 0.769923 | Acc: 99.956597 (59878/59904)
(1638330641.2010746, 1638330740.901593, 99.70051836967468)
Test epoch: 21| Acc: 99.46 (9946/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002504 | Loss_in_diffu: 0.439358 | Loss_out_diffu: 0.767236 | Acc: 99.953259 (59876/59904)
(1638330741.610431, 1638330842.0379603, 100.42752933502197)
Test epoch: 22| Acc: 99.43 (9943/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.002527 | Loss_in_diffu: 0.436660 | Loss_out_diffu: 0.764568 | Acc: 99.953259 (59876/59904)
(1638330842.746627, 1638330942.560896, 99.81426882743835)
Test epoch: 23| Acc: 99.4 (9940/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.002471 | Loss_in_diffu: 0.433574 | Loss_out_diffu: 0.761816 | Acc: 99.958267 (59879/59904)
(1638330943.2716007, 1638331044.090842, 100.8192412853241)
Test epoch: 24| Acc: 99.4 (9940/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.002529 | Loss_in_diffu: 0.430930 | Loss_out_diffu: 0.759137 | Acc: 99.956597 (59878/59904)
(1638331044.8025362, 1638331145.3496847, 100.54714846611023)
Test epoch: 25| Acc: 99.48 (9948/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.002514 | Loss_in_diffu: 0.427929 | Loss_out_diffu: 0.756313 | Acc: 99.951589 (59875/59904)
(1638331146.0679362, 1638331245.4259036, 99.35796737670898)
Test epoch: 26| Acc: 99.43 (9943/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.002220 | Loss_in_diffu: 0.425421 | Loss_out_diffu: 0.753557 | Acc: 99.969952 (59886/59904)
(1638331246.0207045, 1638331346.452283, 100.43157839775085)
Test epoch: 27| Acc: 99.47 (9947/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.002445 | Loss_in_diffu: 0.422446 | Loss_out_diffu: 0.750953 | Acc: 99.961605 (59881/59904)
(1638331347.218167, 1638331446.7730882, 99.55492115020752)
Test epoch: 28| Acc: 99.42 (9942/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.002575 | Loss_in_diffu: 0.419931 | Loss_out_diffu: 0.748198 | Acc: 99.951589 (59875/59904)
(1638331447.3577724, 1638331548.5095432, 101.15177083015442)
Test epoch: 29| Acc: 99.39 (9939/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.002143 | Loss_in_diffu: 0.417143 | Loss_out_diffu: 0.745714 | Acc: 99.969952 (59886/59904)
(1638331549.099744, 1638331648.865907, 99.76616287231445)
Test epoch: 30| Acc: 99.43 (9943/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.002191 | Loss_in_diffu: 0.415628 | Loss_out_diffu: 0.744117 | Acc: 99.959936 (59880/59904)
(1638331649.4653063, 1638331749.6364887, 100.17118239402771)
Test epoch: 31| Acc: 99.39 (9939/10000) 

Epoch: 32
