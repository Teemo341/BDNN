True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.584300 | Loss_in_diffu: 10.193530 | Loss_out_diffu: 10.154158 | Acc: 87.075988 (52162/59904)
(1638323201.4889452, 1638323302.2613983, 100.77245306968689)
Test epoch: 0| Acc: 96.99 (9699/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.095980 | Loss_in_diffu: 8.557739 | Loss_out_diffu: 8.840898 | Acc: 97.531050 (58425/59904)
(1638323302.9688327, 1638323403.6190016, 100.65016889572144)
Test epoch: 1| Acc: 97.08 (9708/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.067488 | Loss_in_diffu: 7.489417 | Loss_out_diffu: 7.774196 | Acc: 98.177083 (58812/59904)
(1638323404.3386803, 1638323504.5629508, 100.2242705821991)
Test epoch: 2| Acc: 98.71 (9871/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.057931 | Loss_in_diffu: 6.504161 | Loss_out_diffu: 6.790137 | Acc: 98.402444 (58947/59904)
(1638323505.2721286, 1638323605.58406, 100.31193137168884)
Test epoch: 3| Acc: 98.47 (9847/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048376 | Loss_in_diffu: 5.564830 | Loss_out_diffu: 5.857337 | Acc: 98.661191 (59102/59904)
(1638323606.2905025, 1638323706.729677, 100.43917441368103)
Test epoch: 4| Acc: 99.28 (9928/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.042887 | Loss_in_diffu: 4.671149 | Loss_out_diffu: 4.966973 | Acc: 98.793069 (59181/59904)
(1638323707.4356322, 1638323806.9347773, 99.49914503097534)
Test epoch: 5| Acc: 98.97 (9897/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.038032 | Loss_in_diffu: 3.811120 | Loss_out_diffu: 4.122112 | Acc: 98.931624 (59264/59904)
(1638323807.652598, 1638323907.116509, 99.46391105651855)
Test epoch: 6| Acc: 98.95 (9895/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.032617 | Loss_in_diffu: 3.006033 | Loss_out_diffu: 3.314104 | Acc: 99.103566 (59367/59904)
(1638323907.7098656, 1638324007.8645682, 100.15470266342163)
Test epoch: 7| Acc: 99.01 (9901/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.026633 | Loss_in_diffu: 2.253548 | Loss_out_diffu: 2.565142 | Acc: 99.215411 (59434/59904)
(1638324008.5822601, 1638324107.924467, 99.34220695495605)
Test epoch: 8| Acc: 98.11 (9811/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.024634 | Loss_in_diffu: 1.594443 | Loss_out_diffu: 1.907556 | Acc: 99.313902 (59493/59904)
(1638324108.6419933, 1638324208.3029566, 99.66096329689026)
Test epoch: 9| Acc: 99.38 (9938/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.021747 | Loss_in_diffu: 1.059185 | Loss_out_diffu: 1.374741 | Acc: 99.394030 (59541/59904)
(1638324208.8968072, 1638324308.4210813, 99.52427411079407)
Test epoch: 10| Acc: 99.26 (9926/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.008535 | Loss_in_diffu: 0.809258 | Loss_out_diffu: 1.128432 | Acc: 99.777978 (59771/59904)
(1638324309.0223813, 1638324409.8154428, 100.79306149482727)
Test epoch: 11| Acc: 99.48 (9948/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006281 | Loss_in_diffu: 0.761825 | Loss_out_diffu: 1.084427 | Acc: 99.863114 (59822/59904)
(1638324410.5299985, 1638324510.5822992, 100.05230069160461)
Test epoch: 12| Acc: 99.5 (9950/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006036 | Loss_in_diffu: 0.719096 | Loss_out_diffu: 1.042268 | Acc: 99.851429 (59815/59904)
(1638324511.1788254, 1638324611.5180902, 100.33926486968994)
Test epoch: 13| Acc: 99.4 (9940/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.005265 | Loss_in_diffu: 0.677566 | Loss_out_diffu: 1.001732 | Acc: 99.891493 (59839/59904)
(1638324612.238125, 1638324711.9955513, 99.75742626190186)
Test epoch: 14| Acc: 99.49 (9949/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.005276 | Loss_in_diffu: 0.638287 | Loss_out_diffu: 0.962604 | Acc: 99.868122 (59825/59904)
(1638324712.7104225, 1638324812.6118813, 99.90145874023438)
Test epoch: 15| Acc: 99.43 (9943/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.004645 | Loss_in_diffu: 0.600910 | Loss_out_diffu: 0.925498 | Acc: 99.893162 (59840/59904)
(1638324813.3313298, 1638324913.550004, 100.21867418289185)
Test epoch: 16| Acc: 99.46 (9946/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004324 | Loss_in_diffu: 0.565217 | Loss_out_diffu: 0.890766 | Acc: 99.896501 (59842/59904)
(1638324914.1384935, 1638325014.563397, 100.42490339279175)
Test epoch: 17| Acc: 99.46 (9946/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004548 | Loss_in_diffu: 0.532052 | Loss_out_diffu: 0.857819 | Acc: 99.899840 (59844/59904)
(1638325015.2832372, 1638325115.56709, 100.28385281562805)
Test epoch: 18| Acc: 99.39 (9939/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004482 | Loss_in_diffu: 0.500932 | Loss_out_diffu: 0.826770 | Acc: 99.883146 (59834/59904)
(1638325116.285452, 1638325217.160892, 100.87544012069702)
Test epoch: 19| Acc: 99.43 (9943/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003510 | Loss_in_diffu: 0.470785 | Loss_out_diffu: 0.797505 | Acc: 99.913194 (59852/59904)
(1638325217.8799703, 1638325318.2104259, 100.33045554161072)
Test epoch: 20| Acc: 99.23 (9923/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002701 | Loss_in_diffu: 0.454844 | Loss_out_diffu: 0.781568 | Acc: 99.939904 (59868/59904)
(1638325318.8613892, 1638325418.4505825, 99.58919334411621)
Test epoch: 21| Acc: 99.48 (9948/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002446 | Loss_in_diffu: 0.451384 | Loss_out_diffu: 0.778578 | Acc: 99.961605 (59881/59904)
(1638325419.1598754, 1638325519.872924, 100.71304869651794)
Test epoch: 22| Acc: 99.47 (9947/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.002433 | Loss_in_diffu: 0.448612 | Loss_out_diffu: 0.775709 | Acc: 99.953259 (59876/59904)
(1638325520.4818501, 1638325621.4078386, 100.92598843574524)
Test epoch: 23| Acc: 99.45 (9945/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.002402 | Loss_in_diffu: 0.445208 | Loss_out_diffu: 0.772756 | Acc: 99.958267 (59879/59904)
(1638325622.005673, 1638325721.7345119, 99.72883892059326)
Test epoch: 24| Acc: 99.47 (9947/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.002323 | Loss_in_diffu: 0.442312 | Loss_out_diffu: 0.769955 | Acc: 99.959936 (59880/59904)
(1638325722.4421318, 1638325822.1733978, 99.73126602172852)
Test epoch: 25| Acc: 99.46 (9946/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.002472 | Loss_in_diffu: 0.439209 | Loss_out_diffu: 0.766989 | Acc: 99.946581 (59872/59904)
(1638325822.8875275, 1638325923.2105536, 100.32302618026733)
Test epoch: 26| Acc: 99.47 (9947/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.002329 | Loss_in_diffu: 0.436530 | Loss_out_diffu: 0.764150 | Acc: 99.963275 (59882/59904)
(1638325923.8102098, 1638326023.9465654, 100.13635563850403)
Test epoch: 27| Acc: 99.45 (9945/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.002322 | Loss_in_diffu: 0.433628 | Loss_out_diffu: 0.761462 | Acc: 99.964944 (59883/59904)
(1638326024.5403585, 1638326125.1005068, 100.56014823913574)
Test epoch: 28| Acc: 99.51 (9951/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.002354 | Loss_in_diffu: 0.430834 | Loss_out_diffu: 0.758575 | Acc: 99.958267 (59879/59904)
(1638326125.817545, 1638326225.335258, 99.51771306991577)
Test epoch: 29| Acc: 99.43 (9943/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.002217 | Loss_in_diffu: 0.428041 | Loss_out_diffu: 0.755973 | Acc: 99.966613 (59884/59904)
(1638326225.9340422, 1638326326.7108247, 100.7767825126648)
Test epoch: 30| Acc: 99.43 (9943/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.002221 | Loss_in_diffu: 0.426388 | Loss_out_diffu: 0.754362 | Acc: 99.968283 (59885/59904)
(1638326327.3173294, 1638326427.7566571, 100.43932771682739)
Test epoch: 31| Acc: 99.44 (9944/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.002235 | Loss_in_diffu: 0.426269 | Loss_out_diffu: 0.754280 | Acc: 99.963275 (59882/59904)
(1638326428.4636304, 1638326528.217426, 99.7537956237793)
Test epoch: 32| Acc: 99.46 (9946/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.002144 | Loss_in_diffu: 0.425936 | Loss_out_diffu: 0.753947 | Acc: 99.974960 (59889/59904)
(1638326528.9375699, 1638326628.5876372, 99.65006732940674)
Test epoch: 33| Acc: 99.38 (9938/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.002223 | Loss_in_diffu: 0.425508 | Loss_out_diffu: 0.753627 | Acc: 99.973291 (59888/59904)
(1638326629.1806512, 1638326728.8551323, 99.67448115348816)
Test epoch: 34| Acc: 99.39 (9939/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.002052 | Loss_in_diffu: 0.425438 | Loss_out_diffu: 0.753399 | Acc: 99.969952 (59886/59904)
(1638326729.4631407, 1638326829.0281558, 99.56501507759094)
Test epoch: 35| Acc: 99.34 (9934/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.002178 | Loss_in_diffu: 0.425024 | Loss_out_diffu: 0.753112 | Acc: 99.966613 (59884/59904)
(1638326829.63009, 1638326929.2395513, 99.60946130752563)
Test epoch: 36| Acc: 99.39 (9939/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.002100 | Loss_in_diffu: 0.424663 | Loss_out_diffu: 0.752773 | Acc: 99.963275 (59882/59904)
(1638326929.832946, 1638327029.6357238, 99.8027777671814)
Test epoch: 37| Acc: 99.39 (9939/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.002084 | Loss_in_diffu: 0.424300 | Loss_out_diffu: 0.752701 | Acc: 99.968283 (59885/59904)
(1638327030.241524, 1638327130.504416, 100.26289200782776)
Test epoch: 38| Acc: 99.4 (9940/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001965 | Loss_in_diffu: 0.424122 | Loss_out_diffu: 0.752355 | Acc: 99.979968 (59892/59904)
(1638327131.2110946, 1638327231.608687, 100.39759230613708)
Test epoch: 39| Acc: 99.45 (9945/10000) 
