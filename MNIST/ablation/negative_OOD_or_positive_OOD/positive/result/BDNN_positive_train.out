True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.606296 | Loss_in_diffu: 10.245267 | Loss_out_diffu: 10.181984 | Acc: 86.324786 (51712/59904)
(1638290028.6415746, 1638290129.5760121, 100.93443751335144)
Test epoch: 0| Acc: 96.81 (9681/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.103103 | Loss_in_diffu: 8.615927 | Loss_out_diffu: 8.890990 | Acc: 97.262286 (58264/59904)
(1638290130.1760726, 1638290230.607469, 100.431396484375)
Test epoch: 1| Acc: 97.38 (9738/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.072031 | Loss_in_diffu: 7.554399 | Loss_out_diffu: 7.835032 | Acc: 97.971755 (58689/59904)
(1638290231.20698, 1638290331.8946068, 100.68762683868408)
Test epoch: 2| Acc: 98.44 (9844/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.059542 | Loss_in_diffu: 6.569453 | Loss_out_diffu: 6.853557 | Acc: 98.349025 (58915/59904)
(1638290332.6119447, 1638290432.0216236, 99.40967893600464)
Test epoch: 3| Acc: 98.17 (9817/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.049563 | Loss_in_diffu: 5.639499 | Loss_out_diffu: 5.930140 | Acc: 98.616119 (59075/59904)
(1638290432.729098, 1638290532.0097477, 99.28064966201782)
Test epoch: 4| Acc: 98.78 (9878/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.046077 | Loss_in_diffu: 4.754156 | Loss_out_diffu: 5.047698 | Acc: 98.679554 (59113/59904)
(1638290532.6046684, 1638290631.8938646, 99.28919625282288)
Test epoch: 5| Acc: 98.65 (9865/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.039288 | Loss_in_diffu: 3.904210 | Loss_out_diffu: 4.204664 | Acc: 98.874866 (59230/59904)
(1638290632.486987, 1638290731.9586015, 99.47161436080933)
Test epoch: 6| Acc: 98.92 (9892/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.034917 | Loss_in_diffu: 3.100143 | Loss_out_diffu: 3.404643 | Acc: 98.980035 (59293/59904)
(1638290732.6638124, 1638290832.5463762, 99.882563829422)
Test epoch: 7| Acc: 99.23 (9923/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.030408 | Loss_in_diffu: 2.366609 | Loss_out_diffu: 2.690896 | Acc: 99.197049 (59423/59904)
(1638290833.1524796, 1638290933.4797766, 100.32729697227478)
Test epoch: 8| Acc: 98.6 (9860/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.027252 | Loss_in_diffu: 1.722189 | Loss_out_diffu: 2.037055 | Acc: 99.248798 (59454/59904)
(1638290934.0867295, 1638291034.1960392, 100.10930967330933)
Test epoch: 9| Acc: 99.1 (9910/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.025210 | Loss_in_diffu: 1.183553 | Loss_out_diffu: 1.499707 | Acc: 99.280515 (59473/59904)
(1638291034.792756, 1638291135.2389483, 100.44619226455688)
Test epoch: 10| Acc: 99.5 (9950/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009382 | Loss_in_diffu: 0.923537 | Loss_out_diffu: 1.242645 | Acc: 99.761285 (59761/59904)
(1638291135.8267837, 1638291235.3859782, 99.55919456481934)
Test epoch: 11| Acc: 99.5 (9950/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.007384 | Loss_in_diffu: 0.874361 | Loss_out_diffu: 1.196699 | Acc: 99.813034 (59792/59904)
(1638291236.1002626, 1638291335.3702, 99.26993727684021)
Test epoch: 12| Acc: 99.48 (9948/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.006958 | Loss_in_diffu: 0.828194 | Loss_out_diffu: 1.151131 | Acc: 99.833066 (59804/59904)
(1638291335.9561787, 1638291435.5600734, 99.60389471054077)
Test epoch: 13| Acc: 99.42 (9942/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.006142 | Loss_in_diffu: 0.783001 | Loss_out_diffu: 1.107005 | Acc: 99.851429 (59815/59904)
(1638291436.146666, 1638291536.360585, 100.21391892433167)
Test epoch: 14| Acc: 99.46 (9946/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006641 | Loss_in_diffu: 0.740547 | Loss_out_diffu: 1.064240 | Acc: 99.819712 (59796/59904)
(1638291537.082628, 1638291636.8906467, 99.8080186843872)
Test epoch: 15| Acc: 99.53 (9953/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005552 | Loss_in_diffu: 0.699609 | Loss_out_diffu: 1.023736 | Acc: 99.854768 (59817/59904)
(1638291637.6088614, 1638291737.4141026, 99.80524110794067)
Test epoch: 16| Acc: 99.56 (9956/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.005423 | Loss_in_diffu: 0.660779 | Loss_out_diffu: 0.985470 | Acc: 99.856437 (59818/59904)
(1638291738.1304417, 1638291837.6299748, 99.49953317642212)
Test epoch: 17| Acc: 99.42 (9942/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.005039 | Loss_in_diffu: 0.624285 | Loss_out_diffu: 0.949157 | Acc: 99.874800 (59829/59904)
(1638291838.3489177, 1638291937.7550814, 99.40616369247437)
Test epoch: 18| Acc: 99.39 (9939/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.005253 | Loss_in_diffu: 0.589928 | Loss_out_diffu: 0.914874 | Acc: 99.858106 (59819/59904)
(1638291938.4597547, 1638292037.8789945, 99.41923975944519)
Test epoch: 19| Acc: 99.49 (9949/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.004506 | Loss_in_diffu: 0.556774 | Loss_out_diffu: 0.882275 | Acc: 99.889824 (59838/59904)
(1638292038.4764407, 1638292138.5552862, 100.07884550094604)
Test epoch: 20| Acc: 99.4 (9940/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.003451 | Loss_in_diffu: 0.538647 | Loss_out_diffu: 0.864496 | Acc: 99.924880 (59859/59904)
(1638292139.1649232, 1638292239.0257146, 99.86079144477844)
Test epoch: 21| Acc: 99.45 (9945/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.003231 | Loss_in_diffu: 0.534950 | Loss_out_diffu: 0.861246 | Acc: 99.933226 (59864/59904)
(1638292239.6219316, 1638292339.3357348, 99.7138032913208)
Test epoch: 22| Acc: 99.46 (9946/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.003177 | Loss_in_diffu: 0.531848 | Loss_out_diffu: 0.858045 | Acc: 99.939904 (59868/59904)
(1638292340.045025, 1638292440.554686, 100.50966095924377)
Test epoch: 23| Acc: 99.56 (9956/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.003095 | Loss_in_diffu: 0.528236 | Loss_out_diffu: 0.854750 | Acc: 99.938235 (59867/59904)
(1638292441.1438851, 1638292541.6863327, 100.54244756698608)
Test epoch: 24| Acc: 99.45 (9945/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.002880 | Loss_in_diffu: 0.525218 | Loss_out_diffu: 0.851758 | Acc: 99.949920 (59874/59904)
(1638292542.3953068, 1638292641.7931504, 99.39784359931946)
Test epoch: 25| Acc: 99.5 (9950/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.003226 | Loss_in_diffu: 0.521670 | Loss_out_diffu: 0.848341 | Acc: 99.931557 (59863/59904)
(1638292642.5019174, 1638292742.0241094, 99.52219200134277)
Test epoch: 26| Acc: 99.42 (9942/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.002929 | Loss_in_diffu: 0.518742 | Loss_out_diffu: 0.845226 | Acc: 99.944912 (59871/59904)
(1638292742.7445974, 1638292843.1871727, 100.44257521629333)
Test epoch: 27| Acc: 99.49 (9949/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.003142 | Loss_in_diffu: 0.515378 | Loss_out_diffu: 0.842158 | Acc: 99.938235 (59867/59904)
(1638292843.9082015, 1638292944.0190134, 100.11081194877625)
Test epoch: 28| Acc: 99.4 (9940/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.003203 | Loss_in_diffu: 0.512514 | Loss_out_diffu: 0.838973 | Acc: 99.926549 (59860/59904)
(1638292944.739355, 1638293044.8851001, 100.1457450389862)
Test epoch: 29| Acc: 99.37 (9937/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.003050 | Loss_in_diffu: 0.509414 | Loss_out_diffu: 0.835894 | Acc: 99.939904 (59868/59904)
(1638293045.489894, 1638293145.1488683, 99.6589744091034)
Test epoch: 30| Acc: 99.49 (9949/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.002879 | Loss_in_diffu: 0.507378 | Loss_out_diffu: 0.834409 | Acc: 99.948251 (59873/59904)
(1638293145.7471945, 1638293246.011814, 100.26461958885193)
Test epoch: 31| Acc: 99.43 (9943/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.002959 | Loss_in_diffu: 0.507468 | Loss_out_diffu: 0.834037 | Acc: 99.943243 (59870/59904)
(1638293246.7186556, 1638293346.4582882, 99.73963260650635)
Test epoch: 32| Acc: 99.46 (9946/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.002963 | Loss_in_diffu: 0.506997 | Loss_out_diffu: 0.833741 | Acc: 99.936565 (59866/59904)
(1638293347.0456629, 1638293447.7694862, 100.7238233089447)
Test epoch: 33| Acc: 99.43 (9943/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.003064 | Loss_in_diffu: 0.506579 | Loss_out_diffu: 0.833412 | Acc: 99.948251 (59873/59904)
(1638293448.475832, 1638293549.147348, 100.67151594161987)
Test epoch: 34| Acc: 99.51 (9951/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.002866 | Loss_in_diffu: 0.506391 | Loss_out_diffu: 0.833295 | Acc: 99.943243 (59870/59904)
(1638293549.757345, 1638293649.656203, 99.89885807037354)
Test epoch: 35| Acc: 99.39 (9939/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.002804 | Loss_in_diffu: 0.505948 | Loss_out_diffu: 0.832914 | Acc: 99.958267 (59879/59904)
(1638293650.2441802, 1638293749.9386835, 99.69450330734253)
Test epoch: 36| Acc: 99.46 (9946/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.002897 | Loss_in_diffu: 0.505559 | Loss_out_diffu: 0.832463 | Acc: 99.949920 (59874/59904)
(1638293750.6600404, 1638293850.2407057, 99.58066534996033)
Test epoch: 37| Acc: 99.45 (9945/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.002787 | Loss_in_diffu: 0.505264 | Loss_out_diffu: 0.832378 | Acc: 99.948251 (59873/59904)
(1638293850.8486984, 1638293950.4424822, 99.59378385543823)
Test epoch: 38| Acc: 99.49 (9949/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.002899 | Loss_in_diffu: 0.505085 | Loss_out_diffu: 0.831915 | Acc: 99.941573 (59869/59904)
(1638293951.1574802, 1638294051.0562117, 99.89873147010803)
Test epoch: 39| Acc: 99.48 (9948/10000) 
