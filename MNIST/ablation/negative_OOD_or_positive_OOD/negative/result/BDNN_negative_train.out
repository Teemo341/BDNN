True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.695910 | Loss_in_diffu: 11.755967 | Loss_out_diffu: 12.179609 | Acc: 83.732305 (50159/59904)
(1638289994.8167949, 1638290094.3942096, 99.57741475105286)
Test epoch: 0| Acc: 96.4 (9640/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.123187 | Loss_in_diffu: 11.303955 | Loss_out_diffu: 12.700410 | Acc: 96.753138 (57959/59904)
(1638290095.1109502, 1638290193.7782104, 98.66726016998291)
Test epoch: 1| Acc: 97.36 (9736/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.077874 | Loss_in_diffu: 11.336238 | Loss_out_diffu: 12.894360 | Acc: 97.811498 (58593/59904)
(1638290194.3644757, 1638290293.892637, 99.52816128730774)
Test epoch: 2| Acc: 97.54 (9754/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.058848 | Loss_in_diffu: 11.395437 | Loss_out_diffu: 13.032908 | Acc: 98.318977 (58897/59904)
(1638290294.5984564, 1638290393.6255379, 99.02708148956299)
Test epoch: 3| Acc: 98.99 (9899/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048357 | Loss_in_diffu: 11.464697 | Loss_out_diffu: 13.154598 | Acc: 98.619458 (59077/59904)
(1638290394.3470044, 1638290493.5135632, 99.1665587425232)
Test epoch: 4| Acc: 98.94 (9894/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.042789 | Loss_in_diffu: 11.540103 | Loss_out_diffu: 13.256082 | Acc: 98.798077 (59184/59904)
(1638290494.1199107, 1638290592.792796, 98.67288517951965)
Test epoch: 5| Acc: 98.67 (9867/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.036705 | Loss_in_diffu: 11.622364 | Loss_out_diffu: 13.353249 | Acc: 98.909923 (59251/59904)
(1638290593.3858435, 1638290692.2116053, 98.82576179504395)
Test epoch: 6| Acc: 98.68 (9868/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.033446 | Loss_in_diffu: 11.710251 | Loss_out_diffu: 13.472208 | Acc: 99.028446 (59322/59904)
(1638290692.9259818, 1638290792.4301622, 99.50418043136597)
Test epoch: 7| Acc: 98.48 (9848/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.028581 | Loss_in_diffu: 11.804642 | Loss_out_diffu: 13.581986 | Acc: 99.172009 (59408/59904)
(1638290793.0531058, 1638290891.6892958, 98.63618993759155)
Test epoch: 8| Acc: 99.14 (9914/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.027473 | Loss_in_diffu: 11.906105 | Loss_out_diffu: 13.701939 | Acc: 99.197049 (59423/59904)
(1638290892.3961327, 1638290991.9361343, 99.54000163078308)
Test epoch: 9| Acc: 99.04 (9904/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.022440 | Loss_in_diffu: 11.994079 | Loss_out_diffu: 13.814521 | Acc: 99.317241 (59495/59904)
(1638290992.5218341, 1638291091.9824975, 99.46066331863403)
Test epoch: 10| Acc: 98.94 (9894/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.009279 | Loss_in_diffu: 12.034724 | Loss_out_diffu: 13.883567 | Acc: 99.759615 (59760/59904)
(1638291092.692808, 1638291192.1414216, 99.44861364364624)
Test epoch: 11| Acc: 99.49 (9949/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006240 | Loss_in_diffu: 12.034647 | Loss_out_diffu: 13.893267 | Acc: 99.859776 (59820/59904)
(1638291192.854756, 1638291291.5084975, 98.6537413597107)
Test epoch: 12| Acc: 99.51 (9951/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005403 | Loss_in_diffu: 12.036639 | Loss_out_diffu: 13.904835 | Acc: 99.878138 (59831/59904)
(1638291292.1540325, 1638291390.9650931, 98.81106066703796)
Test epoch: 13| Acc: 99.42 (9942/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004600 | Loss_in_diffu: 12.038738 | Loss_out_diffu: 13.916260 | Acc: 99.899840 (59844/59904)
(1638291391.6715786, 1638291491.4522562, 99.78067755699158)
Test epoch: 14| Acc: 99.45 (9945/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004403 | Loss_in_diffu: 12.041488 | Loss_out_diffu: 13.925921 | Acc: 99.898170 (59843/59904)
(1638291492.1702514, 1638291590.8725448, 98.7022933959961)
Test epoch: 15| Acc: 99.51 (9951/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003506 | Loss_in_diffu: 12.043722 | Loss_out_diffu: 13.935080 | Acc: 99.926549 (59860/59904)
(1638291591.4720051, 1638291691.2873275, 99.8153223991394)
Test epoch: 16| Acc: 99.44 (9944/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003346 | Loss_in_diffu: 12.046203 | Loss_out_diffu: 13.947670 | Acc: 99.934896 (59865/59904)
(1638291692.0069873, 1638291791.316345, 99.30935764312744)
Test epoch: 17| Acc: 99.49 (9949/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003346 | Loss_in_diffu: 12.048601 | Loss_out_diffu: 13.957424 | Acc: 99.918202 (59855/59904)
(1638291791.9932466, 1638291890.7659926, 98.7727460861206)
Test epoch: 18| Acc: 99.52 (9952/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002679 | Loss_in_diffu: 12.051293 | Loss_out_diffu: 13.962528 | Acc: 99.946581 (59872/59904)
(1638291891.3707712, 1638291990.1837635, 98.81299233436584)
Test epoch: 19| Acc: 99.48 (9948/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002077 | Loss_in_diffu: 12.052793 | Loss_out_diffu: 13.974049 | Acc: 99.973291 (59888/59904)
(1638291990.8940618, 1638292090.8238409, 99.92977905273438)
Test epoch: 20| Acc: 99.41 (9941/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001617 | Loss_in_diffu: 12.053784 | Loss_out_diffu: 13.982077 | Acc: 99.981637 (59893/59904)
(1638292091.5306742, 1638292191.2839305, 99.75325632095337)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001522 | Loss_in_diffu: 12.053678 | Loss_out_diffu: 13.983125 | Acc: 99.983307 (59894/59904)
(1638292191.8850245, 1638292290.6649992, 98.77997469902039)
Test epoch: 22| Acc: 99.49 (9949/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001496 | Loss_in_diffu: 12.054264 | Loss_out_diffu: 13.984096 | Acc: 99.983307 (59894/59904)
(1638292291.3762941, 1638292390.1977386, 98.82144451141357)
Test epoch: 23| Acc: 99.48 (9948/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001449 | Loss_in_diffu: 12.053941 | Loss_out_diffu: 13.985289 | Acc: 99.983307 (59894/59904)
(1638292390.7969666, 1638292490.2246444, 99.42767786979675)
Test epoch: 24| Acc: 99.42 (9942/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001422 | Loss_in_diffu: 12.054397 | Loss_out_diffu: 13.986551 | Acc: 99.983307 (59894/59904)
(1638292490.9368207, 1638292589.7155707, 98.77874994277954)
Test epoch: 25| Acc: 99.46 (9946/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001383 | Loss_in_diffu: 12.054115 | Loss_out_diffu: 13.987196 | Acc: 99.983307 (59894/59904)
(1638292590.4368567, 1638292689.156796, 98.71993923187256)
Test epoch: 26| Acc: 99.47 (9947/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001333 | Loss_in_diffu: 12.054645 | Loss_out_diffu: 13.987999 | Acc: 99.984976 (59895/59904)
(1638292689.7424512, 1638292788.4427085, 98.70025730133057)
Test epoch: 27| Acc: 99.46 (9946/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001287 | Loss_in_diffu: 12.054610 | Loss_out_diffu: 13.989313 | Acc: 99.984976 (59895/59904)
(1638292789.0411754, 1638292888.3978004, 99.35662508010864)
Test epoch: 28| Acc: 99.46 (9946/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001236 | Loss_in_diffu: 12.054862 | Loss_out_diffu: 13.989910 | Acc: 99.986645 (59896/59904)
(1638292889.105299, 1638292987.8705568, 98.76525783538818)
Test epoch: 29| Acc: 99.48 (9948/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001192 | Loss_in_diffu: 12.055020 | Loss_out_diffu: 13.991527 | Acc: 99.988315 (59897/59904)
(1638292988.5773604, 1638293087.372556, 98.79519557952881)
Test epoch: 30| Acc: 99.47 (9947/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001136 | Loss_in_diffu: 12.054995 | Loss_out_diffu: 13.991724 | Acc: 99.988315 (59897/59904)
(1638293088.0931194, 1638293186.8773935, 98.78427410125732)
Test epoch: 31| Acc: 99.47 (9947/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001122 | Loss_in_diffu: 12.055323 | Loss_out_diffu: 13.992158 | Acc: 99.988315 (59897/59904)
(1638293187.5851345, 1638293287.3654218, 99.78028726577759)
Test epoch: 32| Acc: 99.46 (9946/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001117 | Loss_in_diffu: 12.055188 | Loss_out_diffu: 13.992155 | Acc: 99.988315 (59897/59904)
(1638293288.08546, 1638293388.068687, 99.98322701454163)
Test epoch: 33| Acc: 99.46 (9946/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001113 | Loss_in_diffu: 12.055107 | Loss_out_diffu: 13.992228 | Acc: 99.988315 (59897/59904)
(1638293388.6755056, 1638293487.9078503, 99.23234462738037)
Test epoch: 34| Acc: 99.46 (9946/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001111 | Loss_in_diffu: 12.055294 | Loss_out_diffu: 13.992445 | Acc: 99.988315 (59897/59904)
(1638293488.613875, 1638293587.2486715, 98.63479661941528)
Test epoch: 35| Acc: 99.46 (9946/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001108 | Loss_in_diffu: 12.055141 | Loss_out_diffu: 13.992601 | Acc: 99.988315 (59897/59904)
(1638293587.9162052, 1638293686.7091627, 98.79295754432678)
Test epoch: 36| Acc: 99.47 (9947/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001099 | Loss_in_diffu: 12.054790 | Loss_out_diffu: 13.992574 | Acc: 99.988315 (59897/59904)
(1638293687.295544, 1638293786.1530385, 98.85749459266663)
Test epoch: 37| Acc: 99.47 (9947/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001093 | Loss_in_diffu: 12.054942 | Loss_out_diffu: 13.993244 | Acc: 99.988315 (59897/59904)
(1638293786.7540593, 1638293886.3508928, 99.59683346748352)
Test epoch: 38| Acc: 99.44 (9944/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001086 | Loss_in_diffu: 12.055111 | Loss_out_diffu: 13.993042 | Acc: 99.988315 (59897/59904)
(1638293886.9418223, 1638293986.8032496, 99.8614273071289)
Test epoch: 39| Acc: 99.47 (9947/10000) 
