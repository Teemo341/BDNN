True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.675036 | Loss_in_diffu: 11.742412 | Loss_out_diffu: 12.168222 | Acc: 84.555288 (50652/59904)
(1638323170.4317415, 1638323269.9710083, 99.53926682472229)
Test epoch: 0| Acc: 96.75 (9675/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.115559 | Loss_in_diffu: 11.312823 | Loss_out_diffu: 12.675097 | Acc: 96.943443 (58073/59904)
(1638323270.5764139, 1638323369.139154, 98.56274008750916)
Test epoch: 1| Acc: 97.75 (9775/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.077108 | Loss_in_diffu: 11.348703 | Loss_out_diffu: 12.846154 | Acc: 97.871595 (58629/59904)
(1638323369.8600104, 1638323469.1909683, 99.33095788955688)
Test epoch: 2| Acc: 98.37 (9837/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.056804 | Loss_in_diffu: 11.399392 | Loss_out_diffu: 12.977103 | Acc: 98.444177 (58972/59904)
(1638323469.7868423, 1638323568.3124804, 98.52563810348511)
Test epoch: 3| Acc: 98.49 (9849/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048213 | Loss_in_diffu: 11.466435 | Loss_out_diffu: 13.077873 | Acc: 98.652845 (59097/59904)
(1638323569.0299053, 1638323667.7420857, 98.71218037605286)
Test epoch: 4| Acc: 98.89 (9889/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.041448 | Loss_in_diffu: 11.540179 | Loss_out_diffu: 13.156238 | Acc: 98.836472 (59207/59904)
(1638323668.508015, 1638323767.0922458, 98.58423089981079)
Test epoch: 5| Acc: 98.89 (9889/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.034986 | Loss_in_diffu: 11.616557 | Loss_out_diffu: 13.263326 | Acc: 99.016760 (59315/59904)
(1638323767.813725, 1638323867.7366364, 99.92291140556335)
Test epoch: 6| Acc: 99.01 (9901/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.032520 | Loss_in_diffu: 11.704157 | Loss_out_diffu: 13.376342 | Acc: 99.046808 (59333/59904)
(1638323868.4340858, 1638323968.043052, 99.60896611213684)
Test epoch: 7| Acc: 98.98 (9898/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.029173 | Loss_in_diffu: 11.800830 | Loss_out_diffu: 13.511025 | Acc: 99.155315 (59398/59904)
(1638323968.7560449, 1638324067.5218356, 98.76579070091248)
Test epoch: 8| Acc: 98.38 (9838/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.027992 | Loss_in_diffu: 11.901031 | Loss_out_diffu: 13.605979 | Acc: 99.188702 (59418/59904)
(1638324068.115918, 1638324166.897133, 98.78121519088745)
Test epoch: 9| Acc: 99.2 (9920/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.024624 | Loss_in_diffu: 12.001593 | Loss_out_diffu: 13.703940 | Acc: 99.268830 (59466/59904)
(1638324167.4879668, 1638324266.2689984, 98.78103160858154)
Test epoch: 10| Acc: 99.28 (9928/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.008394 | Loss_in_diffu: 12.045081 | Loss_out_diffu: 13.788778 | Acc: 99.767962 (59765/59904)
(1638324266.9870968, 1638324365.80387, 98.81677317619324)
Test epoch: 11| Acc: 99.57 (9957/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006232 | Loss_in_diffu: 12.046183 | Loss_out_diffu: 13.798236 | Acc: 99.854768 (59817/59904)
(1638324366.5231419, 1638324465.3929605, 98.86981868743896)
Test epoch: 12| Acc: 99.53 (9953/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005481 | Loss_in_diffu: 12.048873 | Loss_out_diffu: 13.812217 | Acc: 99.878138 (59831/59904)
(1638324465.9903193, 1638324565.162789, 99.17246985435486)
Test epoch: 13| Acc: 99.5 (9950/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004862 | Loss_in_diffu: 12.051850 | Loss_out_diffu: 13.824742 | Acc: 99.884816 (59835/59904)
(1638324565.7471333, 1638324664.6143057, 98.86717247962952)
Test epoch: 14| Acc: 99.54 (9954/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004414 | Loss_in_diffu: 12.054997 | Loss_out_diffu: 13.839053 | Acc: 99.899840 (59844/59904)
(1638324665.212722, 1638324764.000415, 98.78769302368164)
Test epoch: 15| Acc: 99.57 (9957/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003701 | Loss_in_diffu: 12.057904 | Loss_out_diffu: 13.852095 | Acc: 99.916533 (59854/59904)
(1638324764.6076279, 1638324864.5865073, 99.97887945175171)
Test epoch: 16| Acc: 99.59 (9959/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.003581 | Loss_in_diffu: 12.061101 | Loss_out_diffu: 13.867824 | Acc: 99.928218 (59861/59904)
(1638324865.2998924, 1638324964.0690491, 98.76915669441223)
Test epoch: 17| Acc: 99.42 (9942/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003116 | Loss_in_diffu: 12.063787 | Loss_out_diffu: 13.880558 | Acc: 99.926549 (59860/59904)
(1638324964.6630852, 1638325063.4616284, 98.79854321479797)
Test epoch: 18| Acc: 99.42 (9942/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.002800 | Loss_in_diffu: 12.067028 | Loss_out_diffu: 13.890222 | Acc: 99.948251 (59873/59904)
(1638325064.0616112, 1638325163.0348485, 98.97323727607727)
Test epoch: 19| Acc: 99.59 (9959/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.002337 | Loss_in_diffu: 12.069244 | Loss_out_diffu: 13.903356 | Acc: 99.963275 (59882/59904)
(1638325163.7558618, 1638325263.5214481, 99.76558637619019)
Test epoch: 20| Acc: 99.54 (9954/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.001756 | Loss_in_diffu: 12.070525 | Loss_out_diffu: 13.906657 | Acc: 99.971621 (59887/59904)
(1638325264.1136978, 1638325363.6716056, 99.55790781974792)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.001558 | Loss_in_diffu: 12.070430 | Loss_out_diffu: 13.909274 | Acc: 99.976629 (59890/59904)
(1638325364.2813232, 1638325463.0737264, 98.79240322113037)
Test epoch: 22| Acc: 99.55 (9955/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001524 | Loss_in_diffu: 12.071078 | Loss_out_diffu: 13.911194 | Acc: 99.978299 (59891/59904)
(1638325463.7925787, 1638325562.6110654, 98.81848669052124)
Test epoch: 23| Acc: 99.56 (9956/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001453 | Loss_in_diffu: 12.070804 | Loss_out_diffu: 13.913573 | Acc: 99.979968 (59892/59904)
(1638325563.2111158, 1638325662.5999312, 99.38881540298462)
Test epoch: 24| Acc: 99.54 (9954/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001426 | Loss_in_diffu: 12.071326 | Loss_out_diffu: 13.915598 | Acc: 99.978299 (59891/59904)
(1638325663.3123996, 1638325762.2944849, 98.98208522796631)
Test epoch: 25| Acc: 99.53 (9953/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001381 | Loss_in_diffu: 12.071102 | Loss_out_diffu: 13.917548 | Acc: 99.978299 (59891/59904)
(1638325763.0131207, 1638325861.8224664, 98.80934572219849)
Test epoch: 26| Acc: 99.53 (9953/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001340 | Loss_in_diffu: 12.071697 | Loss_out_diffu: 13.919031 | Acc: 99.978299 (59891/59904)
(1638325862.5466135, 1638325962.1106353, 99.5640218257904)
Test epoch: 27| Acc: 99.56 (9956/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001299 | Loss_in_diffu: 12.071729 | Loss_out_diffu: 13.921947 | Acc: 99.981637 (59893/59904)
(1638325962.7066007, 1638326062.1144848, 99.40788412094116)
Test epoch: 28| Acc: 99.55 (9955/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001248 | Loss_in_diffu: 12.072038 | Loss_out_diffu: 13.923322 | Acc: 99.981637 (59893/59904)
(1638326062.7132776, 1638326162.194716, 99.4814383983612)
Test epoch: 29| Acc: 99.55 (9955/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001200 | Loss_in_diffu: 12.072245 | Loss_out_diffu: 13.925945 | Acc: 99.983307 (59894/59904)
(1638326162.9034967, 1638326261.8859286, 98.98243188858032)
Test epoch: 30| Acc: 99.54 (9954/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001118 | Loss_in_diffu: 12.072240 | Loss_out_diffu: 13.927105 | Acc: 99.986645 (59896/59904)
(1638326262.6025736, 1638326361.2296124, 98.6270387172699)
Test epoch: 31| Acc: 99.55 (9955/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001112 | Loss_in_diffu: 12.072571 | Loss_out_diffu: 13.927556 | Acc: 99.988315 (59897/59904)
(1638326361.837125, 1638326460.6475127, 98.81038761138916)
Test epoch: 32| Acc: 99.51 (9951/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001100 | Loss_in_diffu: 12.072445 | Loss_out_diffu: 13.927577 | Acc: 99.988315 (59897/59904)
(1638326461.3670394, 1638326560.4148912, 99.04785180091858)
Test epoch: 33| Acc: 99.52 (9952/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001100 | Loss_in_diffu: 12.072378 | Loss_out_diffu: 13.928043 | Acc: 99.989984 (59898/59904)
(1638326561.0119784, 1638326659.8096018, 98.7976233959198)
Test epoch: 34| Acc: 99.54 (9954/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001096 | Loss_in_diffu: 12.072574 | Loss_out_diffu: 13.928428 | Acc: 99.989984 (59898/59904)
(1638326660.530266, 1638326759.518178, 98.98791193962097)
Test epoch: 35| Acc: 99.53 (9953/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001091 | Loss_in_diffu: 12.072415 | Loss_out_diffu: 13.928510 | Acc: 99.989984 (59898/59904)
(1638326760.1121402, 1638326858.936806, 98.82466578483582)
Test epoch: 36| Acc: 99.53 (9953/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001088 | Loss_in_diffu: 12.072066 | Loss_out_diffu: 13.928823 | Acc: 99.989984 (59898/59904)
(1638326859.578408, 1638326958.3713057, 98.79289770126343)
Test epoch: 37| Acc: 99.53 (9953/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001082 | Loss_in_diffu: 12.072237 | Loss_out_diffu: 13.929456 | Acc: 99.989984 (59898/59904)
(1638326959.0868413, 1638327057.8917413, 98.80489993095398)
Test epoch: 38| Acc: 99.52 (9952/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001081 | Loss_in_diffu: 12.072412 | Loss_out_diffu: 13.929601 | Acc: 99.988315 (59897/59904)
(1638327058.6106367, 1638327157.4729276, 98.86229085922241)
Test epoch: 39| Acc: 99.55 (9955/10000) 
