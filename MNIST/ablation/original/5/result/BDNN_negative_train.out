True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.670126 | Loss_in_diffu: 11.729304 | Loss_out_diffu: 12.142499 | Acc: 84.613715 (50687/59904)
(1642959421.8158264, 1642959520.5030162, 98.68718981742859)
Test epoch: 0| Acc: 96.88 (9688/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.117725 | Loss_in_diffu: 11.309265 | Loss_out_diffu: 12.589503 | Acc: 96.898371 (58046/59904)
(1642959521.2058558, 1642959620.3556702, 99.14981436729431)
Test epoch: 1| Acc: 97.75 (9775/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.080813 | Loss_in_diffu: 11.346982 | Loss_out_diffu: 12.719487 | Acc: 97.771434 (58569/59904)
(1642959621.0194705, 1642959719.7552972, 98.73582673072815)
Test epoch: 2| Acc: 98.76 (9876/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.058537 | Loss_in_diffu: 11.395575 | Loss_out_diffu: 12.847516 | Acc: 98.355702 (58919/59904)
(1642959720.4574416, 1642959819.1638684, 98.70642685890198)
Test epoch: 3| Acc: 98.58 (9858/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.047045 | Loss_in_diffu: 11.461781 | Loss_out_diffu: 12.982242 | Acc: 98.646167 (59093/59904)
(1642959819.8610134, 1642959918.4344928, 98.5734794139862)
Test epoch: 4| Acc: 98.69 (9869/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.042676 | Loss_in_diffu: 11.538613 | Loss_out_diffu: 13.065509 | Acc: 98.773037 (59169/59904)
(1642959919.0138686, 1642960018.0449858, 99.03111720085144)
Test epoch: 5| Acc: 98.72 (9872/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.035825 | Loss_in_diffu: 11.618582 | Loss_out_diffu: 13.184970 | Acc: 98.944979 (59272/59904)
(1642960018.7495415, 1642960117.8429794, 99.09343791007996)
Test epoch: 6| Acc: 99.23 (9923/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.033141 | Loss_in_diffu: 11.705425 | Loss_out_diffu: 13.284649 | Acc: 98.981704 (59294/59904)
(1642960118.5494087, 1642960217.553552, 99.00414323806763)
Test epoch: 7| Acc: 98.84 (9884/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.029918 | Loss_in_diffu: 11.811558 | Loss_out_diffu: 13.361666 | Acc: 99.118590 (59376/59904)
(1642960218.1205375, 1642960316.8399925, 98.7194550037384)
Test epoch: 8| Acc: 99.17 (9917/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.025533 | Loss_in_diffu: 11.909374 | Loss_out_diffu: 13.472569 | Acc: 99.267161 (59465/59904)
(1642960317.430377, 1642960415.6273375, 98.19696044921875)
Test epoch: 9| Acc: 98.91 (9891/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.022839 | Loss_in_diffu: 11.998188 | Loss_out_diffu: 13.591896 | Acc: 99.338942 (59508/59904)
(1642960416.195734, 1642960514.3570406, 98.16130661964417)
Test epoch: 10| Acc: 99.23 (9923/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.008472 | Loss_in_diffu: 12.036654 | Loss_out_diffu: 13.676405 | Acc: 99.771301 (59767/59904)
(1642960515.0594368, 1642960614.0929384, 99.03350162506104)
Test epoch: 11| Acc: 99.55 (9955/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.006030 | Loss_in_diffu: 12.036858 | Loss_out_diffu: 13.681570 | Acc: 99.843082 (59810/59904)
(1642960614.7969608, 1642960713.935648, 99.13868713378906)
Test epoch: 12| Acc: 99.5 (9950/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.005447 | Loss_in_diffu: 12.038796 | Loss_out_diffu: 13.693115 | Acc: 99.873130 (59828/59904)
(1642960714.64274, 1642960814.250568, 99.60782790184021)
Test epoch: 13| Acc: 99.51 (9951/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.004737 | Loss_in_diffu: 12.040866 | Loss_out_diffu: 13.723196 | Acc: 99.903178 (59846/59904)
(1642960814.9573958, 1642960914.3888943, 99.43149852752686)
Test epoch: 14| Acc: 99.55 (9955/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.004455 | Loss_in_diffu: 12.043502 | Loss_out_diffu: 13.736438 | Acc: 99.899840 (59844/59904)
(1642960915.0957956, 1642961013.5181015, 98.42230582237244)
Test epoch: 15| Acc: 99.53 (9953/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.003815 | Loss_in_diffu: 12.045926 | Loss_out_diffu: 13.746319 | Acc: 99.926549 (59860/59904)
(1642961014.2219548, 1642961113.3911135, 99.1691586971283)
Test epoch: 16| Acc: 99.52 (9952/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004081 | Loss_in_diffu: 12.049669 | Loss_out_diffu: 13.789684 | Acc: 99.919872 (59856/59904)
(1642961114.087124, 1642961212.752832, 98.66570782661438)
Test epoch: 17| Acc: 99.4 (9940/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.003967 | Loss_in_diffu: 12.053543 | Loss_out_diffu: 13.827380 | Acc: 99.909856 (59850/59904)
(1642961213.3342113, 1642961312.3144171, 98.98020577430725)
Test epoch: 18| Acc: 99.38 (9938/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.003679 | Loss_in_diffu: 12.057284 | Loss_out_diffu: 13.860042 | Acc: 99.926549 (59860/59904)
(1642961313.0179274, 1642961411.6790612, 98.66113376617432)
Test epoch: 19| Acc: 99.39 (9939/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003369 | Loss_in_diffu: 12.060836 | Loss_out_diffu: 13.929777 | Acc: 99.928218 (59861/59904)
(1642961412.3806841, 1642961511.0224388, 98.64175462722778)
Test epoch: 20| Acc: 99.5 (9950/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.002182 | Loss_in_diffu: 12.062388 | Loss_out_diffu: 13.944211 | Acc: 99.964944 (59883/59904)
(1642961511.621734, 1642961610.5541625, 98.93242859840393)
Test epoch: 21| Acc: 99.52 (9952/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.002026 | Loss_in_diffu: 12.062309 | Loss_out_diffu: 13.946142 | Acc: 99.971621 (59887/59904)
(1642961611.2501605, 1642961709.6340177, 98.38385725021362)
Test epoch: 22| Acc: 99.49 (9949/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.001961 | Loss_in_diffu: 12.062912 | Loss_out_diffu: 13.948574 | Acc: 99.971621 (59887/59904)
(1642961710.3356695, 1642961809.8638277, 99.52815818786621)
Test epoch: 23| Acc: 99.5 (9950/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.001862 | Loss_in_diffu: 12.062621 | Loss_out_diffu: 13.951292 | Acc: 99.981637 (59893/59904)
(1642961810.5647504, 1642961909.8353739, 99.27062344551086)
Test epoch: 24| Acc: 99.51 (9951/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.001826 | Loss_in_diffu: 12.063097 | Loss_out_diffu: 13.953762 | Acc: 99.978299 (59891/59904)
(1642961910.5385115, 1642962009.7903788, 99.25186729431152)
Test epoch: 25| Acc: 99.49 (9949/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.001764 | Loss_in_diffu: 12.062845 | Loss_out_diffu: 13.955540 | Acc: 99.974960 (59889/59904)
(1642962010.4955852, 1642962109.621967, 99.12638187408447)
Test epoch: 26| Acc: 99.45 (9945/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.001704 | Loss_in_diffu: 12.063420 | Loss_out_diffu: 13.957394 | Acc: 99.981637 (59893/59904)
(1642962110.3228288, 1642962208.982006, 98.65917730331421)
Test epoch: 27| Acc: 99.5 (9950/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.001674 | Loss_in_diffu: 12.063421 | Loss_out_diffu: 13.959858 | Acc: 99.981637 (59893/59904)
(1642962209.5743167, 1642962307.9463398, 98.37202310562134)
Test epoch: 28| Acc: 99.48 (9948/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.001596 | Loss_in_diffu: 12.063695 | Loss_out_diffu: 13.961186 | Acc: 99.983307 (59894/59904)
(1642962308.636899, 1642962407.1766706, 98.53977155685425)
Test epoch: 29| Acc: 99.51 (9951/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.001557 | Loss_in_diffu: 12.063895 | Loss_out_diffu: 13.963329 | Acc: 99.983307 (59894/59904)
(1642962407.7557676, 1642962506.4479, 98.69213247299194)
Test epoch: 30| Acc: 99.5 (9950/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.001456 | Loss_in_diffu: 12.063863 | Loss_out_diffu: 13.964410 | Acc: 99.984976 (59895/59904)
(1642962507.018819, 1642962605.5438492, 98.5250301361084)
Test epoch: 31| Acc: 99.51 (9951/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.001449 | Loss_in_diffu: 12.064195 | Loss_out_diffu: 13.964685 | Acc: 99.984976 (59895/59904)
(1642962606.2568524, 1642962704.597582, 98.34072971343994)
Test epoch: 32| Acc: 99.51 (9951/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.001452 | Loss_in_diffu: 12.064078 | Loss_out_diffu: 13.964801 | Acc: 99.986645 (59896/59904)
(1642962705.3016713, 1642962804.5582767, 99.25660538673401)
Test epoch: 33| Acc: 99.5 (9950/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.001449 | Loss_in_diffu: 12.063998 | Loss_out_diffu: 13.964991 | Acc: 99.984976 (59895/59904)
(1642962805.2685006, 1642962904.4772582, 99.20875763893127)
Test epoch: 34| Acc: 99.51 (9951/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.001440 | Loss_in_diffu: 12.064196 | Loss_out_diffu: 13.965253 | Acc: 99.986645 (59896/59904)
(1642962905.1741714, 1642963003.56469, 98.39051866531372)
Test epoch: 35| Acc: 99.51 (9951/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.001438 | Loss_in_diffu: 12.064044 | Loss_out_diffu: 13.965094 | Acc: 99.984976 (59895/59904)
(1642963004.252599, 1642963102.6757689, 98.4231698513031)
Test epoch: 36| Acc: 99.51 (9951/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.001429 | Loss_in_diffu: 12.063692 | Loss_out_diffu: 13.965253 | Acc: 99.986645 (59896/59904)
(1642963103.3821263, 1642963201.8919892, 98.50986289978027)
Test epoch: 37| Acc: 99.51 (9951/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.001422 | Loss_in_diffu: 12.063849 | Loss_out_diffu: 13.965914 | Acc: 99.986645 (59896/59904)
(1642963202.594733, 1642963301.0875483, 98.49281525611877)
Test epoch: 38| Acc: 99.51 (9951/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.001416 | Loss_in_diffu: 12.064026 | Loss_out_diffu: 13.965878 | Acc: 99.986645 (59896/59904)
(1642963301.789215, 1642963400.3192766, 98.53006148338318)
Test epoch: 39| Acc: 99.5 (9950/10000) 
