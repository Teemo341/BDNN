True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 30.350718 | Loss_out: 0.340018 | Acc: 9.884148 (5921/59904)
(1672485823.9888194, 1672485880.919036, 56.930216550827026)
Test epoch: 0| Acc: 96.1 (9610/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 28.963730 | Loss_out: 0.325362 | Acc: 10.049412 (6020/59904)
(1672485881.4123816, 1672485937.3982441, 55.985862493515015)
Test epoch: 1| Acc: 98.79 (9879/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 28.682553 | Loss_out: 0.325271 | Acc: 10.049412 (6020/59904)
(1672485937.872158, 1672485993.823326, 55.951168060302734)
Test epoch: 2| Acc: 98.45 (9845/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 28.552118 | Loss_out: 0.325263 | Acc: 10.079460 (6038/59904)
(1672485994.308706, 1672486050.324331, 56.015625)
Test epoch: 3| Acc: 98.09 (9809/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 28.486299 | Loss_out: 0.325266 | Acc: 10.206330 (6114/59904)
(1672486050.8188686, 1672486107.0970986, 56.27822995185852)
Test epoch: 4| Acc: 98.29 (9829/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 28.446396 | Loss_out: 0.325249 | Acc: 10.062767 (6028/59904)
(1672486107.5774395, 1672486163.8299444, 56.25250482559204)
Test epoch: 5| Acc: 98.59 (9859/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 28.421048 | Loss_out: 0.325235 | Acc: 9.817374 (5881/59904)
(1672486164.3185065, 1672486220.1077487, 55.78924226760864)
Test epoch: 6| Acc: 96.75 (9675/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 28.408622 | Loss_out: 0.325257 | Acc: 10.189637 (6104/59904)
(1672486220.5972066, 1672486276.3489163, 55.75170969963074)
Test epoch: 7| Acc: 99.06 (9906/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 28.393017 | Loss_out: 0.325245 | Acc: 9.812366 (5878/59904)
(1672486276.8394735, 1672486333.2278695, 56.38839602470398)
Test epoch: 8| Acc: 98.5 (9850/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 28.384511 | Loss_out: 0.325258 | Acc: 9.924212 (5945/59904)
(1672486333.718052, 1672486389.729438, 56.01138615608215)
Test epoch: 9| Acc: 98.91 (9891/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 28.373806 | Loss_out: 0.325243 | Acc: 9.987647 (5983/59904)
(1672486390.205111, 1672486446.1738803, 55.96876931190491)
Test epoch: 10| Acc: 98.95 (9895/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 28.341976 | Loss_out: 0.325100 | Acc: 9.825721 (5886/59904)
(1672486446.6628225, 1672486502.3870912, 55.724268674850464)
Test epoch: 11| Acc: 99.51 (9951/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 28.330058 | Loss_out: 0.325096 | Acc: 10.094485 (6047/59904)
(1672486502.868674, 1672486558.7707686, 55.90209460258484)
Test epoch: 12| Acc: 99.37 (9937/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 28.322337 | Loss_out: 0.325095 | Acc: 10.017695 (6001/59904)
(1672486559.258209, 1672486615.354863, 56.09665393829346)
Test epoch: 13| Acc: 99.53 (9953/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 28.316021 | Loss_out: 0.325094 | Acc: 10.139557 (6074/59904)
(1672486615.8434744, 1672486671.5292153, 55.68574094772339)
Test epoch: 14| Acc: 99.44 (9944/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 28.310301 | Loss_out: 0.325093 | Acc: 10.319845 (6182/59904)
(1672486672.0106332, 1672486728.0520995, 56.0414662361145)
Test epoch: 15| Acc: 99.09 (9909/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 28.308964 | Loss_out: 0.325096 | Acc: 10.086138 (6042/59904)
(1672486728.5300128, 1672486784.4692674, 55.93925452232361)
Test epoch: 16| Acc: 99.34 (9934/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 28.305444 | Loss_out: 0.325094 | Acc: 10.239717 (6134/59904)
(1672486784.9531288, 1672486841.2073574, 56.254228591918945)
Test epoch: 17| Acc: 99.52 (9952/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 28.301785 | Loss_out: 0.325094 | Acc: 10.087807 (6043/59904)
(1672486841.697972, 1672486897.447358, 55.749385833740234)
Test epoch: 18| Acc: 99.34 (9934/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 28.300277 | Loss_out: 0.325094 | Acc: 10.284789 (6161/59904)
(1672486897.9315376, 1672486953.6188009, 55.68726325035095)
Test epoch: 19| Acc: 99.33 (9933/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 28.298149 | Loss_out: 0.325094 | Acc: 9.960938 (5967/59904)
(1672486954.1020696, 1672487009.6056824, 55.503612756729126)
Test epoch: 20| Acc: 99.37 (9937/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 28.295521 | Loss_out: 0.325091 | Acc: 10.039396 (6014/59904)
(1672487010.089417, 1672487065.621579, 55.53216195106506)
Test epoch: 21| Acc: 99.5 (9950/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 28.294422 | Loss_out: 0.325091 | Acc: 9.967615 (5971/59904)
(1672487066.1048343, 1672487121.5919478, 55.48711347579956)
Test epoch: 22| Acc: 99.5 (9950/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 28.293609 | Loss_out: 0.325091 | Acc: 10.166266 (6090/59904)
(1672487122.0741234, 1672487177.751853, 55.67772960662842)
Test epoch: 23| Acc: 99.53 (9953/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 28.293452 | Loss_out: 0.325091 | Acc: 10.144565 (6077/59904)
(1672487178.2422597, 1672487234.427065, 56.184805154800415)
Test epoch: 24| Acc: 99.43 (9943/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 28.292501 | Loss_out: 0.325091 | Acc: 10.111178 (6057/59904)
(1672487234.9075532, 1672487291.039197, 56.131643772125244)
Test epoch: 25| Acc: 99.47 (9947/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 28.292747 | Loss_out: 0.325091 | Acc: 10.002671 (5992/59904)
(1672487291.5253649, 1672487347.4449375, 55.919572591781616)
Test epoch: 26| Acc: 99.49 (9949/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 28.291694 | Loss_out: 0.325090 | Acc: 10.041066 (6015/59904)
(1672487347.9295654, 1672487403.4752712, 55.545705795288086)
Test epoch: 27| Acc: 99.48 (9948/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 28.291092 | Loss_out: 0.325090 | Acc: 10.034388 (6011/59904)
(1672487403.958444, 1672487459.5380075, 55.57956337928772)
Test epoch: 28| Acc: 99.47 (9947/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 28.290738 | Loss_out: 0.325090 | Acc: 10.079460 (6038/59904)
(1672487460.0128682, 1672487516.2616043, 56.24873614311218)
Test epoch: 29| Acc: 99.52 (9952/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 28.289561 | Loss_out: 0.325090 | Acc: 9.967615 (5971/59904)
(1672487516.750405, 1672487572.4052782, 55.65487313270569)
Test epoch: 30| Acc: 99.53 (9953/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 28.289030 | Loss_out: 0.325090 | Acc: 9.922543 (5944/59904)
(1672487572.893766, 1672487628.898384, 56.0046181678772)
Test epoch: 31| Acc: 99.49 (9949/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 28.289289 | Loss_out: 0.325090 | Acc: 10.089476 (6044/59904)
(1672487629.3874443, 1672487685.6553001, 56.26785588264465)
Test epoch: 32| Acc: 99.45 (9945/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 28.289032 | Loss_out: 0.325090 | Acc: 10.157919 (6085/59904)
(1672487686.14542, 1672487742.070556, 55.92513585090637)
Test epoch: 33| Acc: 99.48 (9948/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 28.289050 | Loss_out: 0.325090 | Acc: 9.984308 (5981/59904)
(1672487742.5566297, 1672487798.4770648, 55.920435190200806)
Test epoch: 34| Acc: 99.49 (9949/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 28.289589 | Loss_out: 0.325090 | Acc: 10.001002 (5991/59904)
(1672487798.9520519, 1672487854.5103254, 55.55827355384827)
Test epoch: 35| Acc: 99.47 (9947/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 28.288584 | Loss_out: 0.325090 | Acc: 10.086138 (6042/59904)
(1672487854.9831982, 1672487910.8839543, 55.90075612068176)
Test epoch: 36| Acc: 99.5 (9950/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 28.288796 | Loss_out: 0.325090 | Acc: 10.124533 (6065/59904)
(1672487911.3687022, 1672487966.936528, 55.56782579421997)
Test epoch: 37| Acc: 99.5 (9950/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 28.288319 | Loss_out: 0.325090 | Acc: 9.969284 (5972/59904)
(1672487967.420484, 1672488023.129631, 55.70914697647095)
Test epoch: 38| Acc: 99.5 (9950/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 28.288207 | Loss_out: 0.325090 | Acc: 10.109509 (6056/59904)
(1672488023.6044495, 1672488079.5364864, 55.93203687667847)
Test epoch: 39| Acc: 99.52 (9952/10000) 
