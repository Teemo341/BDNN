True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.530936 | Loss_out: 0.337171 | Acc: 82.463608 (49399/59904)
(1672542550.0211222, 1672542563.7679462, 13.746824026107788)
Test epoch: 0| Acc: 97.75 (9775/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.068895 | Loss_out: 0.326582 | Acc: 98.060230 (58742/59904)
(1672542564.2561033, 1672542577.5595193, 13.303416013717651)
Test epoch: 1| Acc: 98.6 (9860/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.057292 | Loss_out: 0.326312 | Acc: 98.427484 (58962/59904)
(1672542578.0526304, 1672542591.3902228, 13.337592363357544)
Test epoch: 2| Acc: 98.79 (9879/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.052742 | Loss_out: 0.326070 | Acc: 98.554354 (59038/59904)
(1672542591.8776371, 1672542605.2692535, 13.391616344451904)
Test epoch: 3| Acc: 98.83 (9883/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.048036 | Loss_out: 0.325852 | Acc: 98.712941 (59133/59904)
(1672542605.7556105, 1672542619.1503315, 13.394721031188965)
Test epoch: 4| Acc: 98.62 (9862/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.051645 | Loss_out: 0.326064 | Acc: 98.622796 (59079/59904)
(1672542619.6440346, 1672542633.0377734, 13.393738746643066)
Test epoch: 5| Acc: 98.59 (9859/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.051069 | Loss_out: 0.325894 | Acc: 98.604434 (59068/59904)
(1672542633.518194, 1672542646.92075, 13.4025559425354)
Test epoch: 6| Acc: 98.78 (9878/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.051257 | Loss_out: 0.331100 | Acc: 98.684562 (59116/59904)
(1672542647.4016201, 1672542660.8521278, 13.450507640838623)
Test epoch: 7| Acc: 98.12 (9812/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.052172 | Loss_out: 0.327435 | Acc: 98.596087 (59063/59904)
(1672542661.3368156, 1672542674.7954154, 13.45859980583191)
Test epoch: 8| Acc: 98.84 (9884/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.048150 | Loss_out: 0.326279 | Acc: 98.692909 (59121/59904)
(1672542675.2854116, 1672542688.7284925, 13.44308090209961)
Test epoch: 9| Acc: 98.96 (9896/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.049047 | Loss_out: 0.326121 | Acc: 98.694578 (59122/59904)
(1672542689.2081816, 1672542702.642132, 13.433950424194336)
Test epoch: 10| Acc: 98.76 (9876/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.019130 | Loss_out: 0.325155 | Acc: 99.555956 (59638/59904)
(1672542703.1356356, 1672542716.5641394, 13.42850375175476)
Test epoch: 11| Acc: 99.5 (9950/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.012482 | Loss_out: 0.325129 | Acc: 99.719551 (59736/59904)
(1672542717.053158, 1672542730.497622, 13.444463968276978)
Test epoch: 12| Acc: 99.47 (9947/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.009493 | Loss_out: 0.325120 | Acc: 99.808026 (59789/59904)
(1672542730.9831724, 1672542744.4157047, 13.43253231048584)
Test epoch: 13| Acc: 99.48 (9948/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.007617 | Loss_out: 0.325114 | Acc: 99.859776 (59820/59904)
(1672542744.890693, 1672542758.325235, 13.434541940689087)
Test epoch: 14| Acc: 99.53 (9953/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006501 | Loss_out: 0.325109 | Acc: 99.879808 (59832/59904)
(1672542758.8164523, 1672542772.2660725, 13.449620246887207)
Test epoch: 15| Acc: 99.54 (9954/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005354 | Loss_out: 0.325105 | Acc: 99.929888 (59862/59904)
(1672542772.7549517, 1672542786.196416, 13.441464185714722)
Test epoch: 16| Acc: 99.51 (9951/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004678 | Loss_out: 0.325102 | Acc: 99.939904 (59868/59904)
(1672542786.6798224, 1672542800.1208005, 13.440978050231934)
Test epoch: 17| Acc: 99.48 (9948/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004453 | Loss_out: 0.325101 | Acc: 99.946581 (59872/59904)
(1672542800.6106439, 1672542814.0528464, 13.4422025680542)
Test epoch: 18| Acc: 99.49 (9949/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004410 | Loss_out: 0.325102 | Acc: 99.939904 (59868/59904)
(1672542814.5400646, 1672542827.9838183, 13.443753719329834)
Test epoch: 19| Acc: 99.56 (9956/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.003725 | Loss_out: 0.325098 | Acc: 99.966613 (59884/59904)
(1672542828.4741154, 1672542841.9184084, 13.444293022155762)
Test epoch: 20| Acc: 99.55 (9955/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.003301 | Loss_out: 0.325096 | Acc: 99.974960 (59889/59904)
(1672542842.4098396, 1672542855.8556657, 13.445826053619385)
Test epoch: 21| Acc: 99.57 (9957/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.003181 | Loss_out: 0.325096 | Acc: 99.983307 (59894/59904)
(1672542856.3338907, 1672542869.7936468, 13.459756135940552)
Test epoch: 22| Acc: 99.55 (9955/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.003128 | Loss_out: 0.325096 | Acc: 99.983307 (59894/59904)
(1672542870.2763927, 1672542883.713003, 13.436610221862793)
Test epoch: 23| Acc: 99.55 (9955/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.003094 | Loss_out: 0.325096 | Acc: 99.983307 (59894/59904)
(1672542884.1998796, 1672542897.6379573, 13.438077688217163)
Test epoch: 24| Acc: 99.55 (9955/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.003066 | Loss_out: 0.325096 | Acc: 99.983307 (59894/59904)
(1672542898.131303, 1672542911.5686367, 13.437333583831787)
Test epoch: 25| Acc: 99.55 (9955/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.003040 | Loss_out: 0.325096 | Acc: 99.986645 (59896/59904)
(1672542912.0596066, 1672542925.4869907, 13.4273841381073)
Test epoch: 26| Acc: 99.55 (9955/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.003022 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542925.9763823, 1672542939.4045267, 13.428144454956055)
Test epoch: 27| Acc: 99.55 (9955/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.003006 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542939.8826027, 1672542953.3286574, 13.446054697036743)
Test epoch: 28| Acc: 99.57 (9957/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.002990 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542953.8209023, 1672542967.2573228, 13.436420440673828)
Test epoch: 29| Acc: 99.57 (9957/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.002978 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542967.7637873, 1672542981.2078056, 13.444018363952637)
Test epoch: 30| Acc: 99.58 (9958/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.002961 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542981.7051425, 1672542995.141999, 13.436856508255005)
Test epoch: 31| Acc: 99.58 (9958/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.002959 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672542995.6166584, 1672543009.0905383, 13.47387981414795)
Test epoch: 32| Acc: 99.58 (9958/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.002959 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543009.5707831, 1672543023.0252523, 13.454469203948975)
Test epoch: 33| Acc: 99.58 (9958/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.002958 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543023.5141919, 1672543037.013237, 13.499045133590698)
Test epoch: 34| Acc: 99.58 (9958/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.002957 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543037.5023606, 1672543051.001266, 13.498905420303345)
Test epoch: 35| Acc: 99.58 (9958/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.002955 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543051.490155, 1672543064.9884026, 13.498247623443604)
Test epoch: 36| Acc: 99.58 (9958/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.002955 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543065.4674792, 1672543078.9804575, 13.512978315353394)
Test epoch: 37| Acc: 99.58 (9958/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.002953 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543079.456954, 1672543092.9549646, 13.498010635375977)
Test epoch: 38| Acc: 99.58 (9958/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.002952 | Loss_out: 0.325095 | Acc: 99.986645 (59896/59904)
(1672543093.4446445, 1672543106.940732, 13.496087551116943)
Test epoch: 39| Acc: 99.58 (9958/10000) 
