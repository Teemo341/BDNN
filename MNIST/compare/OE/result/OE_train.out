True
load data:  mnist
Building MNIST data loader with 1 workers
==> Building model..

Epoch: 0
Train epoch:0 	Loss_in: 0.525891 | Loss_out: 0.337068 | Acc: 10.186298 (6102/59904)
(1672485262.8759325, 1672485276.719626, 13.843693494796753)
Test epoch: 0| Acc: 97.98 (9798/10000) 

Epoch: 1
Train epoch:1 	Loss_in: 0.067543 | Loss_out: 0.326312 | Acc: 10.006010 (5994/59904)
(1672485277.2016652, 1672485290.6107368, 13.409071683883667)
Test epoch: 1| Acc: 98.14 (9814/10000) 

Epoch: 2
Train epoch:2 	Loss_in: 0.056642 | Loss_out: 0.326178 | Acc: 10.211338 (6117/59904)
(1672485291.0833378, 1672485304.5190794, 13.435741662979126)
Test epoch: 2| Acc: 98.96 (9896/10000) 

Epoch: 3
Train epoch:3 	Loss_in: 0.051943 | Loss_out: 0.325952 | Acc: 10.034388 (6011/59904)
(1672485304.9915338, 1672485318.4325316, 13.440997838973999)
Test epoch: 3| Acc: 98.95 (9895/10000) 

Epoch: 4
Train epoch:4 	Loss_in: 0.050577 | Loss_out: 0.325879 | Acc: 10.042735 (6016/59904)
(1672485318.9045, 1672485332.3414614, 13.43696141242981)
Test epoch: 4| Acc: 98.61 (9861/10000) 

Epoch: 5
Train epoch:5 	Loss_in: 0.049784 | Loss_out: 0.325877 | Acc: 10.234709 (6131/59904)
(1672485332.8166592, 1672485346.2772193, 13.460560083389282)
Test epoch: 5| Acc: 98.72 (9872/10000) 

Epoch: 6
Train epoch:6 	Loss_in: 0.052334 | Loss_out: 0.325890 | Acc: 10.071114 (6033/59904)
(1672485346.7497866, 1672485360.201747, 13.451960325241089)
Test epoch: 6| Acc: 98.66 (9866/10000) 

Epoch: 7
Train epoch:7 	Loss_in: 0.051992 | Loss_out: 0.325765 | Acc: 9.770633 (5853/59904)
(1672485360.6789434, 1672485374.1284168, 13.44947338104248)
Test epoch: 7| Acc: 98.56 (9856/10000) 

Epoch: 8
Train epoch:8 	Loss_in: 0.045497 | Loss_out: 0.325679 | Acc: 10.041066 (6015/59904)
(1672485374.6067483, 1672485388.0617595, 13.455011129379272)
Test epoch: 8| Acc: 98.56 (9856/10000) 

Epoch: 9
Train epoch:9 	Loss_in: 0.049935 | Loss_out: 0.325793 | Acc: 9.867455 (5911/59904)
(1672485388.5314887, 1672485401.966719, 13.435230255126953)
Test epoch: 9| Acc: 98.94 (9894/10000) 

Epoch: 10
Train epoch:10 	Loss_in: 0.052354 | Loss_out: 0.325843 | Acc: 9.697182 (5809/59904)
(1672485402.4242446, 1672485415.865748, 13.441503286361694)
Test epoch: 10| Acc: 99.07 (9907/10000) 

Epoch: 11
Train epoch:11 	Loss_in: 0.017768 | Loss_out: 0.325149 | Acc: 10.082799 (6040/59904)
(1672485416.3398123, 1672485429.8313751, 13.491562843322754)
Test epoch: 11| Acc: 99.46 (9946/10000) 

Epoch: 12
Train epoch:12 	Loss_in: 0.011478 | Loss_out: 0.325102 | Acc: 9.952591 (5962/59904)
(1672485430.3031447, 1672485443.8433151, 13.540170431137085)
Test epoch: 12| Acc: 99.49 (9949/10000) 

Epoch: 13
Train epoch:13 	Loss_in: 0.008768 | Loss_out: 0.325095 | Acc: 10.338208 (6193/59904)
(1672485444.3155622, 1672485457.8046243, 13.489062070846558)
Test epoch: 13| Acc: 99.52 (9952/10000) 

Epoch: 14
Train epoch:14 	Loss_in: 0.007125 | Loss_out: 0.325093 | Acc: 9.872463 (5914/59904)
(1672485458.2783473, 1672485471.769252, 13.490904808044434)
Test epoch: 14| Acc: 99.52 (9952/10000) 

Epoch: 15
Train epoch:15 	Loss_in: 0.006029 | Loss_out: 0.325091 | Acc: 10.433360 (6250/59904)
(1672485472.2363265, 1672485485.7404895, 13.504163026809692)
Test epoch: 15| Acc: 99.49 (9949/10000) 

Epoch: 16
Train epoch:16 	Loss_in: 0.005386 | Loss_out: 0.325089 | Acc: 10.074452 (6035/59904)
(1672485486.2192411, 1672485499.7349145, 13.515673398971558)
Test epoch: 16| Acc: 99.45 (9945/10000) 

Epoch: 17
Train epoch:17 	Loss_in: 0.004582 | Loss_out: 0.325088 | Acc: 9.977631 (5977/59904)
(1672485500.2150085, 1672485513.7432346, 13.528226137161255)
Test epoch: 17| Acc: 99.49 (9949/10000) 

Epoch: 18
Train epoch:18 	Loss_in: 0.004226 | Loss_out: 0.325088 | Acc: 10.064436 (6029/59904)
(1672485514.2165046, 1672485527.7331293, 13.516624689102173)
Test epoch: 18| Acc: 99.49 (9949/10000) 

Epoch: 19
Train epoch:19 	Loss_in: 0.004930 | Loss_out: 0.325089 | Acc: 10.351562 (6201/59904)
(1672485528.1985657, 1672485541.7178936, 13.519327878952026)
Test epoch: 19| Acc: 99.47 (9947/10000) 

Epoch: 20
Train epoch:20 	Loss_in: 0.006011 | Loss_out: 0.325089 | Acc: 10.453392 (6262/59904)
(1672485542.192257, 1672485555.7167583, 13.524501323699951)
Test epoch: 20| Acc: 99.15 (9915/10000) 

Epoch: 21
Train epoch:21 	Loss_in: 0.005241 | Loss_out: 0.325087 | Acc: 10.468416 (6271/59904)
(1672485556.1895926, 1672485569.6923175, 13.502724885940552)
Test epoch: 21| Acc: 99.54 (9954/10000) 

Epoch: 22
Train epoch:22 	Loss_in: 0.003692 | Loss_out: 0.325086 | Acc: 10.294805 (6167/59904)
(1672485570.150694, 1672485583.6452978, 13.494603872299194)
Test epoch: 22| Acc: 99.54 (9954/10000) 

Epoch: 23
Train epoch:23 	Loss_in: 0.003573 | Loss_out: 0.325086 | Acc: 10.207999 (6115/59904)
(1672485584.1213095, 1672485597.6149676, 13.493658065795898)
Test epoch: 23| Acc: 99.55 (9955/10000) 

Epoch: 24
Train epoch:24 	Loss_in: 0.003496 | Loss_out: 0.325086 | Acc: 10.595286 (6347/59904)
(1672485598.0893543, 1672485611.6043692, 13.515014886856079)
Test epoch: 24| Acc: 99.55 (9955/10000) 

Epoch: 25
Train epoch:25 	Loss_in: 0.003439 | Loss_out: 0.325086 | Acc: 10.428352 (6247/59904)
(1672485612.0778093, 1672485625.570141, 13.492331743240356)
Test epoch: 25| Acc: 99.55 (9955/10000) 

Epoch: 26
Train epoch:26 	Loss_in: 0.003396 | Loss_out: 0.325086 | Acc: 10.218015 (6121/59904)
(1672485626.0325212, 1672485639.528765, 13.496243715286255)
Test epoch: 26| Acc: 99.56 (9956/10000) 

Epoch: 27
Train epoch:27 	Loss_in: 0.003361 | Loss_out: 0.325086 | Acc: 10.576923 (6336/59904)
(1672485640.0022967, 1672485653.5000095, 13.497712850570679)
Test epoch: 27| Acc: 99.55 (9955/10000) 

Epoch: 28
Train epoch:28 	Loss_in: 0.003333 | Loss_out: 0.325086 | Acc: 10.296474 (6168/59904)
(1672485653.966243, 1672485667.4629166, 13.496673583984375)
Test epoch: 28| Acc: 99.55 (9955/10000) 

Epoch: 29
Train epoch:29 	Loss_in: 0.003304 | Loss_out: 0.325086 | Acc: 10.381611 (6219/59904)
(1672485667.9353235, 1672485681.4378831, 13.502559661865234)
Test epoch: 29| Acc: 99.55 (9955/10000) 

Epoch: 30
Train epoch:30 	Loss_in: 0.003278 | Loss_out: 0.325086 | Acc: 10.094485 (6047/59904)
(1672485681.9072788, 1672485695.4113867, 13.50410795211792)
Test epoch: 30| Acc: 99.52 (9952/10000) 

Epoch: 31
Train epoch:31 	Loss_in: 0.003249 | Loss_out: 0.325086 | Acc: 10.204661 (6113/59904)
(1672485695.884526, 1672485709.3868663, 13.502340316772461)
Test epoch: 31| Acc: 99.52 (9952/10000) 

Epoch: 32
Train epoch:32 	Loss_in: 0.003246 | Loss_out: 0.325086 | Acc: 10.144565 (6077/59904)
(1672485709.8656855, 1672485723.3654976, 13.499812126159668)
Test epoch: 32| Acc: 99.52 (9952/10000) 

Epoch: 33
Train epoch:33 	Loss_in: 0.003244 | Loss_out: 0.325086 | Acc: 10.298144 (6169/59904)
(1672485723.8437352, 1672485737.3444808, 13.50074553489685)
Test epoch: 33| Acc: 99.52 (9952/10000) 

Epoch: 34
Train epoch:34 	Loss_in: 0.003241 | Loss_out: 0.325086 | Acc: 10.136218 (6072/59904)
(1672485737.82452, 1672485751.3297172, 13.505197048187256)
Test epoch: 34| Acc: 99.52 (9952/10000) 

Epoch: 35
Train epoch:35 	Loss_in: 0.003238 | Loss_out: 0.325086 | Acc: 10.134549 (6071/59904)
(1672485751.8089488, 1672485765.31077, 13.501821279525757)
Test epoch: 35| Acc: 99.52 (9952/10000) 

Epoch: 36
Train epoch:36 	Loss_in: 0.003235 | Loss_out: 0.325086 | Acc: 10.308160 (6175/59904)
(1672485765.7824705, 1672485779.286183, 13.50371265411377)
Test epoch: 36| Acc: 99.52 (9952/10000) 

Epoch: 37
Train epoch:37 	Loss_in: 0.003233 | Loss_out: 0.325086 | Acc: 10.194645 (6107/59904)
(1672485779.7516642, 1672485793.2538662, 13.502202033996582)
Test epoch: 37| Acc: 99.52 (9952/10000) 

Epoch: 38
Train epoch:38 	Loss_in: 0.003225 | Loss_out: 0.325086 | Acc: 10.216346 (6120/59904)
(1672485793.7329, 1672485807.244721, 13.511821031570435)
Test epoch: 38| Acc: 99.52 (9952/10000) 

Epoch: 39
Train epoch:39 	Loss_in: 0.003228 | Loss_out: 0.325086 | Acc: 10.303152 (6172/59904)
(1672485807.7237225, 1672485821.2241497, 13.50042724609375)
Test epoch: 39| Acc: 99.52 (9952/10000) 
